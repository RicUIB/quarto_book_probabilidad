{
  "hash": "d944c9970f188cf74d4d402d6a55eb1f",
  "result": {
    "markdown": "# Variables Aleatorias\n\n## Introducción a las variables aleatorias\n\n* Hasta ahora nuestros sucesos han sido de varios tipos: $\\{C,+\\}$ en\nla moneda, nombres de periódicos, ángulos en una ruleta, número de\nveces que sale cara en el lanzamiento de una moneda etc\\ldots.\n* Necesitamos estandarizar de alguna manera todos estos sucesos. Una\nsolución es asignar a cada suceso un cierto conjunto de\nnúmeros reales, es decir, convertir todos los sucesos en\n*sucesos de números reales* para trabajar con ellos de forma\nunificada.\n* Para conseguirlo utilizaremos unas funciones que\ntransformen los elementos del espacio muestral en números; estas funciones son las\nvariables aleatorias.\n\n\n### Definición de variable aleatoria\n\nComenzaremos dando una definición poco rigurosa, pero suficiente, de variable aleatoria.\n\n<l class=\"definition\"> **Variable Aleatoria (definición práctica)** </l>\n\n\nUna variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio.\n\n<l class=\"observ\">**Notación**:</l>\n\n* Normalmente representaremos las v.a. por letras mayúsculas $X,Y,Z\\ldots$\n* Los valores que \"*toman*\" las v.a. los representaremos por letras minúsculas (las mismas en principio) $x,y,z\\ldots$\n\n\n\n<div class=\"example\">\n**Ejemplo: Dado seis caras**\n\nLanzamos un dado convencional de parchís y el espacio muestral del experimento es\n\n$$\\Omega=\\{1,2, 3, 4,  5, 6\\}.$$\n\n\n\n\n<div class=\"example-sol\">\nUna v.a. $X:\\Omega\\to\\mathbb{R}$\nsobre este espacio queda definida por \n\n\\begin{equation*}\n\\begin{split}\nX(1)&=1,X(2)=2,X(3)=3,\\\\\nX(4)&=4,X(5)=5,X(6)=6.\n\\end{split}\n\\end{equation*}\n\n* Ahora el suceso $A=\\{2, 4, 6\\}$, es decir \"salir\nnúmero par\", es equivalente a $\\{X=2,X=4,X=6\\}$.\n* El suceso $B=\\{1,2,3\\}$, es decir \"salir número\ninferior o igual a $3$\" es  en términos de la v.a. $\\{X=1,X=2,X=3\\}$ o también $\\{X\\leq 3\\}$.\n\n</div>\n</div>\n\n\n<div class=\"example\">\n**Ejemplo: Juego lanzamiento anilla**\n\nConsideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a\nensartar la anilla en la botella, el resultado del experimento es *éxito* y\n*fracaso* en caso contrario. \n\n<div class=\"example-sol\">\nEl espacio muestral asociado a este experimento será\n$\\Omega=\\{\\mbox{éxito, fracaso}\\}$. Construyamos la siguiente variable aleatoria:\n\n$$X:\\{\\mbox{éxito, fracaso}\\}\\to\\mathbb{R}$$\n\ndefinida por \n\n$$X(\\mbox{éxito})=1 \\mbox{ y } X(\\mbox{fracaso})=0.$$\n\n</div>\n</div>\n\n### Tipos de variables aleatorias\n\nHay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.\n\nDamos a continuación una definición informal.\n\n<l class=\"definition\">**Variables Aleatorias Discretas y Continuas** </l>\n\n* Una variable aleatoria es **discreta** si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.\n* Las variables aleatorias **continuas**  toman  valores en intervalos.\n* También existen las variables aleatorias **mixtas**; con una parte discreta y otra continua.\n\n\n<div class=\"example\">\n**Ejemplo: Tipos de variables aleatorias**\n\nSon **variables aleatorias discretas**:\n      \n*  Número de artículos defectuosos en un cargamento.\n*  Número de clientes que llegan a una ventanilla de un banco en una hora.\n*  Número de errores detectados en las cuentas de una compañía.\n*  Número de reclamaciones de una póliza de un seguro médico.\n      \nSon **variables aleatorias continuas**:\n      \n* Renta anual de una familia.\n* Cantidad de petróleo importado por un país.\n* Variación del precio de las acciones de una compañía de telecomunicaciones.\n* Porcentaje de impurezas en un lote de productos químicos.\n      \n</div>\n\n## Variables aleatorias discretas\n\n### Distribuciones de probabilidad para v.a. discretas.\n\n* Pasamos ahora a describir el comportamiento  de la v.a. \nPara ello utilizaremos distintas funciones que nos darán algunas probabilidades de la variable aleatoria.\n* En el caso discreto, estas funciones son la de probabilidad y  la función de distribución o de probabilidad acumulada.\n* En el caso discreto, la función de probabilidad es la que nos da las probabilidades de los sucesos elementales de la v.a. que definimos a continuación.\n\n\n<l class=\"definition\"> **Función de Probabilidad**</l>\n\nLa **función de probabilidad** (*probability mass function* o incluso abusando de notación *probability density function*) de una variable aleatoria discreta $X$ a la que denotaremos por $P_{X}(x)$ está definida por\n$$P_{X}(x)=P(X=x),$$\nes decir, la probabilidad de que $X$ tome el valor $x$.\n\nSi $X$ no asume ese valor $x$, entonces $P_{X}(x)=0$.\n\n<l class=\"definition\"> **Dominio de una variable aleatoria discreta** </l> \n\nEl conjunto $$D_X=\\{ x\\in\\mathbb{R} \\mid P_X(x)>0\\}$$ recibe el nombre de\n**dominio** de la v.a. y son los valores posibles de esta variable. \n\nEn el caso discreto lo más habitual es que $X(\\Omega)=D_X$.\n\n\n<div class=\"example\">\n**Ejemplo: Juego del parchís**\n\nLanzamos un dado de parchís una vez, en esta ocasión representaremos los\nsucesos elementales por el número de puntos de la cara obtenida, tenemos que\n$$\\Omega=\\{\\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\\},$$ \ny la variable aleatoria $X:\\Omega\\to \\mathbb{R}$ viene definida por\n\n$$X(\\mbox{i-puntos})=i\\mbox{ para } i=1,2,3,4,5,6.$$\n  \n<div class=\"example-sol \">\n\nSupongamos que el dado está bien balanceado. Entonces\n$$P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\\frac16.$$\nConcretamente:\n$$\nP_{X}(x)=\n  \\left\\{\n  \\begin{array}{ll}\n   \\frac16 & \\mbox{si } x=1,2,3,4,5,6\\\\\n  0 & \\mbox{en otro caso. }\n  \\end{array}\n  \\right.\n$$\n  \nSu dominio es $$D_X=\\{1,2,3,4,5,6\\}.$$\n</div>\n</div>\n\n<div class=\"example\">\n**Ejemplo: Lanzamiento moneda**\n\n\nSea $X$ la v.a. asociada al lanzamiento de una moneda. Su espacio muestral es  $\\Omega=\\{c,+\\}$, la v.a. queda definida por:\n\n$$X(\\omega)=\\left\\{\\begin{array}{ll} 1 & \\mbox{si } \\omega=c, \\\\\n0 & \\mbox{si }\\omega=+.\\end{array}\\right.$$\n\n\n<div class=\"example-sol\">\n\nSu función de probabilidad es:\n\n$$P_{X}(x)=P(X=x)=\\left\\{\\begin{array}{ll} \\frac12, & \\mbox{si } x=0,1,\\\\\n0, & \\mbox{en otro caso.}\\end{array}\\right.$$\n\n\nFinalmente su dominio es $D_X=\\{0,1\\}.$\n</div>\n</div>\n\n<div class=\"example\">\n**Ejemplo:  Urna con bolas**\n\nTenemos una urna con tres bolas rojas, una negra y dos blancas. Realizamos una extracción y observamos el color de la bola. Entonces, un espacio muestral es\n$$\\Omega=\\{roja, blanca, negra\\}.$$ \n\n<div class=\"example-sol\">\n\nUna variable aleatoria asociada al experimento es:\n\n$$X(\\omega)=\\left\\{\\begin{array}{ll} 1, & \\mbox{si } \\omega=roja,  \\\\\n2, & \\mbox{si }\\omega=negra, \\\\ 3, & \\mbox{si } \\omega=blanca. \\end{array}\\right.$$\n\nLa función de probabilidad es \n\n$$P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac36, & \\mbox{si } x=1,\\\\[1ex]\n\\frac16, & \\mbox{si } x=2,\\\\[1ex] \\frac26, & \\mbox{si } x=3,\\\\[1ex] 0, & \\mbox{en otro\ncaso.}\\end{array}\\right.$$\n\nEl dominio de la v.a.  $X$ es $D_X=\\{1,2,3\\}.$\n\n</div>\n</div>\n\n<l class=\"prop\"> **Propiedades básicas de la función de probabilidad** </l>\n\nSea $X$ una v.a. discreta $X:\\Omega\\to\\mathbb{R}$ con dominio $D_X$. Su función de probabilidad $P_{X}$ verifica las siguientes propiedades:\n\n* $0\\leq P_{X}(x)\\leq 1$, para todo $x\\in\\mathbb{R}$.\n* $\\sum\\limits_{x\\in D_X} P_{X}(x)=1$.\n\n\n\n<div class=\"example\">\n\n**Ejemplo: Lanzamiento moneda** \n\nLanzamos al aire tres veces, de forma independiente, una moneda perfecta. El espacio muestral de este experimento es\n$$\\Omega=\\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\\}$$ (expresados en orden de aparición).\n\n<div class=\"example-sol\">\n\nEste espacio tiene todos los sucesos elementales equiprobables. \n\nConsideremos la variable aleatoria asociada a este experimento:\n\n$$X=\\mbox{ número de caras en los tres lanzamientos}.$$ \n\nSu función de probabilidad es:\n\n$$\n\\begin{array}{l}\nP(X=0)=P(\\{+++\\})=\\frac18,\\\\ P(X=1)=P(\\{c++,+c+,++c\\})=\\frac38,\\\\\n    P(X=2)=P(\\{cc+,c+c,+cc\\})=\\frac38,\\\\\n    P(X=3)=P(\\{ccc\\})=\\frac18.\n\\end{array}\n$$\n\nPodemos reescribir la función de probabilidad de $X$ de forma simplificada:\n    \n$$P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac18, & \\mbox{si } x=0, 3,\\\\[1ex]\n\\frac38, & \\mbox{si } x=1,2,\\\\[1ex] 0, & \\mbox{en otro caso.}\\end{array}\\right.$$\n\n\n\nEfectivamente los valores de la función de distribución suman 1:\n\n$$\\sum_{x=0}^3 P_X(x)= \\frac18+\\frac38+\\frac38+\\frac18=1.$$\n\n</div>\n</div>\n\n<l class=\"definition\"> **Distribución de Probabilidad**</l>\n\nLa función de *distribución de probabilidad* (acumulada) de la v.a. $X$ (de cualquier tipo; discreta o continua) $F_{X}(x)$ representa la probabilidad de que $X$  tome un menor o igual que  $x$, es decir,\n\n$$F_{X}(x)=P(X\\leq x).$$\n\nEsta función también se denomina función de *distribución de\nprobabilidad o simplemente función de distribución* de una v.a., y en inglés\n*cumulative distribution function* por lo que se abrevia con el acrónimo `cdf`.\n\n\n<l class=\"definition\"> **Propiedades de la Función de Distribución**</l>\n\nSea $X$ una v.a. y $F_{X}$ su función de distribución:\n\n1. $P(X>x)=1-P(X\\leq x)=1-F_{X}(x).$\n2. Sea a y b tales que $a<b$, $P(a<X\\leq b)=P(X\\leq b)-P(X\\leq a)=F_{X}(b)-F_{X}(a).$\n\n\n\n<div class=\"dem\"> \n\n**Demostración**:\n\nTenemos que el complementario de $X$ mayor que $x$ es:  $\\overline{\\left\\{X>x\\right\\}}=\\left\\{X>x\\right\\}^c=\\left\\{X\\leq x\\right\\}$. Además,\n\n$$P(X>x)=1-P(\\overline{\\left\\{X>x\\right\\}})=1-P(X\\leq x)=1-F_{X}(x),$$\n    \nlo que demuestra la primera propiedad.\n\nPor otro lado, que $X$ se encuentre entre dos valores $a$ y $b$ es  $\\left\\{a< X \\leq b\\right\\}= \\left\\{X\\leq b\\right\\}-\\left\\{X\\leq  a\\right\\}$. Ahora podemos hacer \n    \n\\begin{eqnarray*}\nP(a<X\\leq b)&=&P(\\left\\{X\\leq b\\right\\}-\\left\\{X\\leq a\\right\\})\\\\\n&=& P(\\left\\{X\\leq b\\right\\})-P(\\left\\{X\\leq a\\right\\})\\\\\n&=& F_{X}(b)-F_{X}(a).\n\\end{eqnarray*}\n\n</div>\n\n\n\n<l class=\"definition\"> **Más propiedades de la Función de Distribución**</l>\n\nSea $F_{X}$ la función de distribución  de una  v.a. $X$ entonces:\n \n* $0\\leq F_{X}(x)\\leq 1$.\n* La función $F_{X}$ es no decreciente.\n* La función $F_{X}$ es continua por la derecha.\n* Si denotamos por $F_X(x_0^{-})=\\displaystyle \\lim_{x\\to x_0^{-}} F(x)$,\nentonces se cumple que $P(X< x_0)=F_X(x_0^{-})$ y que $P(X=x_0)=F_X(x_0)-F_X(x_0^{-})$.\n* Se cumple que $\\displaystyle \\lim_{x\\to\\infty} F_{X}(x)=1$; $\\displaystyle \\lim_{x\\to-\\infty}F_{X}(x)=0$.\n*  Toda función $F$ verificando las propiedades anteriores es función de distribución de alguna v.a. $X$.\n* $P(X>x)=1-F_{X}(x)$.\n* Dados $a,b\\in \\mathbb{R}$ con $a<b$, $$P(a<X\\leq b)=F_{X}(b)-F_{X}(a).$$\n\n**Advertencia desigualdades estrictas**\n\nEn las propiedades anteriores no se pueden cambiar, en general, las desigualdades de\nestrictas o no estrictas.\n\nVeamos qué propiedades tenemos cuando se cambian estas\ndesigualdades.\n\n\nDada una $F_{X}$ una función de distribución de la v.a. $X$ y denotamos por $$F_{X}(x_0^{-})=\\displaystyle \\lim_{x\\to x_0^{-}} F_{X}(x),$$\nentonces  se cumplen las siguientes igualdades:\n\n* $P(X=x)=F_{X}(x)-F_{X}(x^{-})$.\n* $P(a< X< b)=F_{X}(b^{-})-F_{X}(a)$.\n* $P(a\\leq X< b)=F_{X}(b^{-})-F_{X}(a^{-})$.\n* $P(X<a)=F_{X}(a^{-})$.\n* $P(a\\leq X\\leq b)=F_{X}(b)-F_{X}(a^{-})$.\n* $P(X\\geq a)=1-F_{X}(a^{-})$.\n* Si  $F_X$ es continua en $x$ se tiene que $P(X=x)=0$.\nAsí que si la v.a. es continua $P(X\\leq a)=P(X< a)+P(X=a)=P(X<a)$ y propiedades similares.\n* Sea $X$ una variable aleatoria discreta que con dominio $D_X$ y\nque tiene por función de probabilidad $P_{X}(x)$ entonces su función de distribución\n$F_{X}(x_0)$ es\n$$F_{X}(x_0)=\\sum_{x\\leq x_0} P_{X}(x),$$\ndonde $\\sum\\limits_{x\\leq x_0}$ indica que sumamos todos los $x \\in D_X$ tales que $x\\leq\nx_0$.\n\n<div class=\"dem\"> \n\n**Demostración**:\n\n\nSi $X$ es continua $$P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0,$$\npor lo tanto\n$$P(X\\leq a)=P(X<a)+P(X=a)= P(X<a)+0= P(X<a),$$\nlo que demuestra la primera propiedad.\n\nPara demostrar la segunda basta hacer\n$$ \nF_{X}(x_0)= P(X\\leq x_0)=P\\left(\\bigcup_{x\\leq\nx_0; x\\in D_X} \\{x\\}\\right)= \\sum_{x\\leq x_0}P(X=x)= \\sum_{x\\leq x_0}P_{X}(x).\n$$\n  \n</div>\n\n\n<div class=\"example\">\n**Ejemplo: dado (continuación)**\n\nEn el experimento del dado se tiene que:\n\n$$P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac16, & \\mbox{si } x=1,2,3,4,5,6,\\\\ 0, & \\mbox{en el resto de casos.}\\end{array}\\right.,$$\n\npor lo tanto,\n$$F_{X}(x)=P(X\\leq x)=\\left\\{\\begin{array}{ll}\n   0, & \\mbox{si } x<1,\\\\[1ex]\n   \\frac16, &\\mbox{si } 1\\leq x<2,\\\\[1ex]\n   \\frac26, &\\mbox{si } 2\\leq x<3,\\\\[1ex]\n   \\frac36, &\\mbox{si } 3\\leq x<4,\\\\[1ex]\n   \\frac46, &\\mbox{si } 4\\leq x<5,\\\\[1ex]\n   \\frac56, &\\mbox{si } 5\\leq x<6,\\\\[1ex]\n   1, &\\mbox{si } 6\\leq x.\\end{array}\\right.$$\n\nCalculemos más detalladamente algún valor de $F_{X}$, por ejemplo:\n\n\\begin{eqnarray*}\nF_{X}(3.5) & = & P(X\\leq 3.5)=  P(\\{X=1\\}\\cup\\{X=2\\}\\cup \\{X=3\\})\\\\\n&=& P(\\{X=1\\})+P(\\{X=2\\})+P(\\{X=3\\})\\\\\n&=& \\frac16+\\frac16+\\frac16=\\frac36 =\\frac12,\n\\end{eqnarray*}\no de otra forma,\n\\begin{eqnarray*}\nF_{X}(3.5)&=&\\sum_{x\\leq 3.5} P_X(x)=\\sum_{x=1}^3 P(X=x)\\\\&=&\\sum_{x=1}^3 \\frac16= 3 \\cdot\n   \\frac16=\\frac12.\n\\end{eqnarray*}\n</div>\n\n\n**Propiedades de la función de distribución**\n\nSea $X$ una variable con función de distribución $F_{X}$ entonces:\n \n* $0\\leq F_{X}(x)\\leq 1$, para todo $x$.\n* Si $x<x'$, entonces $F_{X}(x)\\leq F_{X}(x'),$ es decir, es una función creciente, no necesariamente estrictamente creciente.\n* $\\displaystyle \\lim_{x\\to -\\infty}F_{X}(x)=0$ y $\\displaystyle \\lim_{x\\to +\\infty}F_{X}(x)=1$.\n* Es continua por la derecha: $\\displaystyle \\lim_{x\\to x_0^{+}}F_{X}(x)=F_{X}(x_0)$.\n  \n\n\n\n### Valores esperados  o esperanza\n\n\nAl igual que en  la estadística descriptiva  se utilizan  distintas medidas para\nresumir los valores centrales y para medir la dispersión de una muestra, podemos definir\nlas correspondientes medidas para variables aleatorias.\n\nA estas medidas se les suele añadir el adjetivo **poblacionales** mientras que a las que provienen de la muestra se las adjetiva como **muestrales**.\n\n\nPor ejemplo,  podemos buscar un valor que resuma toda la variable. Este valor es el que \"*esperamos*\" que se resuma la v.a. o esperamos que las realizaciones de la v.a. queden cerca de él. Veamos su definición formal.\n\n<l class=\"definition\">**Esperanza de una variable aleatoria discreta **</l>\n\nEl valor **esperado o esperanza** (*expected value* en inglés) $E(X)$ de una v.a. discreta $X$, se define como\n\n$$\nE(X)=\\sum_{x\\in X(\\Omega)} x P_{X}(x).\n$$\n\n\nEn ocasiones se denomina **media** (*mean* en inglés) poblacional o simplemente media y muy frecuentemente se la denota $\\mu_{X}=E(X)$ o simplemente $\\mu=E(X)$.\n\n\n<div class=\"example\">\n**Ejemplo: lanzamiento de un dado $n$ veces**\n\nSupongamos que lanzamos un dado $n$ veces y obtenemos unas frecuencias absolutas $n_{i}$ para el resultado $i$ con $i=1,\\ldots,6$. Sea $X$ la v.a. que nos representa el valor de una tirada del dado.\n\nCalculemos la media aritmética (o media muestral) de los datos\n\n$$\n\\overline{x}=\\frac{1\\cdot n_1+2\\cdot  n_2+3\\cdot  n_3+4\\cdot  n_4+5\\cdot  n_5+6 \\cdot \nn_6}{n}=\\sum_{x=1}^6 x\\cdot \\frac{n_{x}}{n}.\n$$\nSi $n\\to \\infty$ se tiene que $\\displaystyle\\lim_{n\\to \\infty} \\frac{n_{x}}{n}=P_{X}(x).$\n\nPor lo tanto $E(X)=\\displaystyle \\lim_{n\\to\\infty}\\sum_{x=1}^6 x\\cdot \\frac{n_{x}}{n}.$\n\nEntonces el valor esperado en una v.a. discreta puede entenderse como el valor promedio que tomaría una v.a. en un número grande de repeticiones.\n\n</div>\n\n\n<div class=\"example\">\n\n**Ejemplo: Erratas en un texto**\n\nSea $X$ el número  de erratas en una página de un texto, con dominio $D_X=\\{0,1,2\\}$.\n\nResulta que\n\n$$\nP(X=0)=0.42,\\ P(X=1)=0.4,\\ P(X=2)=0.18.\n$$\n    \nentonces\n    \n$$\nE(X)=0\\cdot 0.42+ 1\\cdot 0.4 + 2 \\cdot 0.18=0.76.\n$$\n\nElegida una página del texto al azar esperamos encontrar $0.76$ errores por página.\n\nSupongamos que el editor nos paga $2$ euros por cada página que\nencontremos con $1$ error y $3$ euros por cada página con  dos errores (y nada por las\npáginas correctas) ¿Cuánto *esperamos* cobrar si analizamos una página?\n\n$$0\\cdot 0.42 + 2\\cdot 0.4 + 3\\cdot 0.18=1.34.$$\n</div>\n\n<l class=\"definition\"> **Esperanzas de funciones de variables aleatorias discretas** </l>\n\nSea $X$ una v.a. discreta con función de probabilidad $P_{X}$ y de distribución\n$F_{X}$. Entonces el **valor esperado de una función** $g(x)$ es :\n\n$$E(g(X))=\\sum_{x}g(x)\\cdot P_{X}(x).$$\n\n\n**Propiedades de los valores esperados**\n \n* $E(k)=k$ para cualquier constante $k$.\n* Si $a\\leq X\\leq b$ entonces $a\\leq E(X)\\leq b$.\n* Si $X$ es una v.a. discreta que toma valores enteros no negativos entonces\n$E(X)=\\sum_{x=0}^{+\\infty}(1- F_X(x)).$\n  \n<div class=\"exercise\">\n**Ejercicio**\n\nLa demostración de las propiedades anteriores se deja como ejercicio.\n</div>\n\n\n<div class=\"example\"> \n**Ejemplo: paleta de colores aleatoria**\n\nSupongamos que estamos sentados delante de nuestro ordenador con un amigo y\nle decimos que en dos minutos podemos programar una paleta  para poner colores a unos\ngráficos. \n\nQueremos que la paleta tenga dos botones con las opciones color rojo y color azul.\nComo hemos programado a gran velocidad resulta que el programa tiene un error; cada vez que se abre la paleta los colores se colocan al azar (con igual probabilidad) en cada botón, así que no sabemos en qué color hemos de pinchar. \n\nAdemás, como nos sobraron $15$ segundos\npara hacer el programa y pensando en la  comodidad del usuario, la paleta se cierra después de haber seleccionado  un color y hay que volverla a abrir de nuevo.\n\nLa pregunta es: ¿cuál es el valor esperado del\nnúmero de veces que hemos pinchar el botón de color azul antes de obtener este color?\n\n\n<div class=\"example-sol\"> \nLlamemos $X$ al número de veces que pinchamos en el botón azul (y nos sale rojo) hasta\nobtener el primer azul. La variable $X$ toma valores en los enteros no negativos. Su\nfunción de probabilidad queda determinada por\n\n$$\nP_X(x)=P(X=x)=P(\\stackrel{x \\mbox{ veces}}{\\overbrace{rojo, rojo,\\ldots,rojo},azul})\n=\\left(\\frac12\\right)^{x+1}.\n$$\n\n</div>\n</div>\n\n**Series geométricas**\n\nUna **progresión geométrica** de razón $r$ es una sucesión de la  forma  \n$$\nr^0, r^1,\\ldots,r^n,\\ldots.\n$$\nLa serie geométrica es la suma de todos los\nvalores de la progresión geométrica $\\displaystyle\\sum_{k=0}^{+\\infty} r^k$.\n\n<l class=\"prop\">**Propiedades**</l>\n\n* Las sumas parciales desde el término $n_0$ al $n$ de una progresión geométrica valen \n$$\n\\sum_{k=n_0}^n r^k=\\frac{r^{n_0}- r^n r}{1-r}.\n$$\n\n* Si $|r|<1$ la serie geométrica es convergente y $$\\sum_{k=0}^{+\\infty }\nr^k=\\frac1{1-r}$$. \n* En el caso en que se comience en $n_0$ se tiene que\n$$\\sum_{k=n_0}^{+\\infty} r^k=\\frac{r^{n_0}}{1-r}.$$\n\n* Si $|r|<1$  también son convergentes las derivadas, respecto de $r$, de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que\n\n\n\\begin{eqnarray*}\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)'= & \\sum_{k=1}^{+\\infty}k\nr^{k-1} =  \\left(\\frac1{1-r}\\right)'=\\frac1{(1-r)^2}\\\\\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)^{''}=& \\sum_{k=2}^{+\\infty}k (k-1)\nr^{k-2} = \\left(\\frac1{1-r}\\right)^{''}=\\frac2{(1-r)^3}.\n\\end{eqnarray*}\n\n\n\n<div class=\"example\">\n\n**Ejemplo: paleta de colores (continuación)**\n\nSi seguimos con el ejemplo de la paleta de colores, su esperanza es:\n\n\\begin{eqnarray*}\nE(X)&=&\\sum_{x=0}^{+\\infty} x\\cdot P(X=x)=\\sum_{x=0}^{+\\infty} x\\cdot\n\\left(\\frac12\\right)^{x+1}\\\\\n&= & \\left(\\frac12\\right)^2\\sum_{x=1}^{+\\infty} x\\cdot\n\\left(\\frac12\\right)^{x-1}=\\left(\\frac12\\right)^2\n\\frac1{\\left(1-\\frac12\\right)^2}=1.\n\\end{eqnarray*}\n\nAhora calculemos su función de distribución\n\n\\begin{eqnarray*}\nF_X(x)&=& P(X\\leq x)=\\sum_{k=0}^x P(X=k)=\\sum_{k=0}^x\n\\left(\\frac12\\right)^{k+1}\\\\\n&=& \\frac{\\frac12-\\frac12^{x+1}\\cdot\n\\frac12}{1-\\frac12}=1-\\left(\\frac12\\right)^{x+1}.\n\\end{eqnarray*}\n\nComo la variable toma valores enteros positivos, podemos calcular su valor esperado\nde esta otra manera\n\n$$E(X)=\\sum_{x=0}^{+\\infty} (1-F_X(x))=\\sum_{x=0}^{+\\infty}\\left(\\frac12\\right)^{x+1}=\\frac12\\cdot\n\\frac1{1-\\frac12}=1.$$\n\n</div>\n\n<div class=\"exercise\">\n\n**Ejercicio**\n\nCalculad el valor esperado de la variable\n\n$$\nY=\\mbox{número de intentos para conseguir el color azul.}\n$$\n</div>\n\n<l class=\"definition\"> **Momentos de orden $m$**</l>\n\nLlamaremos  **momento de orden $m$** respecto al punto $C$ a \n$$E\\left((X-C)^m\\right).$$\n\n* Cuando $C=0$ los momentos reciben el nombre de **momentos respecto al origen**.\n* Cuando $C=E(X)$ reciben el nombre de **momentos centrales o respecto de la media**. Luego la esperanza es el momento de orden $1$ respecto al origen. Estos momentos son la versión poblacional de los momentos que vimos en el curso de estadística descriptiva, recibiendo estos último el nombre de momentos muestrales.\n\n\n**Resumen de conceptos**\n\n* Hemos descrito el comportamiento aleatorio de una v.a. discreta mediante sus funciones  de probabilidad $P_{X}$ y de distribución $F_{X}$.\n* También tenemos un valor central; el valor esperado $E(X)$. \n* Como medida básica nos queda definir una medida de lo lejos que están los datos del valor central, $E(X)$. Una de estas medidas es la varianza de $X$.\n\n### Medidas de la variabilidad\n\n<l class=\"definition\"> **Varianza** </l>\n\nSea $X$ una v.a. Llamaremos **varianza** de $X$ a\n\n$$Var(X)=E((X-E(X))^2).$$\n\nPor lo tanto, la varianza es el momento central de orden $2$.\n\nDe forma frecuente se utiliza la notación $$\\sigma_{X}^2=Var(X).$$\n    \nA la raíz cuadrada positiva de la varianza\n$$\\sigma_{X}=+\\sqrt{Var(X)},$$\n   \nse la denomina desviación típica o estándar de $X$.\n\n<l class=\"prop\"> **Propiedad** </l>\n\n* Si $X$ es una v.a. discreta con función de probabilidad $P_X$ su varianza es \n $$\\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\\sum_{x}(x-E(X))^2 \\cdot P_{X}(x).$$\n* Sea $X$ una v.a.\n $$Var(X)=E(X^2)-(E(X))^2=\\sum_{x} x^2\\cdot  P_{X}(X)-(E(X))^2$$\n  \n\n\n\n<div class=\"dem\"> \n\n**Demostración de b)**\n\n\n\\begin{eqnarray*}\nVar(X)&= & \\sum_{x}(x-E(X))^2 \\cdot P_{X}(x) = \\sum_{x}(x^2 -2 x E(X)+(E(X)^2)\\cdot  P_{X}(x)\\\\\n&=& \\sum_{x}x^2 \\cdot  P_{X}(x) -  E(X)\\sum_{x}2 x\\cdot  P_{X}(x) + (E(X)^2)\\sum_{x} P_{X}(x)\\\\\n&=& E(X^2)- 2 E(X)\\cdot  E(X) + (E(X))^2=E(X^2)-(E(X))^2.\n\\end{eqnarray*}\n\n\n\n</div>\n\n\n<div class=\"example\"> \n**Ejemplo: número de errores (continuación)**\n\nCalculemos en  el ejemplo anterior la varianza del número de errores.\n\n\n<div class=\"example-sol\"> \n\nRecordemos que:\n   \n$$\nP(X=0)=0.42,\\  P(X=1)=0.4, \\  P(X=2)=0.18,\n$$\ny que\n$$\nE(X)=0.76.\n$$\nEntonces:\n    \n$$\nVar(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.\n$$\nAhora necesitamos calcular \n  \n  $$E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12,$$\ny por lo tanto\n  \n  $$Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542,$$\n  y $$\\sqrt{Var(X)}=\\sqrt{0.542}.$$\n\n  En resumen $\\sigma_{X}^2=0.542$ y $\\sigma_{X}=\\sqrt{0.542}.$\n     \n\n</div>\n</div>\n\n\n**Más propiedades de la varianza**\n\n* $Var(X)\\geq 0$.\n* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$.\n* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.\n  \n\n<div class=\"exercise\">\n**Ejercicio**\n\nSe deja como ejercicio la demostración de estas propiedades.\n\n</div>\n\n\n### Transformaciones lineales. \n\n<l class=\"definition\"> **Transformación lineal** </l>\n\nUn **cambio de variable lineal** o **transformación lineal** de una v.a. $X$ es otra v.a. $Y= a+ b X$  donde $a,b\\in\\mathbb{R}$.\n\n<l class=\"prop\"> **Esperanza de una transformación lineal**</l>\n\nSea $X$ una v.a. con $E(X)=\\mu_{X}$ y $Var(X)=\\sigma_{X}^2$ y $a,b\\in\\mathbb{R}$.\nEntonces si $Y=a+b X$:\n \n* $E(Y)=E(a + b X)=a+ b\\cdot E(X)= a + b\\cdot \\mu_{X}$.\n* $Var(Y)=Var(a+bX)=b^2\\cdot Var(X)= b^2 \\cdot \\sigma_{X}^2$.\n* $\\sigma_{Y}=\\sqrt{Var(Y)}=\\sqrt{b^2\\cdot Var(X)}=|b|\\cdot \\sigma_{X}$.\n  \n    \n\n<div class=\"dem\">\n**Demostración**:\n\n\\begin{eqnarray*}\nE(Y)&=& E(a+bX)=\\sum_{x}(a+b\\cdot X)\\cdot P_{X}(x)\\\\\n&=& a \\sum_{x} P_{X}(x) + b \\sum_{x} x\\cdot P_{X}(x)\\\\ \n&=& a + b\\cdot E(X)=a + b \\mu_{X}.\n\\end{eqnarray*}\n\n</div>\n\n<div class=\"exercise\">\n**Ejercicio**\n\nLas demostración de las demás propiedades se dejan como ejercicio.\n</div>\n\n\n## Variables aleatorias continuas\n\n\nComo ya hemos dicho las variables aleatorias continuas toman valores en\nintervalos o áreas.\n\nLo más habitual es que estas variables tengan función de distribución continua y\nderivable (salvo a los mejor en una cantidad finita o numerable de puntos).\n\nEn lo que sigue supondremos que la función de distribución de variables\naleatorias continuas cumplen estas propiedades.\n\nNotemos que si $X$ es una v.a. con función de distribución continua se tiene que\n$P(X=x_0)=F_X(x_0)-F(x_0^{-})=0$. Por lo que no tiene sentido definir *función de probabilidad*.\n\nEn general tendremos que $P(X<x_0)=P(X\\leq x_0)$.\n\nPor otra parte podemos utilizar una regla parecida del\ncociente entre casos favorables y casos posibles de Laplace  pero en\neste caso el conteo se hace por la *medida*  de los casos\nposibles partida por la *medida* de los casos favorables.\n\nVeamos un ejemplo de v.a. continua, que ampliaremos en el tema siguiente, en el que se utilizan todos estos conceptos.\n\n\n<div class=\"example\"> \n\n**Ejemplo: distancia de un dardo al centro de la diana** \n\nSupongamos que lanzamos un dardo a una diana de radio $1$, de forma que sea *equiprobable* cualquier distancia al centro (¡Cuidado! esto no es equivalente\na que cualquier punto de la diana sea *equiprobable*).\n\nConsideremos la v.a. continua $X=$ distancia del dardo al centro de la diana.\n\n\n<div class=\"example-sol\">\n\nSu función de distribución es \n\n$$\nF_{X}(x)=\n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\nx, & \\mbox{si } 0<x<1,\\\\\n1, & \\mbox{si } x\\geq 1.\n\\end{array}\n\\right.\n$$\n\n* C.F. *longitud favorable* es $x-0$.\n* C.P. *longitud posible* es $1-0$.\n* Luego \n$$P(X\\leq x)=\\frac{C.F.}{C.P.}=\\frac{x-0}{1-0}=x.$$\n</div>\n</div>\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncurve(punif(x,0,1),xlim=c(-1,2),col=\"blue\",\n      main=\"Función de distribución de una v.a. uniforme en el intervalo unidad.\")\n```\n\n::: {.cell-output-display}\n![](2_files/figure-pdf/figUNIF-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n### Propiedades\n\nEn las variables continuas los sucesos del tipo $\\{X\\leq x \\}$ y $\\{X< x \\}$ tendrán la\nmisma probabilidad, y otros tipos de sucesos similares también. Algunas de estas\npropiedades se explicitan en la siguiente proposición.\n\n<l class=\"prop\">**Propiedades**</l>\n\nDada una v.a. continua $X$ se tiene que:\n \n* $P(X\\leq b)=P(X<b)$.\n* $P(X<b)=P(X<a)+P(a<X<b)$.\n* $P(a<X<b)=P(X<b)-P(X<a)$.\n  \n  \n<div class=\"dem\">\n**Demostración:**\n\nLa primera es evidente  $P(X\\leq b)=P(X<b)+P(X=b)=P(X<b)$.\n\nPara demostrar la segunda, tenemos\n\n$$\\{X\\leq a\\}\\cap \\{a<X<b\\}=\\emptyset,$$ \n$$\\{X\\leq a\\}\\cup \\{a<X<b\\}=\\{X<b\\},$$ \nentonces\n\\begin{eqnarray*}\nP(X< b) & = & P(\\{X\\leq a\\}\\cup \\{a<X<b\\})\\\\\n& = & P(X\\leq a)+P(a<X<b) \\\\\n& = & P(X< a)+P(a<X<b).\n\\end{eqnarray*}\n\n\n</div>\n\n<div class=\"exercise\">\n**Ejercicio**\n\nLa demostración de la tercera propiedad es similar a la segunda pero aplicando la primera. La dejamos como ejercicio.\n</div>\n\n\n**Propiedades de la función de distribución**\n\nLas propiedades anteriores  y combinaciones de ellas se pueden\nescribir utilizando la función de distribución de $X$:\n\n\n<l class=\"prop\"> **Propiedades de la Función de Distribución** </l>\n\nDada una variable aleatoria continua se tiene que:\n\n* $F_{X}(b)=F_{X}(a)+P(a<X<b)$.\n* $P(a<X<b)=F_{X}(b)-F_{X}(a)$.\n* $P(a\\leq X\\leq b)=F_{X}(b)-F_{X}(a)$.\n\n\n\n<div class=\"exercise\"> \n\n**Ejercicio**\nSe deja la demostración como ejercicio. \n</div>\n\n\n\n\n<div class=\"example\"> \n**Ejemplo: diana (continuación)**\n\n\nEn el ejemplo de la diana:\n\n$$P(0.25<X<0.3)=F_{X}(0.3)-F_{X}(0.25)=0.3-0.25=0.05.$$\n</div>\n\n### Función de densidad\n\n<l class=\"definition\"> **Función de densidad** </l> \n\nUna función $f:\\mathbb{R}\\to\\mathbb{R}$ es una función de densidad sobre $\\mathbb{R}$ si cumple que\n\n\n* $f_{X}(x)\\geq 0$ para todo $x \\in\\mathbb{R}.$\n* $f$ es continua salvo a lo sumo en una cantidad finita de puntos sobre\ncada intervalo acotado de $\\mathbb{R}$.\n* $\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} f_{X}(x) dx=1.$\n\n\n\n<l class=\"definition\"> **Función de distribución de una variable aleatoria** </l>\n\nSea $X$ una v.a. con función de distribución $F_X$. Sea $f:\\mathbb{R}\\to\\mathbb{R}$ una función de densidad tal que\n\n$$F_X(x)=\\displaystyle\\int_{-\\infty}^{x} f_X(t)\\,dt,\\mbox{ para todo } x\\in\\mathbb{R}.$$\n\nEntonces $X$ es una variable aleatoria continua y $f_X$ es la densidad de la v.a.  $X$.\n\n\n\nEl conjunto $D_X=\\{x\\in\\mathbb{R}| f_x(x)>0\\}$ recibe el nombre de <l class=\"definition\"> soporte o dominio de la\nvariable aleatoria continua</l> y se interpreta como su conjunto de resultados posibles.\n\n\n<div class=\"example-sol\">\n**Ejemplo: diana (continuación)**\n\nEn nuestro ejemplo, la función $f$ es una densidad\n\n$$\nf_{X}(x)=\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\n1, & \\mbox{si } 0 < x < 1,\\\\\n0, & \\mbox{si } 1\\leq x,\n\\end{array}\\right.\n$$\nque es la densidad de $X$. En efecto:\n\n* Si $x \\leq 0$, entonces $\\displaystyle\\int_{-\\infty}^x f_X(t) dt = 0.$\n\n* Si $0\\leq x\\leq 1$, entonces $\\displaystyle\\int_{-\\infty}^x f_X(t) dt = \\int_0^x 1\\, dt = x.$\n\n* Si $x\\geq 1$,  entonces $\\displaystyle\\int_{-\\infty}^x f_X(t) dt = \\int_0^1 1\\, dt = 1.$\n\n\nPor lo tanto,  $F_X(x)=\\displaystyle\\int_{-\\infty}^x f_X(t) dt$ para todo $x\\in\\mathbb{R}.$\n\n\n\n\n::: {.cell layout-align=\"center\" fig_caption='Función de densidad de una v.a. uniforme en el intervalo$(0,1)$'}\n\n```{.r .cell-code}\ncurve(dunif(x,0,1),xlim=c(-0.5,1.5),col=\"blue\",\n      main=\"Densidad de la distribución uniforme en [0,1]\")\n```\n\n::: {.cell-output-display}\n![](2_files/figure-pdf/unnamed-chunk-1-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n</div>\n\n### Utilidad de la función de densidad\n\nLa función de densidad nos permite calcular diversas probabilidades.\n\n<l class=\"prop\">**Propiedades de la función de densidad** </l> \n\n* Sea $X$ una v.a. continua con función de distribución $F_X$ y de\ndensidad $f_X$, entonces\n\\begin{eqnarray*}\nP(a< X< b) &=&  P(a<X\\leq b)= P(a\\leq X< b)=\\\\\n & & P(a\\leq X\\leq b)= \\displaystyle\\int_{a}^b f_X(x) dx.\n\\end{eqnarray*}\n\n* Si $A$ es un subconjunto de $\\mathbb{R}$ entonces \n\n$$\nP(X\\in A)=\\displaystyle\\int_{A} f(x) dx=\\displaystyle\\int_{A\\cap D_X} f(x) dx.\n$$\n\n<l class=\"prop\">**Propiedades de la función de densidad** </l> \n\nSea $X$ una v.a. continua con función de distribución $F_X$ y de densidad $f_X$, entonces:\n\n* Si $f_x$ es continua en un punto $x$, $F_X$ es derivable en ese punto y\n$F_X'(x)=f_X(x).$\n* $P(X=x)=0$ para todo $x\\in\\mathbb{R}.$\n  \n\n<div class=\"exercise\"> **Ejercicio**\n\nComprobar estas propiedades en el ejemplo de la diana. \n</div>\n\n\n\n<div  class=\"example\">\n**Ejemplo: tiempo ejecución de un proceso.**\n\nSea $X=$ tiempo de ejecución de un proceso. Se supone que $X$ sigue una distribución uniforme en dos unidades de tiempo, si tarda más el proceso se cancela.\n\nCalculemos la función de densidad y de distribución de la v.a $X$.\n\n\n<div  class=\"example-sol\">\n\nEntonces\n\n$$\nF_{X}(x)=P(X\\leq x)=\\frac{\\mbox{Casos Favorables}}{\\mbox{Casos Posibles}}=\\frac{x}2.\n$$\n\n\nLuego su función de distribución es:\n\n$$\nF_{X}(x)=\\left\\{\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\[1ex]\n\\frac{x}2, & \\mbox{si } 0<x<2,\\\\[1ex]\n1, & \\mbox{si } 2\\leq x.\n\\end{array}\\right.\n$$\n\nSu función de densidad por su lado es:\n$$\nf_{X}(x)=F_{X}'(x)=\\left\\{\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\[1ex]\n\\frac12, & \\mbox{si } 0<x\\leq 2,\\\\[1ex]\n0, & \\mbox{si } 2\\leq x.\n\\end{array}\\right.\n$$\n\nEfectivamente\n\n* $f_{X}(x)\\geq 0,$ y tiene un conjunto finito de discontinuidades: $\\{0,2\\}$.\n* $F_X(x)=\\int_{-\\infty}^x f_X(t) dt,$ para todo $x\\in \\mathbb{R}$. (Ejercicio: resolverlo gráficamente.)\n\n* $\\displaystyle\\int\\limits_{-\\infty}^{+\\infty}f_{X}(x)dx=\\int\\limits_0^2\\frac12dx=\\left[\\frac{x}2\\right]_0^2=\\frac22-\\frac02=1.$\n\n</div>\n</div>\n\n\n<div class=\"exercise\">\n**Ejercicio: tiempo de un proceso**\n\nCalcular la probabilidad de que uno de nuestros procesos tarde\nmás de una unidad de tiempo en ser procesado. Calcular también la  probabilidad de\nque dure entre $0.5$ y $1.5$ unidades de tiempo.\n</div>\n\n\n\n### Esperanza y varianza para variables aleatorias continuas\n\nLos mismos comentarios y definiciones que se dieron en la sección correspondiente del tema\nde estadística descriptiva son aplicables aquí.\n\nAsí que sólo daremos las definiciones, la forma de cálculo y algunos ejemplos.\n\nEn lo que sigue, salvo que diagamos lo contrario,  $X$  es una v.a. continua con función de densidad $f_{X}(x)$\n\n\n\n<l class=\"definition\"> **Esperanza v.a. continuas** </l>\n\n* Su esperanza es:\n$$E(X)=\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} x\\cdot f_{X}(x)dx.$$\n* Si $g(x)$ es una función de la variable $X$ entonces:\n$$E(g(X))=\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} g(x)\\cdot f_{X}(x)dx.$$\n\n<l class=\"definition\"> **Varianza v.a. continuas** </l>\n\n\n* Su varianza es:\n$$\nVar(X)=\\sigma_{X}^2=E((X-\\mu_{X})^2)=\n\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} (x-\\mu_{X})^2 f_{X}(x)dx.\n$$\n* Su desviación típica es:  $$\\sigma_{X}=+\\sqrt{\\sigma_{X}^2}.$$\n\n<l class=\"prop\"> **Propiedades** </l>\n\n* $\\sigma_{X}^2\\geq 0$.\n* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$.\n* $\\displaystyle Var(x)=E(X^2)-\\mu_{X}^2=\\int\\limits_{-\\infty}^{+\\infty}x^2 f_{X}(x)dx - \\mu_{X}^2.$\n* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$.\n\n\n\n\n<div  class=\"example\">\n\n**Ejemplo: diana (continuación)**\n\nCalcular $\\mu_{X}$ y $\\sigma_{X}^2$ en el ejemplo de la diana.\n\n<div  class=\"example-sol\">\nResultado \n$$\\mu_{X}=\\frac12,\\ E(X^2)=\\frac13,\\ Var(X)=\\frac1{12}.$$\n\n</div>\n</div>\n\n\n<l class=\"prop\">**Proposición**</l>\n\nSea $X$ una v.a. continua con $E(X)=\\mu_{X}$ y $Var(X)=\\sigma_{X}^2$ sea $Y=a+b\\cdot X$, donde\n$a,b\\in\\mathbb{R}$, es una nueva v.a. continua obtenida mediante una transformación lineal de $X$.\nSe verifican las mismas propiedades que en el caso discreto:\n\n* $E(Y)=E(a+b\\cdot X)=a+b\\cdot E(X)$.\n* $Var(Y)=Var(a+b\\cdot X)=b^2\\cdot Var(X)$.\n* $\\sigma_{Y}=|b|\\cdot \\sigma_{X}$.\n* $Z=\\frac{X-\\mu_{X}}{\\sigma_{X}}$ es una transformación\nlineal de $X$ de forma que\n$$E(Z)=0 \\mbox{ y } Var(Z)=1.$$\n\n\n<div class=\"example\"> \n**Ejemplo: venta de vinos**\n\nEn una empresa de venta de vinos por internet, sea\n$X$ el número de  litros de vino del país vendidos en un año.\nSupongamos que sabemos que $E(X)=10000$ y que $Var(X)=100$.\nSupongamos que los gastos fijos de distribución son\n50.000 &euro; y el beneficio por litro es de 10 &euro; por botella.\nDefinimos $T=10 X-50000$ que será el beneficio después de gastos.\n\n<div class=\"example-sol\"> \n\nEntonces la esperanza del beneficio es \n$$E(T)=10 E(X)-50000 = 50000,$$\ny\n$$Var(T)=10^2 Var(X)= 10000.$$\n</div>\n</div>\n\n\n## Transformaciones de variables aleatorias\n\nMuchas variables aleatorias son funciones de otras v.a. En lo que sigue resumiremos diversas técnicas para dada una v.a. $X$ y una\ntransformación $Y=h(X)$  encontrar $F_{Y}$ a\npartir de $F_{X}$.\n\n<l class=\"prop\">**Tranformaciones de v.a. discretas** </l>\n\nSea $X$ una v.a. discreta con $X(\\Omega)=\\{x_1,x_2,\\ldots,x_{n},..\\}$ y sea $h:\\mathbb{R}\\to\\mathbb{R}$ una aplicación.\nEntonces $Y=h(X)$ es también una v.a. discreta. Además si $P_X$\ny $F_{X}$ son las funciones de probabilidad y de distribución de\n$X$ entonces\n\n \n* $\\displaystyle P_{Y}(y)=\\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).$\n* $\\displaystyle F_{Y}(y)=\\sum_{x_{i}|h(x_{i})\\leq y} P_X(x_{i}).$\n\n\nDesafortunadamente para variables no discretas, el resultado  no es tan sencillo como la expresión anterior, pues la transformación de, por ejemplo, una v.a. continua puede ser continua, discreta, mixta, $\\ldots$\n\n<l class=\"prop\">**Transformación de v.a. continuas en continuas**</l>\n\nSea $X$ una v.a. continua cuya función de densidad es $f_{X}$. Sea\n$h:\\mathbb{R}\\to\\mathbb{R}$ una aplicación estrictamente monótona y derivable; por lo tanto, $h'(x)\\not=0$ para todo $x\\in\\mathbb{R}$. Sea $Y=h(X)$ la transformación de $X$ por $h$. Entonces $Y$ es una v.a. continua con función de densidad\n\n$$f_{Y}(y)=\\left.\\frac{f_{X}(x)}\n{\\left|h'(x)\\right|}\\right|_{x=h^{-1}(y)}.$$\n\n\n<l class=\"prop\">**Densidad de una transformación de una v.a. continua**</l>\n\nSea $X$ una v.a. continua cuya función de densidad es $f_{X}$.  Sea \n$$h:\\mathbb{R}\\to\\mathbb{R},$$ \nuna aplicación, no necesariamente monótona tal que :\n\n* sea derivable con derivada no nula,\n* la ecuación $h(x)=y$ tiene un número finito de soluciones\n$x_1,x_2,..,x_{n}$,\n\nentonces:\n\n$$\n\\displaystyle f_{Y}(y)=\\left.\\sum_{k=1}^{n} \\frac{f_{X}(x)}\n{\\left|h'(x)\\right|}\\right|_{x=x_{k}}.\n$$\n\n\n**Método general de transformación de v.a.**\n\nCuando no podamos aplicar las propiedades anteriores intentaremos\ncalcular primero la función de distribución de la transformación\ny luego su densidad.\n\nNotemos que en general si $Y=g(X)$ es una v.a. transformación  de la\nv.a. $X$ entonces\n\n$$\nF_{Y}(y)=P(Y\\leq y)=P(g(X)\\leq y).\n$$\n\n\n\nPor ejemplo, si $g$ es estrictamente creciente y continua,\n\n$$\nF_{Y}(y)=P(g(X)\\leq y)=P(X\\leq g^{-1}(y))=F_{X}(g^{-1}(y)),\n$$\ny si $g$ es estrictamente decreciente y continua,\n$$\nF_{Y}(y)=P(g(X)\\leq y)=P(X\\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).\n$$\n\n\n\n## Desigualdades de Markov y de Chebychev\n\nEn esta sección veremos distintas desigualdades que acotan determinadas probabilidades de\nuna variable aleatoria.\n\nEstas desigualdades sirven en algunos casos para acotar probabilidades de determinados sucesos.\n\nTambién son útiles desde el punto de vista teórico, por ejemplo para justificar que la varianza es una medida de la dispersión de\nlos datos.\n\n### Desigualdad de Markov\n\n<l class=\"prop\">**Desigualdad de Markov**</l>\n\nSea $X$ una v.a. positiva con $E(X)$ finita. Entonces \n\n$$P(X\\geq a)\\leq \\frac{E(X)}{a},\\mbox{ para todo }a>0.$$\n\n<div class=\"dem\">\n**Demostración**:\n\nSi $X$ es continua  y solo toma valores positivos\n\n\\begin{eqnarray*}\nE(X) &=& \\int_{-\\infty}^{+\\infty} x\\cdot  f_{X}(x) dx=  \\int_0^{+\\infty} x\\cdot f_{X}(x) dx=  \\int_0^{a} x\\cdot  f_{X}(x) dx +\\int_{a}^{+\\infty} x\\cdot f_{X}(x) dx \\\\\n& &\\geq   \\int_{a}^{+\\infty} x\\cdot\nf_{X}(x) dx \\geq a \\int_{a}^{+\\infty}\nf_{X}(x) dx = a \\cdot  P(X\\geq a),\n\\end{eqnarray*}\nde donde se sigue que \n$$P(X\\geq a)\\leq \\frac{E(X)}{a}.$$\n\n</div> \n\n\n<l class=\"prop\"> **Corolario**</l>\n\nSea $X$ una v.a. con $E(X)$ finita entonces  para todo $a>0$\n\n$$P(|X|\\geq a )\\leq \\frac{E(|X|)}{a}.$$\n<div class=\"exercise\">\n**Ejercicio**\n\nDemuestra el corolario anterior a partir de la desigualdad de Markov.\n</div>\n\n\n### Desigualdad de Chebychev\n\n<l class=\"prop\">**Desigualdad de Chebychev**</l>\n\nLa desigualdad de Chebychev también se denomina  de Chebyshov y en inglés Chebyshev.\n\nSea  $X$ una v.a. con $E(X)=\\mu$ y $Var(X)=\\sigma^2$  entonces para todo $a>0$,\n\n$$P(|X-\\mu|\\geq a)\\leq \\frac{\\sigma^2}{a^2}.$$ \n\n\n\n<div class=\"dem\"> \n**Demostración**\n\nApliquemos la consecuencia de la desigualdad de Markov a la v.a.\nno negativa $Y^2=(X-\\mu)^2$. Entonces\n\n$$\nP(Y^2\\geq a^2) \\leq \n\\frac{E(Y^2)}{a^2}=\\frac{E((X-\\mu)^2)}{a^2}\n= \\frac{Var(X)}{a^2}=\\frac{\\sigma^2}{a^2}.\n$$\nPor otra parte\n\n$$\nP(Y^2\\geq a^2)=P(|Y|\\geq a)= P(|X-\\mu|\\geq a),\n$$\nhecho que, junto con la desigualdad anterior, demuestra el resultado.\n\n</div>\n\n\n<l class=\"observ\"> **Utilidad básica de la desigualdad de Chebychev**</l>\n\nSupongamos que $X$ es una v.a. con $Var(X)=0$. Entonces, aplicando la desigualdad anterior,\n$$P(|X-E(X)|\\geq a )=0,\\mbox{ para todo }a>0,$$ \nlo que implica que\n$$P(X=E(X))=1,$$\npor lo que  probabilidad de que $X$ sea\nconstantemente $E(X)$ es 1, hecho que nos confirma la utilidad de la varianza como una\nmedida de la dispersión de los datos.\n\n\n<div class=\"example\">\n**Ejemplo: tiempo de respuesta**\n\nSe sabe que el tiempo de respuesta medio y la desviación típica de un sistema multiusuario  son 15 y 3 unidades de tiempo, respectivamente. Entonces:\n$$\nP(|X-15|\\geq 5)\\leq \\frac9{25}=0.36.\n$$\n\n</div>\n\nSi substituimos $a$ por $a\\cdot \\sigma$ en la\ndesigualdad de Chebychev, nos queda:\n\n$$\nP(|X-\\mu|\\geq a \\sigma)\\leq\n\\frac{\\sigma^2}{(a\\sigma)^2}=\\frac1{a^2},\n$$\nque es otra manera de expresar la desigualdad de Chebychev.\n\n\n**Más formas de la desgualdad de Chebychev**\n\nLa desigualdad de Chebychev también se puede escribir de al menos dos maneras más:\n\n$$\nP(\\mu-a\\leq X\\leq \\mu+a)\\geq 1-\\frac{\\sigma^2}{a^2},\n$$\ny tomado como $a=k\\cdot \\sigma$,\n$$\nP(\\mu-k\\cdot \\sigma\\leq X\\leq \\mu+ k \\cdot \\sigma)\\geq 1-\\frac1{k^2}.\n$$\n\nTomando la segunda expresión que hemos visto para la desigualdad de\nChebychev para distintos valores de $k>0$, tenemos la siguiente tabla:\n\n| k | $P(|X-E(X)|\\geq k  \\cdot \\sigma)$|\n|---|---|\n| 1 | $\\leq 1$ |\n| 2 | $\\leq 0.25$ |\n| 3 | $\\leq 0.111$ |\n| 4 | $\\leq 0.0025$ |\n\n\n\nPor ejemplo para $k=2$, esta desigualdad se puede interpretar como que, dada una v.a. $X$ con cualquier distribución que tenga $E(X)$ y $Var(X)$ finitos, *la  probabilidad de que un valor se aleje de la media $\\mu$ más de $a=2$ desviaciones típicas es menor o igual que $0.25$*.\n\nEs decir sólo el 25\\% de los valores estarán alejados de la media\nmás de $2\\sigma$, ¡*sea cual sea la distribución de la v.a.*!\n\n## Cuantiles de variables aleatorias\n\nSi  $X$ es una v.a. con dominio $D_X$ y  $0<p<1$, llamaremos cuantil de orden $p$ al menor valor  perteneciente al dominio $x_p\\in D_X$ tal que:\n$$P(X\\leq x_p)\\geq p.$$\n\nEn `R`, cada distribución $X$ tiene la función `qX(p,...)` que devuelve precisamente el cuantil $x_p$ tal que $P(X\\leq x_p)\\geq p.$\n\n\n\nDada una variable aleatoria $X$, si existe la inversa de la función de distribución de $X$, $F_X^{-1}$, el cuantil de orden $p$ sería el valor que tiene la función $F_X^{-1}$ en $p$: $x_p=F^{-1}(p)$.\n\nEn caso de no existir la inversa, dado $p$, definimos el conjunto $A_p$ como:\n\n$$\nA_p =\\{x\\in\\mathbb{R},\\ |\\ F_X(x)\\geq p\\}.\n$$\n\nEntonces el cuantil $p$ es el mínimo del conjunto $A_p$ considerando sólo valores del dominio de la variable: $x_p =\\displaystyle\\min_{x\\in D_X}(A_p)$. Este mínimo siempre existirá y nos da una fórmula explícita para calcular los cuantiles de cualquier variable aleatoria.\n\n\n<div class=\"example\">\n\n**Ejemplo: variable aleatoria que nos da el resultado del lanzamiento de un dado**\n\nSea  $X$ la variable aleatoria uniforme discreta que nos da el número de puntos obtenidos en el lanzamiento de un dado (seis caras numeradas del 1 al 6).\n\nSu dominio  es $D_X=\\{1,2,3,4,5,6\\}$ y su función de probabilidad es \n$$\nP_X(x)=P(X=x)=\n\\left\\{\n\\begin{array}{ll}\n \\frac{1}{6}, & \\mbox{ si } x=1,2,3,4,5,6, \\\\\n0, & \\mbox{ en otro caso. }.\n\\end{array}\n\\right.\n$$\nSu función de distribución es:\n$$\nF_X(x)= P(X\\leq x)=\n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{ si } x<1, \\\\\n\\frac{k}{6} & \\mbox{ si } k\\leq x< k+1 \\mbox{ para } x= 1,2,3,4,5, \\\\\n 1, & \\mbox{si  } x \\geq 6.\n\\end{array}\n\\right.\n$$\n\nLa función siguiente llamada `ddado` nos define la función de probabilidad de $X$ para un dado de $n$ caras:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nddado=function(x,n=6) {\n  sapply(x,FUN=function(x) {\n    if( x %in% c(1:n)){return(1/n)} else {return(0)}})\n  }\n```\n:::\n\n\n\nPor ejemplo, el valor de $P_X(0.5)$ sería:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nddado(0.5,n=6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\ny los valores de $P_X(i)$ para $i=1,\\ldots 10$ sería:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nddado(1:10,n=6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.0000000\n [8] 0.0000000 0.0000000 0.0000000\n```\n:::\n:::\n\n\n\n\nLa función `pdado` nos da la función de distribución de $X$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npdado=function(x,n=6) \n  {\n  sapply(x,FUN=function(y){ if (y<1){ return(0)}else{if(y>=n){return(1)} else\n  {return(sum(ddado(c(1:(floor(y))),n=n)))}}})\n  }\n```\n:::\n\n\n\nLos valores de $F_X(i)$ para $i=0,\\ldots, 11$ serían:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npdado(0:11,6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.0000000 0.1666667 0.3333333 0.5000000 0.6666667 0.8333333 1.0000000\n [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000\n```\n:::\n:::\n\n\n\nA continuación, construímos la función `qdado` que nos calcula el cuantil $p$, para $0\\leq p\\leq 1$, de la variable $X$ como el mínimo del conjunto $A_p$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqdado=function(p,n=6){\nsapply(p,FUN=function(pp=p,nn=n) \n  {\n  if(pp<0 | pp>1) {return(NA)}\n  else {\n  aux=pp>=pdado(1:n,nn)\n  aux\n  ifelse(all(!aux),return(1),return(max(which(pp>=pdado(1:n,nn)))))}}\n)\n}\n```\n:::\n\n\n\n\nSi $p=1.5$ o $p=-1$, la función anterior nos devuelve `NA` ya que ni 1.5 ni -1 están entre 0 y 1:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqdado(1.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n\n```{.r .cell-code}\nqdado(-1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n:::\n\n\n\nLos cuantiles $x_{0.1}$, $x_{0.5}$ $x_{0.6}$ y $x_1$ son:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqdado(c(0.1,0.5,0.6,1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 3 3 6\n```\n:::\n:::\n\n\n\n</div>\n\n\n",
    "supporting": [
      "2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}