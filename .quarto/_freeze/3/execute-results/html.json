{
  "hash": "e7b06d4226140a5a6cac2ed2969e9b8a",
  "result": {
    "markdown": "# Distribuciones Notables\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'reticulate' was built under R version 4.3.1\n```\n:::\n:::\n\n\n\n\n\n\nEn este tema estudiaremos diversos tipos de experimentos que son muy frecuentes y algunas de las variables aleatorias asociadas a ellos. \n\nEstas variables reciben distintos nombres que aplicaremos sin distinción al tipo de población del experimento, a la variable o a su función de probabilidad, densidad o distribución.\n\nEmpezaremos con las variables aleatorias discretas que se presentan con frecuencia, ya que están relacionadas con situaciones muy comunes como el número de caras en varios lanzamiento de una moneda, el número de veces que una maquina funciona hasta que se estropea, el número de clientes en una cola...\n\n\n## Distribuciones discretas\n\n### Distribución de Bernoulli \n\nConsideremos un experimento con dos resultados posibles: éxito (E) y\nfracaso (F). El espacio de sucesos será $\\Omega=\\{E,F\\}$.\n\nSupongamos que la probabilidad de éxito es  $P(E)=p$,  y naturalmente $P(F)=1-p=q$, con $0<p<1$.\n\nConsideremos la  aplicación \n\n$$\nX:\\Omega=\\{E,F\\}\\to \\mathbb{R},\n$$\ndefinida por $X(E)=1,\\ X(F)=0.$\n\nSu  función de probabilidad es:\n$$\nP_{X}(x)=\n\\left\\{\n\\begin{array}{ll} 1-p=q, & \\mbox{si } x=0,\\\\\np, & \\mbox{si } x=1,\\\\\n0, & \\mbox{en cualquier otro caso.}\n\\end{array}\n\\right.\n$$\n\nSu función de distribución es:\n$$\nF_{X}(x)=P(X\\leq x)=\n\\left\\{\n\\begin{array}{ll} \n0, & \\mbox{si } x<0,\\\\\n1-p=q, & \\mbox{si } 0\\leq x <1,\\\\\n1, & \\mbox{si } 1\\leq x. \\\\\n\\end{array}\n\\right.\n$$\nBajo estas condiciones, diremos que $X$  **es una v.a. Bernoulli** o que  sigue una ley de  **distribución de probabilidad Bernoulli** de parámetro $p$.\n\nLo denotaremos por $X\\equiv Ber(p)$ o también $X\\equiv B(1,p).$\n\nA este tipo de  experimentos (éxito/fracaso) se les denomina experimentos Bernoulli.\n\nFue su descubridor un científico suizo  [Jacob Bernoulli](https://es.wikipedia.org/wiki/Jakob_Bernoulli),  uno más de la de la conocida [familia de científicos suizos Bernoulli](https://es.wikipedia.org/wiki/Familia_Bernoulli).\n\n**Esperanza de una v.a. $X$  $Ber(p)$**\n\nSu **valor esperado** es:\n$$E(X)=\\displaystyle\\sum_{x=0}^1 x\\cdot P(X=x)= 0\\cdot(1-p)+1\\cdot p=p.$$\nCalculemos también $E(X^2)$:\n\n$$E(X^2)=\\displaystyle\\sum_{x=0}^1 x^2\\cdot P(X=x)= 0^2\\cdot(1-p)+1^2\\cdot p=p.$$\n**Varianza de una v.a. $X$  $Ber(p)$**\n\n\nSu **varianza** es:\n\n$$Var(X)=E(X^2)-\\left(E(X)\\right)^2=p-p^2=p\\cdot (1-p)=p\\cdot q.$$\nSu desviación típica es:\n$$\n\\sqrt{Var(X)}=\\sqrt{p \\cdot (1-p)}.\n$$\n\n**Resumen v.a con distribución Bernoulli**\n\n$X$  Bernoulli | $Ber(p)$\n----------:|:--------\n$D_X=$ | $\\{0,1\\}$\n$P_X(x)=P(X=x)=$ |  $\\left\\{\\begin{array}{ll} q & \\mbox{si } x=0\\\\ p & \\mbox{si } x=1\\\\0 & \\mbox{en otro caso}\\end{array}\\right.$ \n$F_X(x)=P(X\\leq x)=$ | $\\left\\{\\begin{array}{ll} 0 & \\mbox{ si } x<0\\\\q & \\mbox{ si } 0\\leq x<1\\\\1 & \\mbox{ si } 1\\leq x \\end{array}\\right.$\n$E(X)=p$ | $Var(X)=p\\cdot q$\n\n\n\n\n\n\n<div class=\"example\">\n**Ejemplo de Distribución Bernoulli**\n\nVeamos los cálculos básicos usando la distribución $Ber(p=0.25)$ en `R`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(0,size=1,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.75\n```\n:::\n\n```{.r .cell-code}\ndbinom(1,size=1,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.25\n```\n:::\n\n```{.r .cell-code}\nrbinom(n=20,size = 1,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n```\n:::\n:::\n\n\nEl siguiente código dibuja las función de probabilidad y la de distribución de una  $Ber(p=0.25)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nplot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=0.25),\n     ylim=c(0,1),xlim=c(-1,2),xlab=\"x\",\n     main=\"Función de probabilidad\\n Ber(p=0.25)\")\nlines(x=c(0,0,1,1),y=c(0,0.75,0,0.25), type = \"h\", lty = 2,col=\"blue\")\ncurve(pbinom(x,size=1,prob=0.25),\n      xlim=c(-1,2),col=\"blue\",\n      main=\"Función de distribución\\n Ber(p=0.25)\")\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n**Gráficas interactivas $Ber(p)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsliderInput(\"p_ber\", label = \"Probabilidad éxito p:\",\n              min = 0.01, max = 0.99, value = 0.25, step = 0.01)\n\nrenderPlot({\npar(mfrow=c(1,2))\n  p=input$p_ber\nplot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=p),\n     ylim=c(0,1),xlim=c(-0.5,2),xlab=\"x\",pch=21,\n     main=paste0(c(\"Función de probabilidad\\n\n                   Ber(p=\",p,\")\"),collapse=\"\"),bg=\"black\")\nsegments(x0=0,y0=0,x1=0,y1=1-p, col = \"blue\", lty =2)\nsegments(x0=1,y0=0,x1=1,y1=p, col = \"blue\", lty =2)\nsegments(x0=-1,y0=1-p,x1=0,y1=1-p, col = \"blue\", lty =2)\nsegments(x0=-1,y0=p,x1=1,y1=p, col = \"blue\", lty =2)\nx=0:1\ny=pbinom(x,size=1,prob=p)\ncurve(pbinom(x,size=1,prob=p),\n      xlim=c(-1,2),col=\"blue\",\n      main=paste0(c(\"Función de distribución\\n Ber(p=\",p,\")\"),collapse=\"\")\n      )\n\npar(mfrow=c(1,1))\n})\n```\n:::\n\n\n\n<!--[![](Images/noshinyImages/interactiva_ber1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n</div>\n\n### Distribución binomial\n\nSi repetimos $n$ veces de forma independiente un experimento Bernoulli de parámetro $p$, el espacio muestral $\\Omega$ estará formado por cadenas de $E$'s y $F$'s de longitud $n$.\nConsideremos la v.a.:\n$$X(\\overbrace{EFFF\\ldots EEF}^{n})=\\mbox{número de éxitos en la cadena}.$$\nA la variable aleatoria anterior se la conoce como distribución binomial de parámetros $n$ y $p$, y lo denotaremos por $X\\equiv B(n,p).$\n\n**Función de probabilidad de una  binomial**\n\nSu **función de probabilidad** es:\n$$\nP_{X}(x)=\\left\\{\n\\begin{array}{ll}\n{n\\choose x}\\cdot  p^x \\cdot(1-p)^{n-x}, &\\mbox{ si } x=0,1,\\ldots,n,\\\\\n0,  & \\mbox{ en otro caso.}\n\\end{array}\\right.\n$$\n**Función de distribución de una binomial**\n\nSu **función de distribución** no tiene una fórmula cerrada. Hay que acumular la función de probabilidad:\n$$\n\\begin{array}{ll}\nF_{X}(x)=P(X\\leq x) & =  \\sum_{i=0}^x P_X(i)\\\\\n& = \n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{ si } x\\leq 0,\\\\\\displaystyle\n\\sum_{i=0}^k {n\\choose i}\\cdot  p^i \\cdot (1-p)^{n-i} & \\mbox{ si } \n\\left\\{\n  \\begin{array}{l} \n  k\\leq x< k+1,\\\\\n  k=0,1,\\ldots,n,\n  \\end{array}\n\\right.\\\\\n1, & \\mbox{ si } n\\leq x.\n\\end{array}\n\\right.\n\\end{array}\n$$\n\n\n\n**Números binomiales con R**\n\nLos números binomiales calculan el número de equipos de baloncesto distintos que  ($k=5$ jugadores) se pueden hacer con 6 jugadores ($n=6$).\n\nEs decir, cuántas  maneras distintas hay para elegir (*choose*) 5 jugadores en un conjunto de 6 jugadores. Todo el mundo diría \n¡¡¡6!!! Efectivamente con `R` es \n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(6,5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6\n```\n:::\n:::\n\n\nCon 10 jugadores, el número de equipos de  5 distintos es bastante más grande\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(10,5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 252\n```\n:::\n:::\n\n\nY, por ejemplo, con un equipo de fútbol profesional  que tiene en plantilla 22 jugadores  (quitando los guardametas) se pueden formar ¡¡nada menos que!!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(22,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 646646\n```\n:::\n:::\n\nun bonito número capicúa que nos da el número de equipos distintos que se pueden formar.\n\nObviamente se tiene que una v.a. Bernoulli es una binomial con $n=1$:\n$B(1,p)=Ber(p).$\n\n<div class=\"exercise\"> \n**Ejercicio**\n\nCalculad las funciones de distribución de una binomial $B(n=1,p=0.3)$ y comprobad que coinciden con  las distribuciones de una $Ber(p=0.3)$.\n</div>\n\n**Observaciones sobre la distribución binomial**\n\n* La probabilidad de fracaso se suele denotar con  $q=1-p$, **sin ningún aviso adicional**, con el fin de acortar  y agilizar la escritura de las  fórmulas.\n* Su **función de distribución no tienen una formula general**, hay que calcularla con una función de `R` o `Python`. En el siglo pasado se tabulaban en los libros de papel :-).\n* En el material adicional os pondremos unas tablas de esta distribución\npara distintos valores de $n$ y $p$ para que disfrutéis de tan ancestral método de cálculo. \n* Cualquier paquete estadístico u hoja de cálculo dispone de\nfunciones para el cálculo de estas probabilidades, así que el **uso de las tablas** queda **totalmente anticuado**. \n\n**Esperanza  de una $B(n,p)$**\n\nSu **esperanza** es: \n$$E(X)=\\displaystyle\\sum_{k=0}^n k \\cdot  {n \\choose k }\\cdot p^k\\cdot q^{n-k} = n\\cdot p.$$\nLa esperanza de $X^2$ es:\n$$\nE(X^2)= \\displaystyle\\sum_{k=0}^n k^2 \\cdot  {n \\choose k }\\cdot p^k\\cdot q^{n-k}= n\\cdot p\\cdot q+(n\\cdot p)^2.\n$$\n\n**Varianza de una $B(n,p)$**\n\nSu **varianza** es:\n\n $$Var(X)=E(X^2)-\\left(E(X)\\right)^2=n\\cdot p \\cdot q=n\\cdot p\\cdot (1-p).$$\n\nSu desviación típica es:\n \n$$\\sqrt{n\\cdot p\\cdot q}=\\sqrt{n\\cdot p\\cdot (1-p)}.$$\n \nEn temas posteriores veremos una forma sencilla del cálculo de la esperanza y varianza de una $B(n,p)$ como las suma de $n$ v.a. $Ber(p)$ independientes.\n\n<div class=\"exercise\">\n**Ejercicio**\n\nJustificar de forma intuitiva que si $X_i$ con $i=1,2,\\ldots, n$ son v.a. $Ber(p)$ independientes  entonces $X=\\displaystyle\\sum_{i=1}^n X_i$ sigue una distribución $B(n,p).$ \n</div>\n\n\n**Resumen v.a con distribución binomial $B(n,p)$**\n\n$X$ binomial | $B(n,p)$ |\n-------------:|:--------|\n$D_X=$ |  $\\{0,1,\\ldots n\\}$ |\n$P_X(x)=P(X=x)=$ |$\\left\\{\\begin{array}{ll}{n\\choose x}  p^x  (1-p)^{n-x} & \\mbox{si } x=0,\\dots,n\\\\0  & \\mbox{ en otro caso.}\\end{array}\\right.$|\n$F_X(x)=P(X\\leq x)=$ | no tiene fórmula (utilizad funciones de `R` o `Python`)|\n$E(X)=n\\cdot p$ | $Var(X)=n\\cdot p \\cdot (1-p)$|\n\n**Cálculos de la distribución Binomial con `R`**\n\nVeamos los cálculos básicos con funciones de `R` para una v.a $X$ con distribución  binomial  $B(n=10,p=0.25)$. \n\nSi queremos calcular con `R` algún valor de la función de distribución, como por ejemplo $F_X(0)=P(X\\leq 0)$, tenemos que hacer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(0,size=10,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05631351\n```\n:::\n:::\n\ny si queremos por ejemplo $F_X(4)=P(X\\leq 4)$, tenemos que hacer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(4,size=10,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9218731\n```\n:::\n:::\n\n\nSin embargo, si queremos calcular algún valor de la función de probabilidad, como por ejemplo $P(X=0)$, tenemos que hacer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(0,size=10,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05631351\n```\n:::\n:::\n\n\no, por ejemplo para  $P(X=4)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(4,size=10,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.145998\n```\n:::\n:::\n\n\n**Generación de muestras aleatorias con R**\n\nGeneraremos una muestra aleatoria  de  100 valores de una población con distribución $B(20,0.5)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2019)\nrbinom(100,size = 20,prob=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 12 11  9 11  6  6 12  5  7 11 12 11  8  8 11 11  7 11  9 10  9 10 14  8  8\n [26]  5 11 14 11 10 11  5 12  8  6  7  9 10  5 12 11  9 12 11 12 10 13 13  8  8\n [51]  9  7  6  9 10  9 16 13  6  6  8  8 11  9 12 15  9  7 12 11  9  8  9  8 11\n [76] 15  7 10  9 12  6 13 14  8 10  8 10 11 11  9 10 11 12  8 10 12  9 13  9 13\n```\n:::\n:::\n\n\n<div class=\"example\"> \n**Ejemplo**\n\nEl ejemplo anterior correspondería a repetir 100 veces el experimento de lanzar una moneda  20 veces y contar el número de caras.\n</div>\n\n**Cálculos de la distribución Binomial con `Python`**\n\nVeamos los cálculos básicos con funciones de `Pyython` para una v.a $X$ con distribución  binomial $B(n=10,p=0.25)$.\n\nPrimero importamos la  función `binom` de la librería `scipy.stat`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nfrom scipy.stats import binom\n```\n:::\n\n\nEn general, en el paquete `scipy`, la función de probabilidad se invocará con el método `pmf`, la de distribución con el método `cdf`, mientras que una muestra aleatoria que siga esta distribución, con el método `rvs`. En todos ellos aparecerá siempre el parámetro `loc` que se utiliza para desplazar el dominio de la variable aleatoria. Por ejemplo, en este caso:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.pmf(k, n, p, loc) =  binom.pmf(k - loc, n, p)\n```\n:::\n\n\n\nPara calcular los valores de la función de distribución como por ejemplo $F_X(0)=P(X\\leq 0)$ y $F_X(4)=P(X\\leq 4)$ utilizamos la función `cdf`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.cdf(0,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.056313514709472684\n```\n:::\n\n```{.python .cell-code}\nbinom.cdf(4,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9218730926513672\n```\n:::\n:::\n\n\nNotemos que al no indicar el valor de `loc`, se le asume que toma el valor 0.\n\nPara calcular los valores de la función de probabilidad $P(X=0)$ y $P(X=4)$ utilizamos la función `pmf`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.pmf(0,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.056313514709472656\n```\n:::\n\n```{.python .cell-code}\nbinom.pmf(4,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.14599800109863284\n```\n:::\n:::\n\n\nNotemos que al no indicar el valor de `loc`, se le asume que toma el valor 0.\n\nSi queremos generar una muestras aleatorias que siga una distribución binomial, podemos usar la función `rvs`. En este caso, generaremos una muestra aleatoria  de  100 valores  de una población $B(20,0.5)$\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.rvs(n=20,p=0.25,size = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 5,  3,  4,  3,  6,  6,  6,  7,  7,  4,  4,  2,  2,  1,  6,  4,  7,\n        2,  3, 10,  5,  2,  2,  4,  7,  5,  4,  5,  6,  5,  4,  6,  5,  9,\n        3,  5,  2,  3,  7,  4,  4,  2,  7,  5,  3,  6,  5,  2,  4,  6,  6,\n        4,  5,  5,  8,  2,  3, 14,  6,  8,  7,  5,  5,  4,  4,  7,  7,  6,\n        5,  2,  7,  5,  6,  5,  5,  4,  5,  0,  5, 10,  4,  9,  2,  6,  3,\n        5,  7,  6,  0,  5,  8,  4,  3,  8,  3,  4,  4,  5,  1,  3],\n      dtype=int64)\n```\n:::\n:::\n\n\n\n\n<l class=\"observ\"> **Observación**</l>\n\nNotemos que la secuencia aleatoria generada no es la misma que con `R`. De hecho, si volvemos a ejecutar esta función obtendremos una muestra aleatoria distinta.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.rvs(n=20,p=0.25,size = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 4,  2, 10,  5,  2,  7,  4,  4,  9,  5,  4,  3,  7,  8,  6,  4,  6,\n        7, 11,  9,  6,  6,  6,  6,  1,  6,  4,  5,  6,  7,  4,  4,  6,  5,\n        3,  6,  6,  7,  9,  5,  5,  7,  6,  8,  6,  4,  4,  1,  5,  4,  5,\n        6,  8,  4,  5,  4,  1,  7,  5,  4,  7,  2,  3,  6,  8,  4,  7,  8,\n        7,  1,  4,  6,  5,  4,  4,  3, 10,  4,  5,  6,  3,  7,  5,  3,  5,\n        6,  6,  5,  3,  5,  7,  4,  7,  1,  4,  3,  4,  4,  4,  4],\n      dtype=int64)\n```\n:::\n:::\n\n</div>\n\n\n\n\nVeamos algunos cálculos básicos con funciones de `Python` para la binomial  $B(n=10,p=0.25)$.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbinom.cdf(5,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9802722930908203\n```\n:::\n\n```{.python .cell-code}\nbinom.pmf(1,n=10,p=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.1877117156982421\n```\n:::\n\n```{.python .cell-code}\nbinom.rvs(n=20,p=0.25,size=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([8, 2, 5, 5, 5, 7, 5, 5, 7, 7], dtype=int64)\n```\n:::\n:::\n\n\n**Gráficas de la distribución Binomial con `R`**\n\nEl siguiente código de `R` dibuja las función de probabilidad y la de distribución de una  $B(n=10,p=0.25)$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\naux=rep(0,22)\naux[seq(2,22,2)]=dbinom(c(0:10),size=10,prob=0.25)\nplot(x=c(0:10),y=dbinom(c(0:10),size=10,prob=0.25),\n  ylim=c(0,1),xlim=c(-1,11),xlab=\"x\",\n  main=\"Función de probabilidad\\n B(n=10,p=0.25)\")\nlines(x=rep(0:10,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\ncurve(pbinom(x,size=10,prob=0.25),\n  xlim=c(-1,11),col=\"blue\",\n  main=\"Función de distribución\\n B(n=10,p=0.25)\")\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n**Gráficas interactivas de la distribución Binomial**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(6,\n         sliderInput(\"n_binom\", label = \"Número de repeticiones n:\",\n              min = 1, max = 50, value =10 , step = 1)),\n  column(6,\n          sliderInput(\"p_binom\", label = \"Probabilidad éxito p:\",\n                     min = 0.01, max = 0.99, value = 0.25, step = 0.01)\n         )\n  )\n)\n\nrenderPlot({\n  n=input$n_binom\n  pr=input$p_binom\n  \n  par(mfrow=c(1,2))\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dbinom(c(0:n),size=n,prob=pr)\n  plot(x=c(0:n),y=dbinom(c(0:n),size=n,prob=pr),\n       ylim=c(0,1),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Función de probabilidad\\n B(n=\",n,\",p=\",pr,\")\"),collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\n  curve(pbinom(x,size=n,p=pr),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Función de distribución\\n B(n=\",n,\",p=\",pr,\")\"),\n                    collapse = \"\"))\n        par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_bino1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n**Gráficos de la distribución binomial con `Python`**\n\n<div class=\"exercise\">\n**Ejercicio**\n\nBuscad en la documentación de `Python` cómo se dibuja la función de probabilidad y de distribución de una binomial y recread los gráficos anteriores.\n\n<div class=\"exercise-sol\">\nPista: Necesitaremos investigar más librerías:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nn, p = 10, 0.25\nx = np.arange(binom.ppf(0.01, n, p),binom.ppf(0.99, n, p))\nfig =plt.figure(figsize=(5, 2.7))\nax = fig.add_subplot(1,2,1)\nax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\nax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5) \nax = fig.add_subplot(1,2,2)\nax.plot(x, binom.cdf(x, n, p), 'bo', ms=8, label='binom pmf')\nax.vlines(x, 0, binom.cdf(x, n, p), colors='b', lw=5, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfig.suptitle('Distribucion Binomial')\nplt.show()\n```\n:::\n\n\n\n\n<div class=\"center\"> \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n<string>:2: MatplotlibDeprecationWarning: The label function was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use Tick.label1 instead.\n```\n:::\n\n::: {.cell-output-display}\n![](3_files/figure-html/dibu_python2-1.png){width=480}\n:::\n:::\n\n</div>\n</div>\n</div>\n\n<div class=\"example\">\n**Ejemplo: número de bolas rojas extraídas de una urna con reposición**\n\nTenemos una urna con $100$ bolas de las cuales 40 son rojas y 60 son blancas. Extraemos al azar una bola, anotamos su color y la devolvemos a (reponemos en) la urna.\n\nSupongamos que repetimos este proceso $n=10$ reponiendo en cada ocasión la bola extraída. \n\nConsideremos la variable aleatoria $X$ como el número de bolas rojas extraídas (con reposición) en $n=10$ repeticiones del mismo experimento de Bernoulli.\n\nBajo estas condiciones repetimos $n=10$ veces el mismo experimento de Bernoulli con probabilidad de éxito (sacar bola roja)\n$$P(Roja)=P(Éxito)=p=\\frac{40}{100}=0.4.$$\n\nAsí que la variable $X$, que es el número de bolas rojas extraídas de la urna (con reposición) en $n=10$ ocasiones, sigue una ley binomial  $B(n=10,p=0.4).$\n\nNos preguntamos:\n\n1. ¿Cuál es la probabilidad de que saquemos exactamente $4$ bolas rojas?\n2. ¿Cuál es la probabilidad de que saquemos al menos  $4$ bolas rojas?\n3. ¿Cuál es la probabilidad de que saquemos  menos de $3$ bolas rojas?\n4. ¿Cuál es el valor esperado del número de bolas rojas?\n5. ¿Cuál es la desviación típica  del número de bolas rojas?\n\n\n\n\n\n<div class=\"example-sol\">\n \n**Solución 1**. ¿Cuál es la probabilidad de que saquemos exactamente $4$ rojas?\n\nUtilizando la función de probabilidad, tenemos que:\n$$\n\\begin{array}{ll}\nP(X=4)&={10\\choose 4}\\cdot 0.4^4\\cdot (1-0.4)^{10-4}\n= \\frac{10!}{(10-4)!\\cdot 4!}\\cdot 0.4^4\\cdot 0.6^6\\\\\n&= \\frac{7\\cdot 8\\cdot 9\\cdot 10}{1\\cdot 2\\cdot 3\\cdot 4}\\cdot 0.4^4\\cdot 0.6^6=0.2508227.\n\\end{array}\n$$\n\nCon `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(4,size=10,prob = 0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2508227\n```\n:::\n:::\n\n</div>\n\n\n\n\n<div class=\"example-sol\">\n**Solución 2**.  ¿Cuál es la probabilidad de que saquemos al menos $4$ bolas rojas?\n\nLa probabilidad de sacar al menos 4 rojas se expresa como $P(X \\geq  4)=1-P(X<4)=1-P(X\\leq 3):$\n$$\n\\begin{array}{rl}\nP(X\\leq 3)& = P(X=0)+P(X=1)+P(X=2)+P(X=3)\\\\\n&= \n {10\\choose 0}\\cdot 0.4^0\\cdot (1-0.4)^{10-0}+ {10\\choose 1}\\cdot 0.4^1\\cdot (1-0.4)^{10-1}\\\\\n&+{10\\choose 2}\\cdot 0.4^2\\cdot (1-0.4)^{10-2}+ {10\\choose 3}\\cdot 0.4^3\\cdot (1-0.4)^{10-3}\\\\\n&=0.3822806.\n\\end{array}\n$$\n\nCon `R`:\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(3,10,0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3822806\n```\n:::\n:::\n\n\n\nAsí que\n\n$$P(X \\geq 4 )=1-P(X< 4)=P(X\\leq 3)=1-0.3822806=0.6177194.$$\n\nOtra manera usando `R` sería:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pbinom(3,10,0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6177194\n```\n:::\n:::\n\n\nAunque en estos casos el parámetro `lower.tail = FALSE` es sin duda nuestra mejor opción: \n\n\n::: {.cell}\n\n```{.r .cell-code}\npbinom(3,10,0.4,lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6177194\n```\n:::\n:::\n\n</div>\n\n\n<div class=\"example-sol\">\n\n**Solución 3**.  ¿Cuál es la probabilidad de que saquemos  menos  de $3$ bolas rojas?\n\n$$\n\\begin{array}{ll}\nP(X< 3)&= P(X\\leq 2)=  P(X=0)+P(X=1)+P(X=2)\\\\\n&=\n{10\\choose 0}\\cdot 0.4^0\\cdot (1-0.4)^{10-0}+ {10\\choose 1}\\cdot 0.4^1\\cdot (1-0.4)^{10-1}\\\\\n&+\n{10\\choose 2}\\cdot 0.4^2\\cdot (1-0.4)^{10-2}\\\\\n&=0.1672898.\n\\end{array}\n$$\n\nEn `R`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(0,10,0.4)+dbinom(1,10,0.4)+dbinom(2,10,0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1672898\n```\n:::\n\n```{.r .cell-code}\npbinom(2,10,0.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1672898\n```\n:::\n:::\n\n</div>\n\n\n\n<div class=\"example-sol\">\n\n**Solución 4**. ¿Cuál es el valor esperado del número de bolas rojas?\n\nComo  $X$ es una $B(n=10,p=0.4)$ sabemos que \n\n$$E(X)=n\\cdot p = 10\\cdot 0.4=4.$$\n\nAunque en `Python` tenemos la función `stats` que nos lo calcula directamente:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(\"E(X) = {m}\".format(m=binom.stats(n = 10, p = 0.4, moments='m')))\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-20-1.png){width=480}\n:::\n:::\n\n\n</div>\n\n\n<div class=\"example-sol\">\n**Solución 5**. ¿Cuál es la desviación típica  del número de bolas rojas?\n\n\nLa varianza es:\n$$\nVar(X)=n\\cdot p \\cdot(1-p)=10\\cdot 0.4\\cdot 0.6=2.4.\n$$\nPor lo  tanto, la desviación típica es:\n\n$$\\sqrt{Var(X)}=\\sqrt{2.4}= 1.5491933.$$\n\nAunque en `Python` tenemos la función `stats` que nos lo calcula directamente:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(\"Var(X) = {v}\".format(v=binom.stats(n = 10, p = 0.4, moments='v')))\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-21-3.png){width=480}\n:::\n:::\n\n\n</div>\n</div>\n\n### Distribución geométrica\n\nTodos hemos jugado a, por ejemplo, tirar una moneda hasta que obtengamos la primera cara.\n\nO también tirar una pelota a una canasta de baloncesto hasta obtener la primera canasta.\n\nDesde otro punto de vista, también podemos intentar modelar el número de veces que accionamos una interruptor y la bombilla se ilumina hasta que falla. \n\nO también, el número de veces que un cajero automático nos da dinero hasta que falla.\n\nLa **modelización de este tipo de problemas se consigue con la llamada distribución geométrica**.\n\n\n<l class=\"definition\"> **Distribución geométrica** </l>\n\nRepitamos un experimento Bernoulli, de parámetro $p$, de forma independiente hasta obtener el primer éxito.\n\nSea $X$ la v.a. que cuenta el número de fracasos antes del primer éxito. Por ejemplo,  que  hayamos tenido  $x$ fracasos  será una cadena de $x$ fracasos culminada con un éxito. Más concretamente \n\n$$P(\\overbrace{FFF\\ldots F}^{x}E)=P(F)^{x}\\cdot P(E)=(1-p)^{x}\\cdot p=q^{x}\\cdot p.$$\nSu función de probabilidad es:\n$$\nP_X(x)=P(X=x)=\\left\\{\\begin{array}{ll}\n(1-p)^{x}\\cdot p, & \\mbox{ si } x=0,1,2,\\ldots,\\\\\n0, &\\mbox{ en otro caso.}\n\\end{array}\\right.\n$$\nLa v.a. definida anteriormente diremos que sigue una distribución geométrica de parámetro $p$. La  denotaremos por $Ge(p)$. \nSu dominio será: $D_X=\\{0,1,2,\\ldots\\}$.\n\nCalculemos como ejemplo P($X\\leq 3$).\nPor la propiedad de la probabilidad del suceso complementario tenemos que\n\n$$\nP(X\\leq 3 )=1-P(X> 3)=1-P(X\\geq 4)\n$$\n\nEfectivamente, el complementario del evento $X\\leq 3$ nos dice que hemos fracasado más de tres veces hasta conseguir el primer éxito, es decir, **hemos fracasado 4 o más veces**. Podemos simbolizar dicho evento de la forma siguiente:\n$$\n\\{X>3\\}=\\{X\\geq 4\\}= \\{FFFF\\}\n$$\n\n\nAhora, al  ser los intentos independientes, tenemos que:\n$$\n\\begin{array}{ll}\nP(X>3) & =  P(\\{FFFF\\})= P(F)\\cdot P(F)\\cdot P(F)\\cdot P(F)\\\\\n&= (1-p)\\cdot (1-p)\\cdot (1-p)\\cdot (1-p)= (1-p)^{3+1}=(1-p)^{4}.\n\\end{array}\n$$\n\nEl valor de la función de distribución de $X$ en $x=3$ será, pues:\n$$F_X(3)=P(X\\leq 3)=1-P(X>3)=1-(1-p)^{3+1}.$$\nGeneralizando el resultado anterior a cualquier entero positivo $k=0,1,2,\\ldots$, tenemos:\n$$F_X(k)=P(X\\leq k)=1-(1-p)^{k+1},\\mbox{ si } k=0,1,2,\\ldots$$\n\nEn general, tendremos que:\n$$\nF_X(x)=P(X\\leq x)=\n\\left\\{\\begin{array}{ll} \n0, & \\mbox{ si } x<0,\\\\\n1- (1-p),  & \\mbox{ si } k=0\\leq x <1,\\\\\n1- (1-p)^2, & \\mbox{ si } k=1\\leq x <2,\\\\\n1- (1-p)^3, & \\mbox{ si } k=2\\leq x <3,\\\\\n1- (1-p)^{k+1}, & \\mbox{ si } \\left\\{ \\begin{array}{l}k\\leq x< k+1,\\\\\\mbox{para } k=0,1,2,\\ldots\\end{array}\n    \\right.\\end{array}\\right.\n$$\nDe forma más compacta, tendremos que \n$$\nF_X(x)=P(X\\leq x)=\n\\left\\{\\begin{array}{ll} \n0, & \\mbox{ si } x<0,\\\\\n1- (1-p)^{k+1}, & \\mbox{ si } \\left\\{ \\begin{array}{l}k\\leq x< k+1,\\\\\\mbox{para } k=0,1,2,\\ldots\\end{array}\n    \\right.\\end{array}\n    \\right.\n$$\n\nNotemos que el límite de la función de distribución es:\n$$\n\\displaystyle\\lim_{k\\to +\\infty } F_X(k)=\\lim_{k\\to +\\infty } 1-(1-p)^{k+1}=\n1,\n$$\nya que $0<1-p<1$.\n\n\n**Sumas derivadas series geométricas**\n\nRecordemos las propiedades siguientes del tema de variables aleatorias:\n\n* Si $|r|<1$  también son convergentes las derivadas, respecto de $r$, de la serie geométrica y convergen a la derivada correspondiente. Así, tenemos que:\n$$\n\\begin{array}{ll}\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)' &= \\sum_{k=1}^{+\\infty}k\\cdot\nr^{k-1}\\\\\n&= \\left(\\frac{1}{1-r}\\right)'=\\frac{1}{(1-r)^2}.\\\\\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)^{''} &= \\sum_{k=2}^{+\\infty}k \\cdot(k-1)\\cdot r^{k-2} \\\\\n&= \\left(\\frac{1}{1-r}\\right)^{''}=\\frac{2}{(1-r)^3}.\n\\end{array}\n$$\n\n\n**Esperanza de una v.a. $Ge(p)$**\n\nRecordemos que $P(X=x)=(1-p)^x\\cdot p$ si $x=0,1,2,\\ldots$ y aplicado la fórmula anterior con $r=1-p$, tenemos:\n$$\n\\begin{array}{rll}\nE(X)&=&\\sum_{x=0}^{+\\infty} x\\cdot P_x(x)=\\sum_{x=0}^{+\\infty} x\\cdot (1-p)^x\\cdot p=\np\\cdot (1-p) \\cdot \\sum_{x=1}^{+\\infty} x\\cdot (1-p)^{x-1}\\\\\n&=& p\\cdot (1-p)\\cdot \\frac{1}{(1-(1-p))^2}=p\\cdot (1-p)\\cdot \\frac{1}{p^2}=\\frac{1-p}{p}.\n\\end{array}\n$$\n\n**Valor $E(X^2)$ de una v.a. $Ge(p)$**\n\n$$\n\\begin{array}{rll}\nE(X^2)&=&\\sum_{x=0}^{+\\infty} x^2\\cdot P_X(x)=\\sum_{x=1}^{+\\infty} x^2\\cdot (1-p)^x\\cdot p\\\\\n&=& \n\\sum_{x=1}^{+\\infty} (x\\cdot (x-1)+x)\\cdot (1-p)^{x}\\cdot p\\\\\n&=&\n\\sum_{x=1}^{+\\infty} x\\cdot (x-1)\\cdot (1-p)^{x}\\cdot p+\\sum_{x=1}^{+\\infty} x \\cdot (1-p)^{x}\\cdot p\\\\\n&=&\n(1-p)^{2}\\cdot p\\cdot \\sum_{x=2}^{+\\infty} x\\cdot (x-1)\\cdot (1-p)^{x-2}\\\\ \n& & +    (1-p)\\cdot p\\sum_{x=1}^{+\\infty} x \\cdot (1-p)^{x-1} \n\\\\  &=&\n(1-p)^{2}\\cdot p\\cdot \\sum_{x=2}^{+\\infty} x\\cdot (x-1)\\cdot (1-p)^{x-2}\\\\ \n& &+   (1-p)\\cdot p\\sum_{x=1}^{+\\infty} x \\cdot (1-p)^{x-1}\\\\\n&=&\np\\cdot (1-p)^2 \\frac{2}{(1-(1-p))^3}+  (1-p)\\cdot p \\frac{1}{(1-(1-p))^2}\\\\\n&=&\np\\cdot (1-p)^2 \\frac{2}{p^3}+  (1-p)\\cdot p \\frac{1}{p^2}\\\\\n&=&\\frac{2\\cdot (1-p)^2}{p^2}+\\frac{1-p}{p}.\n\\end{array}\n$$\n\n\n**Varianza de una v.a. $Ge(p)$**\n\n$$\n\\begin{array}{rll}\nVar(X)&=&E(X^2)-E(X)^2=\\frac{2\\cdot (1-p)^2}{p^2}+\\frac{1-p}{p}-\\left(\\frac{1-p}{p}\\right)^2\\\\\n&=&\n\\frac{2\\cdot (1-p)^2+p\\cdot(1-p)-(1-p)^2}{p^2}=\\frac{(1-p)^2+p\\cdot(1-p)}{p^2}\\\\\n&=&\n\\frac{1-2\\cdot p + p^2+p-p^2}{p^2}\\\\\n&=& \\frac{1-p}{p^2},\n\\end{array}\n$$\ny su desviación típica será\n$$\\sqrt{Var(X)}=\\sqrt{\\frac{1-p}{p^2}}.$$\n\n**Resumen $Ge(p)$ empezando en $0$**\n\n$X=$ Geométrica (empieza en $0$)  | número de fracasos  para conseguir el primer éxito\n------:|:-----\n$D_X=$ | $\\{0,1,\\ldots n,\\ldots\\}$ \n$P_X(x)=P(X=x)=$ |$\\left\\{\\begin{array}{ll}(1-p)^{x}\\cdot p, & \\mbox{ si } x=0,1,2,\\ldots \\\\0,  & \\mbox{ en otro caso.}\\end{array}\\right.$\n$F_X(x)=P(X\\leq x)=$ | $\\left\\{\\begin{array}{ll} 0 & \\mbox{ si } x<0\\\\\n  1- (1-p)^{k+1}, & \\mbox{ si } \\left\\{ \\begin{array}{l}k\\leq x< k+1,\\\\\\mbox{para } k=0,1,\\dots\\end{array}\n    \\right.\\end{array}\\right.$ \n$E(X)=\\frac{1-p}{p}$ | $Var(X)=\\frac{1-p}{p^2}$\n\n**La variable geométrica que cuenta los intentos para obtener el primer éxito**\n\nSupongamos que sólo estamos interesados en el **número de intentos** para obtener el primer éxito. \n\nSi definimos $Y$ como número de  intentos para obtener el  primer éxito, entonces $Y=X+1$, donde $X\\equiv Ge(p)$.\n\nSu dominio es $D_Y=\\{1,2,\\ldots\\}$ \n\nLa media se incrementa en un intento debido al éxito  $E(Y)=E(X+1)=E(X)+1=\\frac{1-p}{p}+1=\\frac1{p}$.\n\nLa varianza es la misma $Var(Y)=Var(X+1)=Var(X)=\\frac{1-p}{p^2}$.\n\n\n**Resumen $Ge(p)$ comenzando en $1$**\n\n$Y$ geométrica  (que cuenta el éxito empieza en 1)| número de INTENTOS  para OBTENER el primer éxito\n------:|:-----\n$D_Y=$ |  $\\{1,2,\\ldots n,\\ldots\\}$ \n$P_Y(y)=P(Y=y)=$ |$\\left\\{\\begin{array}{ll}(1-p)^{y-1}\\cdot p, & \\mbox{ si } y=1,2,3,\\ldots\\\\  0,  & \\mbox{ en otro caso.}\\end{array}\\right.$\n$F_Y(y)=P(Y\\leq y)=$ | $\\left\\{\\begin{array}{ll} 0, & \\mbox{ si } y<1\\\\ 1- (1-p)^{k}, & \\mbox{ si } \\left\\{ \\begin{array}{l}k\\leq y< k+1,\\\\\\mbox{para } k=1,2,3,\\dots \\end{array}    \\right.\\end{array}\\right.$ \n$E(X)=\\frac1{p}$ |$Var(X)=\\frac{1-p}{p^2}$\n\n\n\n\n**Propiedad de la falta de memoria**\n\nSea $X$ una v.a. discreta con dominio $D_X=\\{0,1,2,\\ldots\\}$, con $P(X=0)=p$.\n\nEntonces $X$ sigue una ley $Ge(p)$ si, y sólo si,\n$$\nP\\left(X> k+j\\big| X\\geq j\\right)=P(X> k)\n$$\npara todo $k,j=0,1,2,3\\ldots$.\n\n\n<div class=\"dem\">\n**Demostración**\n\nSi $X$ es geométrica, entonces el lado derecho de la igualdad es \n\n$$\nP(X>k)=1-P(X\\leq k)=1-\\left(1-(1-p)^{k+1}\\right)=(1-p)^{k+1},\n$$\ny el lado de izquierdo es:\n$$\n\\begin{array}{rll} \nP\\left(X> k+j\\big| X\\geq j\\right)&=&\\frac{P\\left(\\{X> k+j\\}\\cap \\{X\\geq j\\} \\right)}{P\\left(X\\geq j\\right)}=\n\\frac{P\\left(X>k+j \\right)}{P\\left(X\\geq j \\right)} = \\frac{1-P(X\\leq k+j)}{1-P(X\\leq j-1)}\\\\\n&=&  \\frac{1-(1-(1-p)^{k+j+1})}{1-(1-(1-p)^{j-1+1})} =\\frac{(1-p)^{k+j+1}}{(1-p)^{j}} = (1-p)^{k+1},\n\\end{array}\n$$\nlo que demuestra  la igualdad.\n\nPara demostrar el recíproco, tomemos $j=1$  y $k\\geq 0$. Entonces, por la propiedad de la pérdida de memoria:\n$$\nP\\left(X> k+1\\big| X\\geq 1\\right)=P(X> k)\n$$\n\nComo $P(X=0)=p$, tenemos que $P(X \\geq 1 )=1-P(X<1)=1-P(X=0)=1-p$.\n\nCombinado las igualdades, tenemos que:\n$$\nP\\left(X> k+1\\big| X\\geq 1\\right)=\\frac{P(X>k+1, X\\geq 1)}{P(X\\geq 1)}=\\frac{P(X>k+1)}{P(X\\geq 1)}=P(X>k).\n$$\nAsí podemos poner que \n\n\n$$\n\\begin{array}{rll}\nP(X>k+1)&=&P(X\\geq 1)\\cdot P(X>k)=\\left(1-P(X<1)\\right)\\cdot P(X>k)\\\\\n&=&\\left(1-P(X=0)\\right)\\cdot P(X>k)=(1-p)\\cdot P(X>k).\n\\end{array}\n$$\n\nEn general tenemos que:\n\n$$\nP(X>k+1)=(1-p)\\cdot P(X>k).\n$$\nDel mismo modo para $j=2$,\n$$\nP(X>k+2)=(1-p)\\cdot P(X>k+1).\n$$\nRestando la primera igualdad de la última obtenemos:\n$$\nP(X>k+1)-P(X>k+2)=(1-p)\\cdot P(X>k)-(1-p)\\cdot P(X>k+1),\n$$\nde donde operando en cada lado de la igualdad obtenemos la recurrencia:\n$$\n[1-P(X\\leq k+1)]-[1-P(X\\leq k+2)]=(1-p)\\cdot [P(X>k)-P(X>k+1)]\n$$\n\nAhora operando,\n$$\n\\begin{array}{rl}\nP(X\\leq k+2)-P(X\\leq k+1) & =(1-p)\\cdot[1-P(X\\leq k)-\\left(1-P(X\\leq k+1)\\right)],\\\\\nP(X=k+2) & =(1-p)\\cdot[P(X\\leq k+1)-P(X\\leq k)], \\\\\nP(X=k+2) & =(1-p)\\cdot P(X=k+1).\n\\end{array}\n$$\nDe forma similar, obtenemos \n\n$$\nP(X=k+1)=(1-p)\\cdot P(X=k).\n$$\nUtilizando la recurrencia anterior, podemos calcular todas las probabilidades $P(X=k)$ a partir de la $P(X=0)=p$: \n$$\n\\begin{array}{rl}\nP(X=0)&= p,\\\\\nP(X=1)&=P(X=0+1)= (1-p)\\cdot P(X=0) =(1-p)\\cdot  p,\\\\\nP(X=2)&=P(X=1+1)= (1-p)\\cdot P(X=1)=(1-p)\\cdot (1-p)\\cdot p=(1-p)^2\\cdot p,\\\\\n \\vdots& \\vdots \\\\\nP(X=k)&=P(X=(k-1)+1)= (1-p)\\cdot P(X=k-1)=(1-p)\\cdot (1-p)^{k-1}\\cdot p \\\\\n& =(1-p)^{k}\\cdot p,\n\\end{array}\n$$\nlo que demuestra el recíproco, es decir, que $X$ es $Geom(p)$.\n</div>\n\n\n\n\n\n<l class=\"observ\"> **Observación: Interpretación  de la propiedad de la falta de memoria**</l>\n\nLa propiedad de la falta de memoria\n$$\nP(X> k+j\\big|X \\geq j)=P(X > k),\n$$   \nsignifica que, aunque **ya llevemos al menos  $j$ fracasos**, la probabilidad de **que fracasemos $k$ veces más** no disminuye, es la misma  que era cuando empezamos el experimento. \n\nA este efecto se le suele etiquetar con la frase  **el experimento carece de memoria** o es un **experimento sin memoria** (*Memoryless Property*).\n\n**Ejemplo falta de memoria**\n\nUn ejemplo muy sencillo nos aclarará el alcance de esta propiedad es el ejercicio siguiente:\n\n<div class=\"exercise\"> **Ejercicio: la llave que abre la puerta**\n\nTenemos un llavero con 10 llaves,  sólo una de ellas abre una puerta. Cada vez que probamos una llave y falla olvidamos que llave hemos probado. ¿Cuál es la probabilidad de que  si ya lo hemos intentado  5 veces necesitemos más de 4 intentos adicionales  para abrir la puerta?\n\n<div class=\"example-sol\">\n\nTomemos $k=4,j=5$, aplicando la propiedad de la falta de memoria\n\n$$\nP(X> 4+5/X \\geq 5)=P(X > 4)\n$$\n\nDespués de 5 fracasos no estamos \"más cerca\" de abrir la puerta.\nLa propiedad de la falta de  memoria  nos dice que en **después de cada intento es como si empezásemos  de nuevo a abrir la puerta**. Tras 5 fracasos la probabilidad de que fallemos más de  4 veces  más es la misma que cuando lo intentamos la primera vez.\n\n¿Cuál es el número esperado de fracasos hasta abrir la puerta?\n\n$$\nE(X)=\\frac{1-p}{p}=\\frac{1-\\frac{1}{10}}{\\frac{1}{10}}=\\frac{\\frac{9}{10}}{\\frac{1}{10}}=9.\n$$\n\nLa varianza es \n$$\nVar(X)=\\frac{1-p}{p^2}=\\frac{1-\\frac{1}{10}}{\\left(\\frac{1}{10}\\right)^2}=\\frac{\\frac{9}{10}}{\\frac{1}{100}}=\n90.\n$$\n\nLa desviación típica es $\\sqrt{90}=9.486833.$\n</div>\n</div>\n\n\n<div class=\"exercise\">\n\n**Ejemplo: partidos hasta que el Barça gana al Madrid**\n\nLos partidos Real Madrid vs FC Barcelona de **la liga** española se suelen denominar  **El Clásico**, sean en el Bernabeu (estadio del Real Madrid) o en el Camp Nou (estadio del Barça).\n\nSea $X$ la variable que cuenta el número de veces consecutivas que en un partido de fútbol de la liga el Barça no gana al Madrid sea en el Camp Nou o el Bernabeu.\n\nNuestra amiga Aina es muy culé (hincha del Barça) y quiere averiguar cuántos partidos consecutivos de **El Clásico** tiene que ver hasta ver ganar al Barça por primera vez. \n\nLe interesa estimar cuánto le va a costar este capricho. Tendrá que comprar las entradas y pagar los viajes de Barcelona a Madrid.\n\nEn [datos historicos de **El clásico**  en la wikipedia](https://es.wikipedia.org/wiki/El_Cl%C3%A1sico) están los datos hasta el 3 de marzo de 2019: se han jugado en total 178 **Clásicos** donde el Real Madrid ganó en 72 ocasiones, el Barça en 72 y empataron 34 veces.\n\nLa pregunta es: ¿Cuántos partidos se tienen que jugar de media para ver ganar al Barça por primera vez?\n\n<div class=\"example-sol\"> \n\nCon los datos anteriores, podemos estimar que la probabilidad de que el Barça gane un clásico cualquiera es:\n$$P(\\mbox{Barça})=\\frac{72}{178}=0.4045.$$\n\nPor tanto, podemos modelar la variable $X$ con una ley  geométrica con probabilidad de éxito $p=P(\\mbox{Barça})=\\frac{72}{178}.$\n\nEl número de partidos esperado para que el Barça gane por primera vez es:\n\n$$E(X)=\\frac{1-p}{p}=\\frac{1-0.4045}{0.4045}=1.4722,$$\ncon una varianza de:\n$$Var(X)=\\frac{1-p}{p^2}=\\frac{1-0.4045}{0.4045^2}=3.6397$$\ny desviación típica:\n$$\\sqrt{3.6397}=1.9078.$$\n</div>\n</div>\n\n\n\n**Cálculos con `R`**\n\nVeamos los cálculos básicos con `R` para la distribución geométrica  $Ge(p=0.25)$. `R` implementa la geométrica que cuenta el número de fracasos, $P(X=0)=(1-0.25)^0\\cdot 0.25^1=0.25$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndgeom(0,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.25\n```\n:::\n:::\n\n\n$P(X\\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25$:\n\n::: {.cell}\n\n```{.r .cell-code}\npgeom(0,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.25\n```\n:::\n:::\n\n\n$P(X\\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953$:\n\n::: {.cell}\n\n```{.r .cell-code}\npgeom(4,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7626953\n```\n:::\n:::\n\n\nUna muestra aleatoria de tamaño 25 de una $Ge(0.25)$:\n\n::: {.cell}\n\n```{.r .cell-code}\nrgeom(n=25,prob=0.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  5  4  1  6 10  0  0 10  7  0  6  2  1  3  0  2  5  0  0  5  5  3  3  2  2\n```\n:::\n:::\n\n\n**Gráficos con `R`**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nx=c(0:10)\nplot(x=x,y=dgeom(x,prob=0.25),\n  ylim=c(0,1),xlim=c(-1,11),xlab=\"x\",\n  main=\"Función de probabilidad\\n Ge(p=0.25)\")\nlines(x=rep(0:10,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\naux0=dgeom(c(0:10),prob=0.25)\nceros=rep(0,21)\nceros\naux=ceros\naux[2*(c(1:11))]<-aux0\ncurve(pgeom(x,prob=0.25),\n  xlim=c(-1,10),col=\"blue\",\n  main=\"Función de distribución\\n Ge(p=0.25)\")\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/graficos22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n**Gráficas interactivas de la distribución Geométrica**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsliderInput(\"p_geom\", label = \"Probabilidad de éxito:\",\n              min = 0.01, max = 0.99, value =0.25 , step = 0.01)\nrenderPlot({\n  par(mfrow=c(1,2))\n  p=input$p_geom\n  n=30\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dgeom(c(0:n),prob=p)\n  plot(x=c(0:n),y=dgeom(c(0:n),prob=p),\n       ylim=c(0,1),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Función de probabilidad\\n Ge(p=\",p,\")\"),collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\n  curve(pgeom(x,prob=p),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Función de distribución\\n Ge(p=\",p,\")\"),collapse = \"\"))\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_geometrica1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n**Cálculos con `Python`**\n\nVeamos los cálculos básicos con  python para la distribución geométrica  $Ge(p=0.25)$. `scipy.stats` implementa la distribución geométrica que cuenta el número  intentos, así que empieza en 1.\n\nCargamos la  función de la librería \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import geom\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/geom1-1.png){width=480}\n:::\n:::\n\n\nLa función de probabilidad es `geom.pmf(x,p,loc=0)=geom.pmf(x,p)`. Es una geométrica que cuenta el número de intentos para obtener el primer éxito y el valor por defecto del último parámetro es  `loc=0`.\n\nSi queremos la que cuenta el número de fracasos para obtener el primer éxito (la geométrica que empieza en 0) tenemos que usar `geom.pmf(x,p,loc=-1)`.\n\nEs decir `geom.pmf(x,p,loc=-1)=geom.pmf(x-1,p,loc=0)`\n\nVeamos pues los cálculos para la $Ge(p)$ que empieza en $0$.\n\n$P(X=0)=(1-0.25)^0\\cdot 0.25^1=0.25$:\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.pmf(0,p=0.25,loc=-1)\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/py_geom_funciones1-3.png){width=480}\n:::\n:::\n\n\n$P(X\\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25$:\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.cdf(0,p=0.25,loc=-1)\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/py_geom_funciones2-5.png){width=480}\n:::\n:::\n\n\n$P(X\\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953$:\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.cdf(4,p=0.25,loc=-1)\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/py_geom_funciones3-7.png){width=480}\n:::\n:::\n\n\nUna muestra aleatoria de tamaño 25 de una $Ge(0.25)$:\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.rvs(p=0.25, size=20, loc=-1)\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/py_random_binom-9.png){width=480}\n:::\n:::\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\n¿Qué probabilidades son las que calcula el siguiente código y qué tipo de variables geométricas son?\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.cdf(range(5),p=0.3,loc=0)\ngeom.cdf(range(5),p=0.3,loc=-1)\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-25-11.png){width=480}\n:::\n:::\n\n</div>\n\n**Cálculos con `Python` de la esperanza y varianza**\n\nCon `Python` también podemos calcular directamente algunos parámetros asociados a una función de distribución predefinida\n\n::: {.cell}\n\n```{.python .cell-code}\ngeom.stats(p=0.25, loc=0, moments='mv')\ngeom.stats(p=0.25, loc=-1, moments='mv')\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/py_mean_var_stats-13.png){width=480}\n:::\n:::\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nComprobad que las medias y las varianzas calculadas en el código anterior corresponden a una $Ge(p=0.3)$ empezando en $1$ y a una $Ge(p=0.3)$ empezando en $0$.\n\n¿Son las varianzas siempre iguales?\n</div>\n\n\n**Gráficos con `Python`**\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = 0.25\nx = np.arange(geom.ppf(0.01, p),geom.ppf(0.99, p))\nfig =plt.figure(figsize=(5, 2.7))\nax = fig.add_subplot(1,2,1)\nax.plot(x, geom.pmf(x, p), 'bo', ms=5, label='geom pmf')\nax.vlines(x, 0, geom.pmf(x, p), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5) \nax = fig.add_subplot(1,2,2)\nax.plot(x, geom.cdf(x, p), 'bo', ms=5, label='geom pmf')\nax.vlines(x, 0, geom.cdf(x, p), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfig.suptitle('Distribucion Geometrica')\nplt.show()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-26-15.png){width=480}\n:::\n:::\n\n\n\n### Distribución binomial negativa\n\n**El problema de la puerta con dos cerraduras**\n\nSupongamos que disponemos de 10 llaves distintas y tenemos que abrir una puerta con **dos cerraduras**.\n\nComenzamos por la primera cerradura, de tal forma que cada vez olvidamos qué llave hemos probado.\n\nUna vez abierta la primera cerradura probamos de igual forma con la segunda hasta que también la abrimos.\n\nSea $X$ la v.a. que cuenta el número de fracasos hasta abrir la puerta.\n\nAcertar una llave de la puerta es un experimento Bernoulli con probabilidad de éxito $p=0.1$. Lo repetiremos hasta obtener 2 éxitos.\n\nEn general, tendremos un experimento de Bernoulli con probabilidad de éxito $0<p<1$  tal que:\n\n* Repetimos el experimento hasta obtener el $n$-ésimo éxito ¡¡abrir la maldita puerta!!.\n* Sea $X$ la v.a. que cuenta el número fallos hasta abrir la puerta, es decir, hasta  conseguir el $n$-ésimo éxito. Notemos que no contamos los éxitos, solo contamos los fracasos.\n\nSi representamos como es habitual un suceso como una cadena de F's y E's, para $n=2$, algunos sucesos elementales serán:\n $$\\{EE,FEE,EFE, FFEE,FEFE,EFFE,FFFEE,FFEFE,FEFFE,EFFFE\\}.$$\n \nCalculemos algunas probabilidades para $n=2$:\n$$\n\\begin{array}{rl}\nP(X=0) & =P(\\{EE\\})=p^2, \\\\\nP(X=1) & =P(\\{FEE,EFE\\})=2\\cdot (1-p)\\cdot p^2, \\\\\nP(X=2) & =P(\\{FFEE,FEFE,EFFE\\})=3\\cdot (1-p) 2\\cdot p^2, \\\\\nP(X=3) & =P(\\{FFFEE,FFEFE,FEFFE,EFFFE\\})=4\\cdot (1-p)^3\\cdot p^2.\n\\end{array}\n$$\nEn general, su función de probabilidad es\n$$\nP_{X}(k)=P(X=k)=\\left\\{\\begin{array}{ll}\n     {{k+n-1}\\choose{n-1}} \\cdot (1-p)^{k}\\cdot p^n, & \\mbox{si } k=0,1,\\ldots\\\\\n     0, & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n     \nUna v.a. con este tipo de distribución recibe el nombre de **binomial negativa** y la denotaremos por $BN(n,p)$. \n\nNotemos que $BN(1,p)=Ge(p)$.\n\n<div class=\"dem\">\n**Demostración**\n\nJustifiquemos el resultado. Sea $X$ una $BN(n,p)$ y sea $k=0,1,2,\\ldots$\n\n$$P(X=k)=P(\\mbox{Todas las cadenas de E's y F' con $k$ F, con $n$ E y acabadas en E})$$\n\n\n$$\n\\overbrace{\\underbrace{\\overbrace{EFFF\\ldots EEF}^{n-1 \\quad \\mbox{Éxitos}.}}}_{k \\quad\\mbox{Fracasos}}^{k+n-1\\mbox{ posiciones}}E\n$$\n\n\n\nDe estas cadenas hay  tantas como maneras de elegir de entre las $k+n-1$ primeras posiciones $n-1$ para colocar los éxitos. Esta cantidad es el número binomial ${k+n-1\\choose n-1}$.\n\n</div>\n\n\n**Números binomiales negativos**\n\nDados dos enteros positivos $n$ y $k$, se define el número binomial negativo como:\n$$\\binom{-n}{k}=\\frac{(-n)(-n-1)\\cdots (-n-k+1)}{k!}.$$\nLos números binomiales negativos generalizan la fórmula de Newton para exponentes negativos:\n$$\n(t+1)^{-n}=\\sum_{k=0}^{+\\infty}\\left(\\begin{array}{c} -n\n\\\\ k\\end{array}\\right) t^{k}.\n$$\n\n\n\n`R` usa la función `choose` para calcular números binomiales, sean negativos o no. Veámoslo con un ejemplo:\n$$\n{-6\\choose 4}=\\frac{-6\\cdot (-6-1)\\cdot \\cdot (-6-2)\\cdot (-6-3) }{4!}= \\frac{-6\\cdot(-7)\\cdot (-8)\\cdot (-9)}{24}\n= \\frac{3024}{24}=126.\n$$\nSi realizamos el cálculo con `R` obtenemos el mismo resultado:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(-6,4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 126\n```\n:::\n:::\n\n\n**Esperanza de una $BN(n,p)$**\n\nSu **esperanza es**:\n\n$$E(X)=\\sum_{k=0}^{+\\infty} k\\cdot {k+n-1\\choose n-1} \\cdot (1-p)^{k}\\cdot p^n=n\\cdot\\frac{1-p}{p}.$$\n\nLa **esperanza de $X^2$** es:\n\n$$E(X^2)=\\sum_{k=0}^{+\\infty} k^2\\cdot {k+n-1\\choose n-1} \\cdot (1-p)^{k}\\cdot p^n=n\\cdot\\frac{1-p}{p^2}+\\left(n\\cdot \\frac{1-p}{p}\\right)^2.$$\n\n**Varianza de una $BN(n,p)$**\n\nPor último, la **varianza** es:\n$$\nVar(X)=E(X^2)-E(X)^2=n\\cdot \\frac{1-p}{p^2}+\\left(n\\cdot \\frac{1-p}{p}\\right)^2-\\left(n\\cdot \\frac{1-p}{p}\\right)^2=\nn\\cdot \\frac{1-p}{p^2},\n$$\ny la desviación típica es:\n\n$$\\sqrt{Var(X)} = \\frac{\\sqrt{n(1-p)}}{p}.$$\n\n**Resumen Binomial Negativa $BN(n,p)$**\n\n\n $X = BN(n,p)$ | Número de fracasos antes de  conseguir el $n$-ésimo éxito. Probabilidad de éxito $p$\n--------------:|:------------\n$D_X=$ | $\\{0,1,2,3\\ldots\\}$  \n$P_X(k)=P(X=k)=$ | $\\left\\{\\begin{array}{ll} {k+n-1\\choose n-1} \\cdot (1-p)^{k}\\cdot p^n, & \\mbox{si }  k=0,1,\\ldots \\\\ 0, & \\mbox{en otro caso.}\\end{array}\\right.$\n$F_X(x)=P(X\\leq x)=$ | $\\begin{array}{l}\\left\\{\\begin{array}{ll} 0, & \\mbox{si } x<0\\\\\\displaystyle\\sum_{i=0}^{k} P(X=i) & \\mbox{si  }\\left\\{\\begin{array}{l}k\\leq x< k+1,\\\\k=0,1,2,\\ldots\\end{array}\\right.\\end{array}\\right.\\end{array}$ Calcular la suma o utilizar funciones de `R` o `Python`.|\n$E(X)=n\\cdot\\frac{1-p}{p}$ | $Var(X)=n\\cdot \\frac{1-p}{p^2}$ \n\n\n<div class=\"exercise\">\n**Ejercicio: Puerta  con dos cerraduras**\n\nRecordemos nuestra puerta con dos cerraduras que se abren secuencialmente. Tenemos un manojo de 10 llaves casi idénticas de manera que cada vez que probamos una llave olvidamos qué llave hemos usado.\n\nSea $X$ la v.a que nos da el número de intentos fallidos hasta abrir abrir la puerta. \n\nEstamos interesado en modelar este problema. La preguntas son:\n\n1. ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número fallos hasta abrir la puerta? \n2. ¿Cuál es la función de probabilidad y de distribución de $X$?\n3. ¿Cuál es la probabilidad de fallar exactamente 5 veces antes de abrir la puerta?\n4. ¿Cuál es la probabilidad de fallar más de 4?\n5. ¿Cuál es  el número esperado de fallos? ¿Y su desviación típica?\n\n<div class=\"example-sol\">\n\n**Solución 1.**  ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número fallos  hasta abrir la puerta? \n\nBajo estados condiciones tenemos que la probabilidad de \"éxito\" de cada intento es $p=\\frac{1}{10}=0.1$. Como cada vez *olvidamos* qué llave hemos probado, cada intento será independiente del anterior.\n\nAsí que  la variable $X$ que queremos modelar cuenta el número de fallos de repeticiones sucesivas e independientes de  un experimento $Ber(p=0.1)$ hasta conseguir 2 éxitos en un experimento.\n\nPor lo tanto  podemos asegurar que $X$ sigue un distribución $BN(n=2,p=0.1).$\n\n**Solución 2.** ¿Cuál es la función de probabilidad y de distribución de $X$?\n\nEn general la función de probabilidad  de una $BN(n,p)$ es \n\n$$\nP_X(X=k)=\n\\left\\{\n\\begin{array}{cc} \n{k+n-1\\choose n-1} \\cdot (1-p)^{k}\\cdot p^n, & \\mbox{si }  k=0,1,\\ldots \\\\ 0, & \\mbox{en otro caso.}\\end{array}\\right.\n$$\nSi aplicamos la expresión anterior para $n=2$ y $p=0.1$, obtenemos:\n\n$$\nP_X(X=k)=\n\\left\\{\n\\begin{array}{cc} \n{k+2-1\\choose 2-1} \\cdot 0.9^{k}\\cdot 0.1^2, & \\mbox{si }  k=0,1,2,\\ldots \\\\ 0, & \\mbox{en otro caso.}\\end{array}\\right.\n$$\nSimplificando,\n$$\nP_X(X=k)=P(X=k)=\n\\left\\{\n\\begin{array}{cc} \n0.01\\cdot (k+1)\\cdot 0.9^{k}, & \\mbox{si }  k=0,1,2,\\ldots \\\\ 0 & \\mbox{en otro caso.}\\end{array}\\right.\n$$\nLa función de distribución  en general es \n\n$$\nF_X(x)=P(X\\leq x)=\n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x<0, \\\\\n\\displaystyle\\sum_{i=0}^{k }{i+n-1\\choose n-1} \\cdot (1-p)^{i+n-1}\\cdot p^n, \n& \\mbox{si }\\left\\{\\begin{array}{l} k\\leq x< k+1,\\\\k=0,1,2,\\ldots\\end{array}\\right. \n\\end{array}\n\\right.\n$$\nSimplificando para $n=2$, $p=0.1$.\n\n$$\nF_X(x)=P(X\\leq x)=\n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x<0, \\\\\n\\displaystyle\\sum_{i=0}^{k }0.01\\cdot (i+1) \\cdot 0.9^{i+1},\n& \\mbox{si }\\left\\{\\begin{array}{l} k\\leq x< k+1,\\\\k=0,1,2,\\ldots\\end{array}\\right. \n\\end{array}\n\\right.\n$$\n\n**Solución 3.**  ¿Cuál es la probabilidad de fallar exactamente 5 veces antes de abrir la puerta?\n$$\nP(X=5)= 0.01\\cdot (5+1) \\cdot 0.9^{5}= 0.06 \\cdot 0.9^{5}= 0.0354294.\n$$\n\n**Solución 4.** ¿Cuál es la probabilidad de fallar más de 4?\n\nNos piden calcular $P(X>4)=1-P(X\\leq 4).$\n\nCalculemos primero $P(X\\leq 4):$\n\n$$\n\\begin{array}{rl}\nP(X\\leq 4) &=  \\displaystyle\\sum_{x=0}^{4} P(X=x) \\\\ & =P(X=0)+P(X=1)+P(X=2)+P(X=3)+P(X=4)\\\\\n&= 0.01\\cdot (0+1) \\cdot 0.9^{0}+0.01\\cdot (1+1) \\cdot 0.9^{1}+0.01\\cdot (2+1) \\cdot 0.9^{2} \\\\ &\\ \\ \n+0.01\\cdot (3+1) \\cdot 0.9^{3} + 0.01\\cdot (4+1) \\cdot 0.9^{4} \\\\ & =\n0.01 +0.018+0.0243+0.02916+0.032805 = 0.114265.\n\\end{array}\n$$\n\nPor lo tanto \n\n\n$$\nP(X>4)=1-P(X\\leq 4)=1-0.114265=\n0.885735.\n$$\n\n\n::: {.cell}\n\n:::\n\n</div>\n\n\n<div class=\"example-sol\">\n\n**Solución 5.**  ¿Cuál es  el número esperado de fallos? ¿Y su desviación típica?\n\n\nComo $X$ sigue una ley $BN(n=2,p=0.1)$\n\n$$E(X)=n\\cdot \\frac{1-p}{p}=2\\cdot \\frac{1-0.1}{0.1}=18.$$\n\nEl número de fallos esperado es 18.\n\nLa varianza será:\n$$\nVar(X)=n\\cdot\\frac{1-p}{p^2}=2 \\cdot \\frac{1-0.1}{0.1^2}=180.\n$$\nLa varianza de $X$ es 180 y su desviación típica $\\sqrt{180}=13.41641.$\n\n</div>\n</div>\n\n\n**Cálculos con `R`**\n\nLa función de `R` que calcula la función de probabilidad de la  binomial negativa con sus parámetros básicos es: \n\n```\ndnbinom(x, size, prob,...)`\n```\ndonde `size` ($n$) es el número de éxitos y  `prob` ($p$), la probabilidad de éxito.\n\nAsí, en el ejemplo de la puerta con dos cerraduras, $X$ es una $BN(n=size=2,p=prob=0.1)$. Por ejemplo, $P(X=5)$ que hemos calculado en el ejemplo anterior, vale:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndnbinom(5,size=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0354294\n```\n:::\n:::\n\n\nDe forma similar calculamos calculamos $P(X\\leq 4)$, $P(X>4)=1-P(X\\leq 4)$ y $P(X>4)$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnbinom(4,size=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.114265\n```\n:::\n\n```{.r .cell-code}\n1-pnbinom(4,size=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.885735\n```\n:::\n\n```{.r .cell-code}\npnbinom(4,size=2,p=0.1,lower.tail=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.885735\n```\n:::\n:::\n\n\n**Cálculos con `Python`**\n\nLa función con `Python` es `nbinom.pmf(k, n, p, loc)`. Hay que cargarla desde `scpi.stats`\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import nbinom\n```\n:::\n\n\nRecordemos que de nuevo se cumple que \n\n::: {.cell}\n\n```{.python .cell-code}\nnbinom.pmf(k, n, p, loc) = nbinom.pmf(k-loc, n, p)`\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nnbinom.pmf(k=5,n=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.0354294\n```\n:::\n\n```{.python .cell-code}\nnbinom.pmf(k=5,n=2,p=0.1,loc=0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.0354294\n```\n:::\n\n```{.python .cell-code}\nnbinom.cdf(k=4,n=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.11426500000000002\n```\n:::\n\n```{.python .cell-code}\n1-nbinom.cdf(k=4,n=2,p=0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.8857349999999999\n```\n:::\n:::\n\n\n\nGeneremos 100 observaciones aleatorias de una $BN(n=2,0.1)$. Es decir serán las veces que hemos fallado hasta abrir la puerta 100 veces.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnbinom.rvs(n=2, p=0.1, size=100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 5,  3, 14,  5, 26,  9, 24, 15, 28,  6,  8, 25,  9, 25, 36, 43, 37,\n       26, 49,  7,  7, 12, 42,  9, 25,  3,  7, 10, 49,  4, 10, 17, 19, 13,\n       14, 14,  6, 24,  7,  0, 24,  7, 55,  2,  0, 25, 29,  0, 25,  7, 13,\n       21, 26, 44, 24, 35, 28, 20,  9, 15, 42,  4, 24, 30, 13, 15, 57, 11,\n       33,  8,  5,  6, 12, 22,  7,  9, 10, 25,  3, 15,  9,  9,  7, 28,  8,\n       16, 12, 16,  7, 31,  1, 12,  8, 36, 13, 51,  6, 19, 24, 38],\n      dtype=int64)\n```\n:::\n:::\n\n\nLa **esperanza** y la **varianza**de una $BN(n=2,0.1)$ valen: \n\n\n::: {.cell}\n\n```{.python .cell-code}\nn, p=2,0.1\nparams = nbinom.stats(n,p,moments='mv')\nprint(\"E(X)={m}\".format(m=params[0]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nE(X)=18.0\n```\n:::\n\n```{.python .cell-code}\nprint(\"Var(X)={v}\".format(v=params[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVar(X)=179.99999999999997\n```\n:::\n:::\n\n\n**Gráficas de la binomial negativa con `R`**\n\nEl siguiente código de `R` dibuja las función de probabilidad y la de distribución de una $BN(n=2,p=0.1)$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\naux=rep(0,22)\naux[seq(2,22,2)]=dnbinom(c(0:10),size=2,prob=0.1)\nplot(x=c(0:10),y=dnbinom(c(0:10),size=2,prob=0.1),\n  ylim=c(0,1),xlim=c(-1,11),xlab=\"x\",\n  main=\"Función de probabilidad\\n BN(n=2,p=0.1)\")\nlines(x=rep(0:10,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\ncurve(pnbinom(x,size=2,prob=0,1),\n  xlim=c(-1,11),col=\"blue\",\n  main=\"Función de distribución\\n BN(n=2,p=0.1)\")\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-37-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n**Gráficas interactivas binomial negativa**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(6,\n         sliderInput(\"n_nbinom\", label = \"Número de éxitos n:\",\n              min = 1, max = 50, value =20 , step = 1)),\n  column(6,\n          sliderInput(\"p_nbinom\", label = \"Probabilidad de un éxito p:\",\n                     min = 0.01, max = 0.99, value = 0.8, step = 0.01)\n         )\n  )\n)\n\nrenderPlot({\n  n=input$n_nbinom\n  pr=input$p_nbinom\n  \n  par(mfrow=c(1,2))\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dnbinom(c(0:n),size=n,prob=pr)\n  plot(x=c(0:n),y=dnbinom(c(0:n),size=n,prob=pr),\n       ylim=c(0,1),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Función de probabilidad\\n BN(n=\",n,\",p=\",pr,\")\"),\n                   collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\n  curve(pnbinom(x,size=n,p=pr),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Función de distribución\\n BN(n=\",n,\",p=\",pr,\")\"),\n                    collapse = \"\"))\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_binomial_negativa1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n<div class=\"exercise\">\n**Ejercicio**\n\nBuscad en los manuales de `Python` cómo se dibuja la función de probabilidad y de distribución de una binomial.\nnegativa \n\n<div class=\"exercise-sol\">\nNecesitamos de nuevo más librerías\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nfrom scipy.stats import nbinom\nimport matplotlib.pyplot as plt\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nn, p = 10, 0.25\nx = np.arange(0,nbinom.ppf(0.99, n, p))\nfig =plt.figure(figsize=(5, 2.7))\nax = fig.add_subplot(1,2,1)\nax.plot(x, nbinom.pmf(x, n, p), 'bo', ms=5, label='nbinom pmf')\nax.vlines(x, 0, nbinom.pmf(x, n, p), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5) \nax = fig.add_subplot(1,2,2)\nax.plot(x, nbinom.cdf(x, n, p), 'bo', ms=5, label='nbinom pmf')\nax.vlines(x, 0, nbinom.cdf(x, n, p), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfig.suptitle('Distribucion Binomial Negativa')\nplt.show()\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n<string>:2: MatplotlibDeprecationWarning: The label function was deprecated in Matplotlib 3.1 and will be removed in 3.8. Use Tick.label1 instead.\n```\n:::\n\n::: {.cell-output-display}\n![](3_files/figure-html/negativa_py_show-1.png){width=480}\n:::\n:::\n\n</div>\n</div>\n\n\n<div class=\"exercise\">\n**Ejercicio:  acceso aleatorio a un sistema con triple clave**\n\nSupongamos que tenemos un sistema informático que tiene un programa de seguridad que genera accesos con claves  de  3 dígitos  $000,001,\\ldots 999$. En total tenemos 1000 posibilidades.\n\nComo una clave de tres dígitos es fácil de romper, proponemos considerar tres claves consecutivas de acceso al sistema, cada una de 3 dígitos.\n\nPara acceder al sistema hay que dar las tres claves de forma consecutiva y por orden.\n\nEs decir hasta que no averiguamos la primera clave no pasamos a la segunda clave.\n\nSupongamos que cada vez que ponemos las dos claves olvidamos el resultado y seguimos poniendo claves al azar hasta adivinar la contraseña.\n\nAsí hasta conseguir entrar en el sistema.\n\nSea $X$ la v.a que nos da el número de fallos antes de entrar en el sistema.\n\nEstamos interesados en modelar  este problema.  La preguntas son:\n\n1. ¿Cuál es la distribución de probabilidad de $X$, la v.a que nos da el número de fallos antes de acceder al sistema.\n2. ¿Cuál es la función de probabilidad y de distribución del $X$?\n3. ¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el sistema?\n4. ¿Cuál es la probabilidad de fallar más de 150 veces antes de entrar en el sistema?\n5. ¿Cuál es  el número esperado de fallos antes de acceder al sistema? ¿Y su varianza?\n\n\n<div class=\"exercise-sol\">\n\n**Solución 1.**  ¿Cuál es la distribución de probabilidad de $X$, la v.a que nos da el número de fallos antes de acceder al  sistema?\n\nBajo estas dos condiciones tenemos que la probabilidad de \"éxito\" de cada intento es $p=\\frac{1}{1000}=0.001$. Y como cada vez *olvidamos* los dígitos cada intento será independiente del anterior.\n\nAsí que  la variable $X$ cuenta el número de fracasos independientes hasta conseguir 3 éxitos en un experimento $Ber(p=0.001)$, por lo tanto $X$ sigue un distribución $BN(n=3,p=0.001).$\n\n**Solución 2.** ¿Cuál es la función de probabilidad y de distribución del $X$\n\nEn general la función de probabilidad  de una $BN(n,p)$ es: \n\n\n$$\nP_X(X=x)=P(X=x)=\n\\left\\{\n\\begin{array}{cc} \n{x+n-1\\choose n-1} \\cdot (1-p)^{x}\\cdot p^n, & \\mbox{si }  x=0,1,\\ldots \\\\ 0, & \\mbox{en otro caso.}\\end{array}\\right.\n$$\nEn particular la función de probabilidad  de una $BN(n=3,p=0.001)$ es\n\n\n$$\nP_X(X=x)=P(X=x)=\n\\left\\{\n\\begin{array}{cc} \n{x+2\\choose 2} \\cdot 0.999^{x}\\cdot 0.001^3 & \\mbox{si }  x=0,1,2,\\ldots \\\\ 0 & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n\n\n**Solución 3.** ¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el sistema?\n\nNos piden calcular la probabilidad siguiente:\n$$\nP(X=150)= {152\\choose 2} \\cdot 0.999^{150}\\cdot 0.001^3.\n$$\nRealizaremos el cálculo anterior con ayuda de `R`:\n\n::: {.cell}\n\n```{.r .cell-code}\nchoose(152,2)*0.999^150*0.001^3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.876743e-06\n```\n:::\n:::\n\no, usando la función de `R` que nos calcula la función de probabilidad:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnbinom(150,size=3,p=0.001)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.876743e-06\n```\n:::\n:::\n\n\nSi queremos calcular la probabilidad anterior con `Python`, tenemos que hacer:\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom  scipy.special import binom\nbinom(152,2)*0.999**150*0.001**3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n9.876743459670526e-06\n```\n:::\n\n```{.python .cell-code}\nnbinom.pmf(150,n=3,p=0.001)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n9.876743459670532e-06\n```\n:::\n:::\n\nVemos que es muy improbable fallar 150 veces antes de acceder al sistema.\n\n\n**Solución 4.** ¿Cuál es la probabilidad de fallar  más de  150  veces antes de entrar en el sistema?\n\nNos piden calcular la probabilidad siguiente:\n$$P(X>150)=1-P(X\\leq 150).$$\n\nCalculemos $P(X\\leq 150)$\n$$\n\\begin{array}{rl}\nP(X\\leq 150) &= P(X=0)+P(X=1)+P(X=2)+\\ldots+P(X=150) \\\\ & = \\sum\\limits_{k=0}^{150} {k+3-1\\choose 3-1} \\cdot (0.999)^{k}\\cdot 0.001^3= \\ldots = 5.2320035\\times 10^{-4}\n\\end{array}\n$$\nSi hacemos el cálculo con `R`, obtenemos:\n\n::: {.cell}\n\n```{.r .cell-code}\npnbinom(150,3,0.001)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0005232003\n```\n:::\n:::\n\n\nSi lo hacemos en `Python`, obtenemos el mismo resultado:\n\n::: {.cell}\n\n```{.python .cell-code}\nnbinom.cdf(150,n=3,p=0.001)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.0005232003490824064\n```\n:::\n:::\n\nEl valor pedido será pues:\n$$\nP(X>150)=1-P(X\\leq 150)=1-5.2320035\\times 10^{-4}=0.9994768.\n$$\nVemos que es muy probable que fallemos más de 150 veces antes de entrar en el sistema.\n\n\n**Solución 5.**  ¿Cuál es  el número esperado de fallos antes de acceder al sistema? ¿Y su varianza?\n\n$$E(X)=n\\cdot \\frac{1-p}{p}=3\\cdot \\frac{1- 0.001}{0.001}=2997.$$\n$$Var(X)=n\\cdot \\frac{1-p}{p^2}=3\\cdot \\frac{1- 0.001^2}{0.001^2}=2.997\\times 10^{6}.$$\n\nCon `Python`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nparams = nbinom.stats(n=3,p=0.001,moments='mv')\nprint(\"E(X) = {m}\".format(m=params[0]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nE(X) = 2997.0\n```\n:::\n\n```{.python .cell-code}\nprint(\"Var(X) = {v}\".format(v=params[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVar(X) = 2997000.0\n```\n:::\n:::\n\n\n</div>\n</div>\n\n\n\n<div class=\"exercise\">\n\n**Ejercicio: ¿Tres claves de tres dígitos o una de 9 dígitos?**\n\nSupongamos que ponemos una sola clave de 9 dígitos. Estudiemos en este caso la variable aleatoria que da el número de fallos antes de entrar en el sistema y comparemos los resultados.\n\n<div class=\"exercise-sol\">\nSi seguimos suponiendo que cada vez ponemos la contraseña al azar, pero esta vez con una  clave de  9 dígitos. La probabilidad de éxito será ahora $p=\\frac{1}{10^{9}}$.\n\nSi llamamos $X_9$  a la variable aleatoria que nos da el número de fallos antes de entra en el sistema seguirá una distribución $Ge(p=\\frac{1}{10^9}=0.000000001)$.\n\nSu valor esperado es\n\n$$\nE(X_9)=\\frac{1-p}{p}=\\frac{1-0.000000001}{0.000000001}=10\\times 10^{8}.\n$$\n\n $1000 000 000$  son  1000 millones de fallos esperados hasta abrir la puerta.\n \nRecordemos que con tres contraseñas de 3 dígitos  el valor esperado de fallos era:\n \n $$3\\cdot \\frac{1-0.001}{0.001}=2997.$$\n \nPor lo tanto, desde el punto de vista de la seguridad, es mejor una clave larga de 9 dígitos que tres cortas si escribimos las contraseñas al azar.\n</div>\n</div>\n\n### Distribución de Poisson\n\nDiremos que una v.a. discreta $X$ con $X(\\Omega)=\\mathbb{N}$ tiene distribución de Poisson con parámetro $\\lambda>0$, y lo denotaremos por $Po(\\lambda)$ si su función de probabilidad es:\n\n$$\nP_{X}(x)=P(X=x)=\n\\left\\{\\begin{array}{ll}\n\\frac{\\lambda^x}{x!} e^{-\\lambda},& \\mbox{ si } x=0,1,\\ldots\\\\\n0, & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n\nUsando que el desarrollo en serie  de Taylor de la función exponencial es \n$$\ne^{\\lambda}=\\sum_{x=0}^{+\\infty} \\frac{\\lambda^x}{x!},\n$$\nes  fácil comprobar que la suma de la función de probabilidad en todos los valores del dominio de $X$, o sea, los enteros positivos, vale 1.\n\n\nAdemás, recordemos que   dado $x\\in\\mathbb{R}-\\{0\\}$   se tiene que  \n\n$$\n\\lim_{n\\to\\infty} \\left(1+\\frac{x}{n}\\right)^n=e^x.\n$$\n\nUsando la expresión anterior para $x=-\\lambda$, tenemos:\n$$\n\\lim_{n\\to\\infty} \\left(1-\\frac{\\lambda}{n}\\right)^n=\\lim_{n\\to\\infty} \\left(1+\\frac{-\\lambda}{n}\\right)^n=e^{-\\lambda}.\n$$\n\n**La distribución de Poisson como \"límite\" de una binomial**\n\nLa distribución de Poisson ([Siméon Denis Poisson](https://es.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson)) aparece en el conteo de determinados  eventos que se producen en un intervalo de tiempo o en el espacio.\n\nSupongamos que nuestra variable de interés es  $X$, el número de eventos en el intervalo de tiempo $(0,t]$, como por ejemplo el número de llamadas a un *call center* en una hora donde suponemos que se cumplen las siguientes condiciones:\n\n1. El número promedio de eventos en el intervalo $(0,t]$ es $\\lambda>0$.\n2. Es posible dividir el intervalo de tiempo en un\ngran número de subintervalos (denotemos por $n$ al número de intervalos) de forma que:\n    + La probabilidad de que se produzcan dos o más eventos en un subintervalo es despreciable.\n    + El número de ocurrencias de eventos en un intervalo  es independiente del número de ocurrencias en otro intervalo.\n    + La probabilidad de que un evento ocurra en un subintervalo es $p_n=\\frac{\\lambda}{n}$·\n\nBajo estas condiciones, podemos considerar que el número de eventos en el intervalo $(0,t]$ será el número de \"éxitos\" en $n$ repeticiones independientes de un proceso Bernoulli de parámetro $p_n$.\n\nEntonces si $n\\to\\infty$ y $p_n\\cdot n$ se mantiene igual a $\\lambda$, resulta que la función de probabilidad de $X_n$ se puede escribir como\n\n$$\n\\begin{array}{rl}\nP(X_n=k)&=\\left(\\begin{array}{c} n\\\\ k\\end{array}\\right) \\cdot p_n^k\\cdot  (1-p_n)^{n-k}\n\\\\\n&= {n\\choose k}\\cdot \\left(\\frac{\\lambda}{n}\\right)^{k}\\cdot \\left(1-\\frac{\\lambda}{n}\\right)^{n-k}\\\\\n&=\n\\frac{\\lambda^k}{k!}\\cdot\\frac{n!}{(n-k)!\\cdot n^k}\\cdot\n\\left(1-\\frac{\\lambda}{n}\\right)^{n}\\cdot \\left(1-\\frac{\\lambda}{n}\\right)^{-k}.\n\\end{array}\n$$\nSi hacemos tender $n$ hacia $\\infty$, obtenemos:\n$$\n\\displaystyle\\lim_{n\\to \\infty} P(X_n=k) = \\lim_{n\\to \\infty} \\frac{\\lambda^k}{k!}\\cdot\\frac{n!}{(n-k)!\\cdot n^k} \\cdot\n\\left(1-\\frac{\\lambda}{n}\\right)^{n}\\cdot \\left(1-\\frac{\\lambda}{n}\\right)^{-k}.\n$$\n\nCalculemos el límite de algunos de los factores de la expresión \n\n$$\n\\begin{array}{rl}\n\\lim\\limits_{n\\to \\infty}\\frac{n!}{(n-k)!\\cdot n^k} & = \\lim\\limits_{n\\to \\infty}\\frac{n\\cdot (n-1)\\cdots (n-k-1)}{n^k}\n=\\lim\\limits_{n\\to \\infty}\\frac{n^{k}+\\cdots}{n^k}=1, \\\\\n\\lim\\limits_{n\\to \\infty} \\left(1-\\frac{\\lambda}{n}\\right)^{n} & =e^{-\\lambda},\\\\\n\\lim\\limits_{n\\to \\infty} \\left(1-\\frac{\\lambda}{n}\\right)^{-k} & =\\lim\\limits_{n\\to \\infty} 1^{-k}=\\lim\\limits_{n\\to \\infty}  1=1,\n\\end{array}\n$$\ndonde en el último límite, hemos tenido en cuenta que $k$ es constante.\n\nUsando las expresiones halladas anteriormente, tenemos que el límite de la función de probabilidad de la variable $X_n$ tiende a la función de probabilidad de la variable de Poisson de parámetro $\\lambda$:\n\n$$\n\\displaystyle\\lim_{n\\to\\infty} P(X_n=k)=\n\\lim_{n\\to\\infty} \\left(\\begin{array}{c} n\\\\ k\\end{array}\\right)\n\\cdot p_n^k \\cdot (1-p_n)^{n-k}= \\frac{\\lambda^k}{k!}\\cdot 1 \\cdot e^{-\\lambda}\\cdot 1=\\frac{\\lambda^k}{k!}\\cdot e^{-\\lambda}.\n$$\nUsando que las variables $X_n$ tienen distribución $B(n,p_n=\\frac{\\lambda}{n})$, tenemos que el límite de binomiales de parámetros $n$ y $p_n=\\frac{\\lambda}{n}$ es una distribución de Poisson de parámetro $\\lambda$, $Po(\\lambda)$.\n\n**Procesos de Poisson**\n\nLo interesante de las variables Poisson es que podemos modificar (si el modelo lo permite)  el intervalo de tiempo $(0,t]$ en el que contamos los eventos, siempre y cuando se cumplan las condiciones 1 y 2 enunciadas anteriormente en el nuevo intervalo de tiempo. \n\nEn general, podemos afirmar si la variable es Poisson en  $(0,t]$,  también lo será en cualquier subintervalo $(0,t']$ para todo $t'$ tal que  $0<t'<t$. \n\nDe esta forma, podremos definir una serie de variables $X_t$ de distribución $Po(\\lambda\\cdot t)$.\n\n\n\n<l class=\"prop\"> **Definición de procesos de Poisson** </l>\n\nConsideremos  un experimento *Poisson*  con $\\lambda$ igual\nal promedio de eventos en una unidad de tiempo (u.t.).\n\nSi $t$ es una cantidad de tiempo en u.t., la v.a. $X_{t}$ definida como el número de eventos en el intervalo $(0,t]$ es una $Po(\\lambda\\cdot t)$.\n\nEl conjunto de variables $\\{X_t\\}_{t>0}$ recibe el nombre de **proceso de Poisson**.\n\n\n**Resumen de la distribución de Poisson  $X\\equiv Po(\\lambda)$**\n\n$X$ Poisson |  $\\lambda$\n-------:|:-------\n$D_X=$|  $\\{0,1,\\ldots \\}$ \n$P_X(x)=P(X=x)=$ | $\\left\\{\\begin{array}{ll}  \\frac{\\lambda^x}{x!}e^{-\\lambda}, & \\mbox{ si } x=0,1,\\ldots\\\\ 0,  & \\mbox{ en otro caso.}\\end{array}\\right.$\n$F_X(x)=P(X\\leq x)=\\sum_{i=0}^kP(X = i)=$ |  $\\begin{array}{l}\\left\\{\\begin{array}{ll} 0, & \\mbox{si } x<0,\\\\\\displaystyle\\sum_{i=0}^{k} \\frac{\\lambda^i}{i!}\\cdot e^{-\\lambda}, & \\mbox{si  }\\left\\{\\begin{array}{l}k\\leq x< k+1,\\\\k=0,1,2,\\ldots\\end{array}\\right.\\end{array}\\right.\\end{array}$ Calcular la suma o utilizar funciones de `R` o `Python`.   \n$E(X)=\\lambda$ | $Var(X)=\\lambda$\n\n\n**Resumen proceso   Poisson  $X_t\\equiv Po(\\lambda\\cdot t)$**\n\n$X_t$  $Po(\\lambda\\cdot t)$ |  $\\lambda$ promedio por u.t. \n-------:|:-------\n$D_X=$|  $\\{0,1,\\ldots \\}$ \n$P_X(x)=P(X=x)=$ | $\\left\\{\\begin{array}{ll}  \\frac{(\\lambda\\cdot t)^x}{x!}e^{-\\lambda\\cdot t} & \\mbox{ si } x=0,1,\\ldots\\\\ 0  & \\mbox{ en otro caso.}\\end{array}\\right.$\n$F_X(x)=P(X\\leq X)=\\sum_{i=0}^kP(X = i)=$ |  $\\begin{array}{l}\\left\\{\\begin{array}{ll} 0, & \\mbox{si } x<0,\\\\\\displaystyle\\sum_{i=0}^{k} \\frac{(\\lambda\\cdot t)^i}{i!}\\cdot e^{-\\lambda\\cdot t}, & \\mbox{si  }\\left\\{\\begin{array}{l}k\\leq x< k+1,\\\\k=0,1,2,\\ldots\\end{array}\\right.\\end{array}\\right.\\end{array}$ Calcular la suma o utilizar funciones de `R` o `Python`.   \n$E(X)=\\lambda\\cdot t$ | $Var(X)=\\lambda\\cdot t$\n\n**Aproximación de la distribución binomial por la Poisson**\n\nDada una variable aleatoria de distribución $B(n,p)$, si $n$ es grande y $p$ es pequeño podemos aproximar la distribución anterior por una distribución Poisson de parámetro $\\lambda=n\\cdot p$, $Po(\\lambda = n\\cdot p)$.\n\nUn criterio para decidir que la aproximación anterior es buena es que \n$n\\geq 20$, o mejor, $n\\geq 30$, $n\\cdot p < 10$  y  $p\\leq 0.05.$\n\nLa aproximación de la función de probabilidad de una variable binomial a una variable de Poisson es óptima en los valores cercanos a $E(X)=\\lambda$.\n\n**Gráficos de la aproximación binomial a la de Poisson**\n\nSuponemos que estamos en las condiciones anteriores: $n\\geq 20$,  $n\\cdot p < 10$, $p\\leq 0.05$.\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(6,\n         sliderInput(\"n_binomP\", label = \"Número de repeticiones n:\",\n              min = 1, max = 100, value =20 , step = 1)),\n  column(6,\n          sliderInput(\"p_binomP\", label = \"Probabilidad éxito p:\",\n                     min = 0.001, max = 0.9, value = 0.05, step = 0.001)\n         )\n  )\n)\n\nrenderPlot({\n  n=input$n_binomP\n  pr=input$p_binomP\n  par(mfrow=c(1,2))\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dbinom(c(0:n),size=n,prob=pr)\n  plot(x=c(0:n),y=dbinom(c(0:n),size=n,prob=pr),\n       ylim=c(0,0.6),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Funciones de probabilidad\\n B(n=\",n,\",p=\",pr,\"), \n                     Po(lambda=\",n*pr,\")\"),collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux,pch=21, type = \"h\", lty = 2,col=\"blue\")\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),n*pr)\n  points(x=c(0:n),y=dpois(c(0:n),n*pr),\n       ylim=c(0,0.6),xlim=c(-1,n+1),xlab=\"x\",pch=25,col=\"red\")\n  lines(x=rep(0:n,each=2),y=aux, type = \"h\", lty = 3,col=\"red\")\n  legend(\"topleft\",legend=c(\"Binomial\",\"Poisson\"),col=c(\"blue\",\"red\"), \n         pch=c(21,25),lty=c(2,3),bty = \"n\")\n  curve(pbinom(x,size=n,p=pr),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Funciones de distribución \\n B(n=\",n,\",p=\",pr,\"),\n                       Po(lambda=\",n*pr,\")\"),collapse = \"\"))\n  curve(ppois(x,n*pr),\n        xlim=c(-1,n+1),col=\"red\",add=TRUE)\n  if(all(c(n>=20,n*pr<10,pr<= 0.05))){aux_l=\"Condición\\n TRUE\"} else \n    {aux_l=\"Condición\\n FALSE\"}\n  legend(\"topleft\",legend=c(aux_l,paste0(\"n=\",n),paste0(\"n*p=\",n*pr),\n                            paste0(\"p=\",pr)),bg=\"transparent\",cex=0.8,bty = \"n\")\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_Poisson1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n\n\n<div class=\"example\">\n**Ejemplo de una distribución de Poisson $Po(\\lambda)$: trampa para insectos**\n\nLa conocida [lámpara antiinsectos o insecticida eléctrico](https://es.wikipedia.org/wiki/Insecticida_el%C3%A9ctrico) atrae a los insectos voladores con una luz ultravioleta  y los mata por electrocución. \n\nConsideremos la v.a. $X$ que cuenta el número de insectos caídos en la trampa en una hora. Supongamos que el número promedio de insectos que captura la trampa en una hora es $E(X)=20$ y que podemos admitir que $X$ sigue una ley de probabilidad $Po(\\lambda=20)$.\n\n\nNos piden \n\n1.  Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson. \n2.  Escribir de forma explícita la función de probabilidad  y de distribución de $X$.\n3.  Calculad la probabilidad de que en una hora caigan en la trampa  exactamente 21 insectos.\n4.  Calculad la probabilidad de que en una hora caigan en la trampa  al menos 6 insectos.\n5.  ¿Cuál es el valor esperando, la varianza y la desviación típica de $X$?\n\n\n\n\n<div class=\"example-sol\">\n\n**Solución 1.**  Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson. \n\n\n1. El número promedio de eventos en el intervalo $(0,1]$, una hora  es\n$\\lambda=20>0$.\n2. Es posible dividir el intervalo de tiempo  de una hora en un\ngran número de subintervalos (denotemos por $n$ al número de intervalos) de forma que:\n    + La probabilidad de que se produzcan dos o más  electrocuciones un subintervalo es despreciable. No es posible que dos mosquitos se electrocuten al mismo tiempo.\n    + El número de ocurrencias, electrocuciones de insectos, en un intervalo  es independiente del número de electrocuciones en otro intervalo.\n    + La probabilidad de que un evento ocurra en un subintervalo es $p_n=\\frac{\\lambda}{n}$· Podemos dividir los 20 insectos promedio entre los $n$ intervalos (trozo de hora) de forma que $p_n=\\frac{\\lambda}{n}$. \n    + Por ejemplo si $n=60$ tenemos que $p_n=\\frac{20}{60}=\\frac{1}{3}$. La probabilidad de que en un minuto la trampa chisporrotee es  $\\frac{1}{3}$.\n\n**Solución 2.** Escribid de forma explícita la función de probabilidad  y de distribución de $X$.\n\nLa distribución de probabilidad de un $Po(\\lambda)$ es\n\n$$\nP_X(x)=P(X=x)=\\left\\{\\begin{array}{ll}  \\frac{\\lambda^x}{x!}e^{-\\lambda}, & \\mbox{ si } x=0,1,\\ldots\\\\ 0,  & \\mbox{ en otro caso.}\\end{array}\\right.\n$$\n\nEn nuestro caso, $\\lambda =20$:\n$$\nP_X(x)=P(X=x)=\\left\\{\\begin{array}{ll}\\frac{20^x}{x!}e^{-20}, & \\mbox{ si } x=0,1,\\ldots\\\\ 0,  & \\mbox{ en otro caso.}\\end{array}\\right.\n$$\nLa función de distribución es:\n\n$$\nF_X(x)=P(X\\leq X)=\n\\left\\{\\begin{array}{ll} \n0, & \\mbox{si } x<0,\\\\\n\\displaystyle\\sum_{i=0}^{k} P(X=i)=\\sum_{i=0}^{k}\\frac{\\lambda^i}{i!}\\cdot e^{-\\lambda}, & \\mbox{si  }\n\\left\\{\\begin{array}{l}\nk\\leq x< k+1,\\\\k=0,1,2,\\ldots\n\\end{array}\n\\right.\n\\end{array}\n\\right.\n$$     \nEn nuestro caso:\n$$\nF_X(x)=P(X\\leq X)=\n\\left\\{\\begin{array}{ll} \n0, & \\mbox{si } x<0,\\\\\n\\displaystyle\\sum_{i=0}^{k} P(X=i)=\\sum_{i=0}^{k}\\frac{20^i}{i!}\\cdot e^{-20}, & \\mbox{si  }\n\\left\\{\\begin{array}{l}\nk\\leq x< k+1,\\\\k=0,1,2,\\ldots\n\\end{array}\n\\right.\n\\end{array}\n\\right.\n$$ \n**Solución 3.** Calculad la probabilidad de que en una hora caigan en la trampa  exactamente 21 insectos.\n\nNos piden la probabilidad siguiente:\n$$\nP(X=21)=\\frac{20^{21}}{21!} e^{-20}=0.0846051.\n$$\n\nPara realizar el cálculo anterior, podemos usar `R` como calculadora o usar la función `dpois` que nos calcula la función de distribución de la variable de Poisson:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n20^(21)/factorial(21)*exp(-20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08460506\n```\n:::\n\n```{.r .cell-code}\ndpois(21,lambda = 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08460506\n```\n:::\n:::\n\n\n\n**Solución 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.\n\n\nNos piden la probabilidad siguiente:\n$$\n\\begin{array}{rl}\n P(X\\geq 6)&=1- P(X<6)=1-P(X\\leq 5)=1-F_X(5)=1-\\displaystyle\\sum_{x=0}^{5} \\frac{20^{x}}{x!}\\cdot e^{-20}\\\\\n &=\n 1-\\left(\\frac{20^{0}}{0!}\\cdot e^{-20}+\\frac{20^{1}}{1!}\\cdot e^{-20}+\\frac{20^{2}}{2!}\\cdot e^{-20}+\\frac{20^{3}}{3!}\\cdot e^{-20}+\\frac{20^{4}}{4!}\\cdot e^{-20}+\\frac{20^{5}}{5!}\\cdot e^{-20}\\right)\\\\[1ex]\n &=\n 1-e^{-20}\\cdot \\left(1+20+\\frac{400}{4}+\\frac{8000}{6}+\\frac{160000}{24}+\\frac{3200000}{120}\\right)\\\\[1ex]\n &=\n 1-e^{-20} \\cdot \\left(\\frac{1 \\cdot 120+20\\cdot 120+400\\cdot 30+8000\\cdot 20+160000\\cdot 24+3200000\\cdot 1}{120}\\right)\\\\[1ex]\n &= 1-e^{-20}\\cdot\\left(\\frac{4186520}{120}\\right)=1-7.1908841\\times 10^{-5} =0.9999281.\n\\end{array}\n$$\n\n**Solución 5.**  ¿Cuál es el valor esperado, la varianza y la desviación típica de $X$?\n\n \nEl valor esperado del número de insectos caídos  en la trampa en una hora es:\n$$E(X)=\\lambda=20.$$\nSu varianza es \n$$Var(X)=\\lambda=20,$$\ny  su desviación típica vale:\n$$\\sqrt{Var(X)}=+\\sqrt{\\lambda}=+\\sqrt{20}=4.47214.$$\n</div>\n</div>\n\n**Cálculos con `R`**\n\nConsideremos por ejemplo una v.a. $X$ con distribución $Po(\\lambda=3)$. Calculemos $P_X(0)=P(X=0), P_X(1)=P(X=1)$ con `R`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndpois(0,lambda = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04978707\n```\n:::\n\n```{.r .cell-code}\ndpois(1,lambda = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1493612\n```\n:::\n:::\n\n\nSi quisiéramos hallar la función de distribución en los mismos valores anteriores, \n$F_X(0)=P(X\\leq 0), F_X(1)=P(X\\leq 1)$, haríamos lo siguiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppois(0,lambda = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04978707\n```\n:::\n\n```{.r .cell-code}\nppois(1,lambda = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1991483\n```\n:::\n\n```{.r .cell-code}\ndpois(0,lambda = 3)+dpois(1,lambda = 3) # es igual a ppois(1,lambda=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1991483\n```\n:::\n:::\n\n\n\nA continuación, comprobemos que $F_X(10)=\\sum\\limits_{x=0}^{10} P_X(x)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndpois(0:10,3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.0497870684 0.1493612051 0.2240418077 0.2240418077 0.1680313557\n [6] 0.1008188134 0.0504094067 0.0216040315 0.0081015118 0.0027005039\n[11] 0.0008101512\n```\n:::\n\n```{.r .cell-code}\nsum(dpois(0:10,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9997077\n```\n:::\n\n```{.r .cell-code}\nppois(10,3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9997077\n```\n:::\n:::\n\n\n\nSi quisiéramos generar una secuencia de $100$ observaciones para una distribución de Poisson de parámetro $\\lambda=3$, $Po(3)$, tendríamos que hacer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpois(n=100,lambda = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 2 5 3 3 2 2 5 2 4 4 2 3 2 2 2 2 2 3 3 5 3 3 2 4 2 3 2 1 1 3 4 6 2 5 3 4 1\n [38] 1 6 3 4 1 4 3 4 3 0 2 1 4 3 0 2 4 2 3 5 2 1 3 3 4 2 5 0 3 1 1 4 6 4 5 0 4\n [75] 0 3 3 3 4 1 2 6 2 2 2 2 1 2 5 2 5 3 7 3 5 2 3 2 1 3\n```\n:::\n:::\n\n\n<div class=\"exercise\">\n**Ejercicio de la trampa para insectos (continuación)**\n\nEn el ejercicio de la trampa para insectos  teníamos que $X$ es una $Po(20)$. Responded con `R`  a la preguntas 3 y 4 de este ejercicio\n\n<div class=\"example-sol\">\n**Pregunta 3.**  Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.\n\nRecordemos que la probabilidad pedida es $P(X=21)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndpois(21,lambda=20) # P(X=21)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08460506\n```\n:::\n:::\n\n\n**Pregunta 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.\n\nRecordemos que la probabilidad pedida es $P(X\\geq 6)=1-P(X<6)=1-P(X\\leq 5)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppois(5,lambda=20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7.190884e-05\n```\n:::\n\n```{.r .cell-code}\n1-ppois(5,lambda=20) # es 1-P(X<=5)=P(X>=6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9999281\n```\n:::\n\n```{.r .cell-code}\n# acumula hacia arriba P(X>5)=P(X>=6)=P(X=6)+P(X=7)+..\nppois(5,lambda=20,lower.tail =FALSE ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9999281\n```\n:::\n:::\n\n</div>\n</div>\n\n**Gráficos  de la distribución Poisson con `R`**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda=20\npar(mfrow=c(1,2))\nn=qpois(0.99,lambda=lambda)\naux=rep(0,(n+1)*2)\naux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)\nymax=max(ppois(0:n,lambda=lambda))\nplot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),\n     ylim=c(0,ymax),xlim=c(-1,n+1),xlab=\"x\",\n     main=paste0(c(\"Función de probabilidad\\n  Po(lambda=\",lambda,\")\"),\n                 collapse = \"\"))\nlines(x=rep(0:n,each=2),y=aux,pch=21, type = \"h\", lty = 2,col=\"blue\")\ncurve(ppois(x,lambda=lambda),\n      xlim=c(-1,n+1),col=\"blue\",\n      main=paste0(c(\"Función de distribución \\n Po(lambda=\",lambda,\")\"),\n                  collapse = \"\"))\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/graficosPOISON-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n**Gráficos  interactivos con `R`**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsliderInput(\"lambda\", label = \"Promedio de eventos lambda\",\n              min = 1, max = 100, value =20 , step = 1)\nrenderPlot({\n  lambda=input$lambda\n  par(mfrow=c(1,2))\n  n=qpois(0.99,lambda=lambda)\n  #n\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)\n  ymax=0.45\n  plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),\n       ylim=c(0,ymax),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Función de probabilidad\\n  Po(lambda=\",lambda,\")\"),\n                   collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux,pch=21, type = \"h\", lty = 2,col=\"blue\")\n  curve(ppois(x,lambda=lambda),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Función de distribución \\n Po(lambda=\",lambda,\")\"),\n                     collapse = \"\"))\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n\n<!--[![](Images/noshinyImages/interactiva_Poisson2.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n**Cálculos con `Python`**\n\nRealicemos los mismos cálculos realizados con `R` pero ahora usando `Python`. Recordemos que considerábamos una v.a. $X$ con distribución $Po(\\lambda=3)$. Calculemos $P_X(0)=P(X=0), P_X(1)=P(X=1)$ con `Python`\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import poisson\npoisson.pmf(0,mu = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.049787068367863944\n```\n:::\n\n```{.python .cell-code}\npoisson.pmf(1,mu = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.14936120510359185\n```\n:::\n:::\n\n\nSi quisiéramos hallar las funciones de distribución en los mismos valores anteriores,\n$F_X(0)=P(X\\leq 0), F_X(1)=P(X\\leq 1)$, tendríamos que hacer:\n\n::: {.cell}\n\n```{.python .cell-code}\npoisson.cdf(0,mu = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.04978706836786395\n```\n:::\n\n```{.python .cell-code}\npoisson.cdf(1,mu = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.1991482734714558\n```\n:::\n\n```{.python .cell-code}\npoisson.pmf(0,mu = 3)+poisson.pmf(1,mu= 3) # es igual a poisson.cdf(1,lambda=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.1991482734714558\n```\n:::\n:::\n\n\nLa comprobación de que $F_X(10)=\\displaystyle\\sum_{0}^{10} P_X(x)$ en `Python` se realiza de la forma siguiente:\n\n::: {.cell}\n\n```{.python .cell-code}\nrange(0,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrange(0, 10)\n```\n:::\n\n```{.python .cell-code}\npoisson.pmf(range(0,10),mu=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.04978707, 0.14936121, 0.22404181, 0.22404181, 0.16803136,\n       0.10081881, 0.05040941, 0.02160403, 0.00810151, 0.0027005 ])\n```\n:::\n\n```{.python .cell-code}\nsum(poisson.pmf(range(0,10),mu=3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9988975118698846\n```\n:::\n\n```{.python .cell-code}\npoisson.cdf(10,mu=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9997076630493527\n```\n:::\n:::\n\n\n<div class=\"exercise\">\n**Ejercicio de la trampa para insectos (continuación)**\n\nEn el ejercicio de la trampa para insectos  teníamos que $X$ es una $Po(20)$. Responded con `Python` a la preguntas 3 y 4 de este ejercicio\n\n<div class=\"example-sol\">\n**Pregunta 3.**  Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.\n\nRecordemos que la probabilidad pedida es  $P(X=21)$:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npoisson.pmf(21,mu=20) # P(X=21)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.08460506418293791\n```\n:::\n:::\n\n\n**Pregunta 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.\n\nLa probabilidad pedida es $P(X\\geq 6)=1-P(X\\leq 5)$:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n1-poisson.cdf(5,mu=20)  # es 1-P(X<=5)=P(X>=6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.9999280911594716\n```\n:::\n:::\n\n\n\nComo ya hemos visto con `scipy.stats`, podemos pedir los momentos de una variable aleatoria\n$Po(3)$\n\n\n::: {.cell}\n\n```{.python .cell-code}\npoisson.stats(mu=3, moments='mv')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(3.0, 3.0)\n```\n:::\n:::\n\n\nY también generar secuencias de observaciones aleatorias de una población $Po(3)$:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npoisson.rvs(mu=3,size=40)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([3, 1, 3, 2, 0, 4, 3, 3, 3, 3, 2, 0, 2, 1, 4, 2, 4, 1, 1, 7, 5, 1,\n       5, 3, 5, 5, 1, 3, 4, 4, 5, 1, 3, 3, 2, 3, 2, 0, 6, 3], dtype=int64)\n```\n:::\n:::\n\n</div>\n</div>\n\n**Gráficos con  `Python`**\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import poisson\nmu = 10 ## mu = lambda\nx = np.arange(poisson.ppf(0.01, mu),poisson.ppf(0.99, mu))\nfig =plt.figure(figsize=(5, 2.7))\nax = fig.add_subplot(1,2,1)\nax.plot(x, poisson.pmf(x, mu), 'bo', ms=5, label='Poisson pmf')\nax.vlines(x, 0, poisson.pmf(x, mu), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5) \nax = fig.add_subplot(1,2,2)\nax.plot(x, poisson.cdf(x, mu), 'bo', ms=5, label='Poisson cdf')\nax.vlines(x, 0, poisson.cdf(x, mu), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  tick.label.set_fontsize(5)\nfig.suptitle('Distribucion de Poisson')\nplt.show()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](3_files/figure-html/py_poiss2-1.png){width=480}\n:::\n:::\n\n\n\n**Gráficos interactivos para un proceso de Poisson $Po(\\lambda\\cdot t$)**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\n  fluidRow(\n      column(6,\n           sliderInput(\"lambdapp\", label=\"Promedio eventos por unidad de tiempo\", \n                       min = 0.1, max = 50, value =10 , step = 0.01)),\n    column(6,sliderInput(\"t\", label = \"Intervalo de tiempo (0,t]\", \n                         min = 1, max = 120, value =1 , step = 0.5))\n   )\n)\n\n\nrenderPlot({\n  lambda1=input$lambdapp\n  t=input$t\n  lambda=lambda1*t ## es lambda* t\n  par(mfrow=c(1,2))\n  n=qpois(0.99,lambda=lambda)\n  #n\n  aux=rep(0,(n+1)*2)\n  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)\n  ymax=ppois(which.max(ppois(0:n,lambda))-1,lambda)*0.7\n  plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),\n       ylim=c(0,ymax),xlim=c(-1,n+1),xlab=\"x\",\n       main=paste0(c(\"Función de probabilidad\\n  Po(lambda=\",lambda,\")\"),\n                   collapse = \"\"))\n  lines(x=rep(0:n,each=2),y=aux,pch=21, type = \"h\", lty = 2,col=\"blue\")\n  curve(ppois(x,lambda=lambda),\n        xlim=c(-1,n+1),col=\"blue\",\n        main=paste0(c(\"Función de distribución \\n Po(lambda=\",lambda,\")\"),\n                    collapse = \"\"))\n  par(mfrow=c(1,1))\n  })\n```\n:::\n\n\n<!--![[](Images/noshinyImages/interactivos_proceso_Poisson1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n\n<div class=\"example\">\n\n**Ejemplo: Número de impactos de insectos en la visera de un casco**\n\nUn colega de trabajo, al que llamaremos  JG, es muy aficionado a los grandes premios de velocidad tanto en coches como en motos.\n\nComo es tan aficionado, está obsesionado con  muchas de las más extravagantes estadísticas de estos deportes.\nEn particular le propusimos que estudiara el número de insectos que chocan contra la visera de un casco de un  motorista GP  o de un  conductor de fórmula 1 .\n\nLa idea es que el número de insectos  está igualmente repartido por todo el circuito y de promedio impactan $\\lambda>0$ insectos por minuto. También es razonable suponer que:\n\n* podemos dividir la superficie de la visera en cuadrados suficientemente pequeños de forma que la probabilidad de que caigan dos insectos en la misma zona es prácticamente 0. \n* la probabilidad de que un insecto impacte en  un cuadrado cualquiera  de la visera es independiente de cualquier otro cuadrado.\n* si hemos dividido la visera en $n$ cuadrados la probabilidad $p_n$ de impacto de un cuadrado vale $p_n=\\frac{\\lambda}{n}$.\n\nBajo estas condiciones,  si denotamos por $X_t$ como el número de insectos que ha impactado en la visera en  el intervalo $(0,t]$ (en $t$ minutos), podemos afirmar que $X_t$  es un proceso de  Poisson $Po(\\lambda\\cdot t)$.\n\nSupongamos que nos dicen que  $\\lambda=3$ insectos por minuto. Entonces el proceso de Poisson $X_t$ seguirá un ley $Po(3\\cdot t).$ \n\nNos piden las probabilidades siguientes:\n\n1. ¿Cuál es la probabilidad de que en 10 minutos impacten más de 25 insectos?\n2. ¿Cuál es la probabilidad de que tengamos que esperar más de 2 minutos para observar el primer impacto?\n\n\n\n<div class=\"exercise-sol\">\n\n**Solución de 1. ¿Cuál es la probabilidad de que en 10 minutos impacten más de 25 insectos?**\n\nEn este caso $t=10$ y $X_{10}$ es la variable aleatoria que nos da el número de insectos que impactan en 10 minutos o durante el intervalo $[0,10)$. La distribución de $X_{10}$ será de Poisson de parámetro $\\lambda=3\\cdot 10=30)$, $Po(30)$. \n\nNos piden la probabilidad siguiente: $P(X>25)=1-P(X\\leq 25)$, que calculamos con ayuda de `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-ppois(25,lambda=30)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7916426\n```\n:::\n:::\n\n\n**Solución de 2. ¿Cuál es la probabilidad de que tengamos que esperar más de 2 minutos para observar el primer impacto?**\n\nNos piden la probabilidad siguiente $P(X_2=0)$ ya que la variable $X_2$ nos dice el número de impactos en dos minutos. La distribución de $X_2$ será de Poisson de parámetro $\\lambda =2\\cdot 3=6$, $Po(6)$. Si hemos de esperar más de dos minutos para el primer impacto, significa que $X_2=0$:\n$$P(X_2=0)=\\frac{(6)^0}{0!}\\cdot e^{-6}= e^{-6}=0.002479.$$\nSi usamos `R`, obtenemos: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n6^0/factorial(0)*exp(-6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002478752\n```\n:::\n\n```{.r .cell-code}\nppois(0,lambda=3*2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002478752\n```\n:::\n:::\n\n\n\n</div>\n</div>\n\n### Distribución hipergeométrica\n\nSupongamos que disponemos de una  urna de sorteos que contiene $m$ bolas blancas y $n$ bolas rojas.\n\nEn total en esta urna  hay $m+n$ bolas, $m$ blancas y $n$ rojas. Si extraemos dos bolas de la urna lo podemos hacer de dos formas:\n\n* Extraer una, anotar su color y reponerla. Sacar otra y anotar su color. Hemos extraído  la bola con reposición.\n* Extraer simultáneamente dos bolas (sin reposición) y contar el número de bolas blancas.\n\nSea $X$ es la v.a. que cuenta el número de bolas blancas extraídas.\n\n* En el primer caso, $X$ es una $B(n=2,p=\\frac{m}{m+n})$  ya que consiste en  repetir dos veces el mismo experimento de Bernoulli.\n* En el segundo caso, $X$ sigue una distribución hipergeométrica que estudiaremos en esta sección.\n\n\n<l class=\"definition\"> **Distribución hipergeométrica** </l>\n\nSean $n$, $m$ y $k$ tres número enteros positivos y tales  que $k<m+n$.\n\nConsideremos una urna que contiene $m+n$ bolas de las que $m$ son blancas y las restantes $n$ no (son no blancas).\n\nEl número total de bolas es $m+n$. Extraemos  de forma aleatoria $k$ bolas de la urna sin reemplazarlas.\n\nSea  $X$ la v.a. que cuenta el número de bolas blancas extraídas. Diremos que la distribución de $X$ es hipergeométrica de parámetros $m$, $n$ y $k$ y la denotaremos por $H(m,n,k)$.\n\nSu dominio es \n\n$$D_X=\\left\\{x\\in\\mathbb{N}\\mid \\max\\{0,k-n\\}\\leq  x \\leq \\min\\{m,k\\}\\right\\}$$\n\n\nPara explicarlo,  veamos varios ejemplos: \n\n* $H(m=5,n=2,k=3)$. Tenemos  $m=5$ bolas blancas, $n=2$ no blancas y sacamos $k=3$ bolas sin reposición.\n  + En este caso el mínimo de bolas blancas extraídas es $1=k-n=3-2$, ya que sólo hay dos no blancas.\n  + En cambio, el máximo sí es $k=3$, ya que tenemos bolas blancas de \"sobra\". \n\n* $H(m=2,n=5,k=3)$. Tenemos $m=2$ bolas blancas, $n=5$ no blancas y sacamos $k=3$ bolas sin reposición. \n  + En este caso el mínimo de bolas blancas es $0$ ya que puedo sacar 3 no blancas.\n  + En cambio, el máximo sí es $m=2$, ya que aunque saquemos $k=3$ bolas, al llegar a 2 ya hemos  extraído todas las bolas blancas de la urna. \n\n* $H(m=10,n=10,k=3)$. Tenemos $m=10$ bolas blancas, $n=10$ no blancas y sacamos $k=3$ bolas sin reposición. \n  + En este caso podemos obtener desde $0$ blancas hasta $k=3$ blancas.\n\nSu función de probabilidad es:\n$$\nP_{X}(x)=\\left\\{\n\\begin{array}{ll}\n\\frac{\\binom{m}{x}\\cdot \\binom{n}{k-x}}{\\binom{m+n}{k}}, & \\mbox{ si }\n\\max\\{0,k-n\\}\\leq x \\leq \\min\\{m,k\\}, \\mbox { para  } x\\in \\mathbb{N},\\\\\n0,  & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n\n\n\n<l class=\"observ\"> **Observación: otras parametrizaciones** </l>\n\n\nEn ocasiones se parametriza una v.a. hipergeométrica mediante $N=m+n$, número total de bolas, \n$k$, número de extracciones y $p$, probabilidad de extraer una bola blanca. \n\n\nAsí, podemos **parametrizar alternativamente** la distribución hipergeométrica como\n$H(N,k,p)$ donde $p=\\frac{m}{N}.$\n\n**Resumen  hipergeométrica  $H(m,n,k)$**\n\n$X=H(m,n,k)$ | Número de bolas blancas en $k$ extracciones sin reposición de una urna con $m$ bolas blancas y $n$ no blancas\n------:|:------\n$D_X$= | $\\left\\{x\\in\\mathbb{N}\\mid \\max\\{0,k-n\\}\\leq  x \\leq \\min\\{m,k\\}\\right\\}$\n$P_X(x)=P(X=x)=$ | $\\left\\{ \\begin{array}{ll} \\frac{\\binom{m}{x}\\cdot \\binom{n}{k-x}}{\\binom{m+n}{k}}, & \\mbox{si } x\\in[\\max\\{0,k-n\\},\\min\\{m,k\\}] \\\\ 0,  & \\mbox{en otro caso.}\\end{array}\\right.$\n$F_X(x)=P(X\\leq x)$ | Hay que sumarla. Utilizad funciones de `R` o de `Python`.\n$E(X)=\\frac{k\\cdot m}{m+n}$   | $Var(X)=k\\cdot\\frac{m}{m+n}\\cdot\\left(1-\\frac{m}{m+n}\\right) \\cdot\\frac{m+n-k}{m+n-1}$ \n\n\n<div class=\"example\">\n**Ejemplo: urna con $m=15$ blancas, $n=10$ rojas y $k=3$ extracciones sin reposición**\n\nTenemos una urna con 15 bolas blancas y 10 bolas rojas. Extraemos al azar tres bolas de la urna sin reposición. Sea  $X$ el número de bolas **blancas** extraídas. Bajo estas condiciones, la v.a. $X$ sigue una ley de distribución $H(m=15,n=10,k=3)$.\n\nNos piden:\n\n1. Hallar la función de probabilidad de $X$.\n2. Probabilidad de sacar dos bolas blancas.\n3. Probabilidad de sacar más de una bola blanca.\n4. Esperanza, varianza y desviación típica de $X$.\n\n\n<div class=\"example-sol\">\n\n**Solución de 1. Hallar la función de probabilidad de $X$**\n\nLa función de probabilidad de $X$ es: \n$$\nP_X(x)=P(X=x)=\\left\\{\n\\begin{array}{ll}\n\\frac{\\binom{m}{x}\\cdot \\binom{n}{k-x}}{\\binom{m+n}{k}}, & \\mbox{ si }\n\\max\\{0,k-n\\}\\leq x \\leq \\min\\{m,k\\}, \\mbox { para  } x\\in \\mathbb{N},\\\\\n0,  & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n\nSustituyendo los parámetros $m,n$ y $k$ por $m=15$, $n=10$ y $k=3$, obtenemos:\n\n$$\nP_X(x)=P(X=x)=\\left\\{\n\\begin{array}{ll}\n\\frac{\\binom{15}{x}\\cdot \\binom{10}{3-x}}{\\binom{25}{3}}= \\frac{\\binom{15}{x}\\cdot \\binom{10}{3-x}}{2300}, & \\mbox{ si }\n0\\leq x \\leq 3, \\mbox { para  } x\\in \\mathbb{N},\\\\\n0,  & \\mbox{en otro caso.}\\end{array}\\right.\n$$\n\n\n**Solución de 2. Probabilidad de sacar dos bolas blancas**\n\nLa probabilidad de sacar 2 blancas será:\n$$\nP(X=2)=\\frac{\\binom{15}{2}\\cdot \\binom{10}{3-2}}{\\binom{25}{3}}\n$$ \n\nSi calculamos con ayuda de `R` los números binomiales involucrados en la expresión anterior, obtenemos:\n\n::: {.cell}\n\n```{.r .cell-code}\nc(choose(15,2), choose(10,1), choose(25,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  105   10 2300\n```\n:::\n:::\n\n\nLa probabilidad pedida, será, pues:\n$P(X=2)=\\frac{105\\cdot10 }{2300}=0.4565217.$\n\n\n::: {.cell}\n\n:::\n\n\n**Solución de 3. Probabilidad de sacar más de una bola blanca**\n\nLa probabilidad de que saquemos más de 1 bola blanca es:\n$$\n\\begin{array}{rl}\nP(X> 1)&= 1-P(X\\leq 1)=1-(P(X=0)+P(X=1))\\\\\n&=\n1-\\left(\\frac{\\binom{15}{0}\\cdot \\binom{10}{3}}{\\binom{25}{3}}+\n\\frac{\\binom{15}{1}\\cdot \\binom{10}{2}}{\\binom{25}{3}}\\right)\\\\\n&=\n1-\\left(\n\\frac{1\\cdot120 }{2300}+\\frac{15\\cdot45 }{2300}\n\\right)=1-\\frac{120+15\\cdot 45}{2300}=0.6543478.\n\\end{array}\n$$\n\n**Solución de 4. Esperanza, varianza y desviación típica de $X$**\n\nEl número esperado de  bolas blancas extraídas para una v.a. $X$ de distribución $H(m=15,n=10,k=3)$ es:\n\n$$E(X)=\\frac{k\\cdot m}{m+n}=\\frac{3\\cdot 15}{15+10}=\\frac{45}{35}=1.285714.$$\nLa varianza vale:\n$$\n\\begin{array}{rl}\nVar(X)&=k\\cdot\\frac{m}{m+n}\\cdot\\left(1-\\frac{m}{m+n}\\right) \\cdot\\frac{m+n-k}{m+n-1}\\\\\n&=3\\cdot\\frac{15}{15+10}\\cdot\\left(1-\\frac{15}{15+10}\\right) \\cdot\\frac{15+10-3}{15+10-1}\\\\\n&=\n3\\cdot\\frac{15}{25}\\cdot\\left(1-\\frac{15}{25}\\right) \\cdot\\frac{22}{24}= \n3\\cdot\\frac{15}{25}\\cdot\\frac{25-15}{25} \\cdot\\frac{22}{24}\\\\\n&=\n3\\cdot\\frac{15}{25}\\cdot\\frac{10}{25}\\cdot\\frac{22}{24}=0.66.\n\\end{array}\n$$\n\nY por lo tanto, su desviación típica es:\n\n$$\n+\\sqrt{Var(X)}=+\\sqrt{0.66}=0.812404.\n$$\n\n</div> \n</div>\n\n\n**Cálculos con `R`**\n\nSea $X$ una v.a. $H(m,n,k)$. La función de `R` para calcular la función de probabilidad en un valor $x$, $P(X=x)$, es `dhyper(x,m,n,k)` y para calcular la función de distribución en un valor $q$, $P(X\\leq q)$, es `phyper(q,m,n,k)`. Para generar una muestra de valores que siga la distribución $H(m,n,k)$, hay que usar la función `rhyper(nn,m,n,k)` donde `nn` es el número de observaciones aleatorias deseado de la muestra.\n\nPor ejemplo, si $X$ es una $H(m=15,n=10,k=3)$, los valores de $P(X=2)$ y que $P(X>1)=1-P(X\\leq 1)$ son:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndhyper(x=2,m=15,10,k=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4565217\n```\n:::\n\n```{.r .cell-code}\nphyper(q=1,m=15,n=10,k=3)## sí, le han puesto q ya veremos el porqué\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3456522\n```\n:::\n\n```{.r .cell-code}\n1-phyper(q=1,m=15,n=10,k=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6543478\n```\n:::\n:::\n\n\nUna muestra aleatoria de este experimento de tamaño 200 sería:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrhyper(nn=200,m=15,n=10,k=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 2 3 1 3 1 2 2 3 2 2 1 2 1 2 2 3 3 1 1 1 1 0 2 3 2 1 3 2 2 2 2 3 2 3 3 2 0\n [38] 1 2 1 3 2 2 3 2 3 2 2 3 2 3 1 2 2 2 2 3 2 2 1 3 2 2 3 1 2 2 2 2 2 3 0 2 0\n [75] 3 2 2 2 1 2 2 3 1 1 1 2 2 2 2 1 1 3 2 2 3 2 2 1 1 1 3 3 2 2 2 1 3 2 2 2 1\n[112] 1 2 3 2 2 1 2 2 2 2 2 2 3 1 2 3 3 1 1 2 2 1 1 3 2 1 1 2 2 3 1 1 1 2 1 1 3\n[149] 1 2 2 3 3 2 3 1 2 1 2 2 2 1 2 3 1 3 3 3 2 2 1 3 3 1 1 2 2 2 2 2 3 2 1 2 1\n[186] 1 1 1 2 1 1 2 2 2 2 3 3 1 0 2\n```\n:::\n:::\n\n\n**Gráficas  con `R`**\n\nLos gráficos de la función de probabilidad y de la función de distribución en `R` se realizan de la forma siguiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nm=15\nn=10\nk=3\na=max(c(0,k-n))\nb=min(c(m,k))\nl=b-a+1\naux=rep(0,2*l)\naux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)\nx=a:b\nplot(x,y=dhyper(x,m=m,n=n,k=k),\n  ylim=c(0,0.6),xlim=c(a-1,b+1),xlab=\"x\",\n  main=paste0(\"Función de probabilidad\\n H(m=\",m,\", n=\",n,\", k=\",k,\")\"))\nlines(x=rep(a:b,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\ncurve(phyper(x,m=m,n=n,k=k),\n  xlim=c(a-1,b+1),col=\"blue\",\n  main=paste0(\"Función de distribución\\n H(m=\",m,\", n=\",n,\", k=\",k,\")\"))\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-62-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n**Gráficos interactivos $H(m,n,k)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(4,\n         sliderInput(\"mh\", label = \"Número de bolas blancas m\",\n              min = 1, max = 50, value =15, step = 1)),\n  column(4,\n         sliderInput(\"nh\", label = \"Número de bolas rojas n\",\n              min = 1, max = 50, value =10 , step = 1)),\n  column(4,\n          sliderInput(\"kh\", label = \"Número bolas extraídas k\",\n                     min = 1, max=25, value = 3, step = 1)\n         )\n  )\n)\n\nrenderPlot({\n  m=input$mh\n  n=input$nh\n  k=input$kh\n  #n=10\n  #k=3\n  #m=15\n  par(mfrow=c(1,2))\n  a=max(c(0,k-n))\n  b=min(c(m,k))\n  l=b-a+1\n  aux=rep(0,times=2*l)\n  aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)\n  x=a:b\n  plot(x,y=dhyper(x,m=m,n=n,k=k),\n       ylim=c(0,0.6),xlim=c(a-1,b+1),xlab=\"x\",\n       main=paste0(\"Función de probabilidad\\n H(m=\",m,\", n=\",n,\", k=\",k,\")\"))\n  lines(x=rep(a:b,each=2),y=aux, type = \"h\", lty = 2,col=\"blue\")\n  curve(phyper(x,m=m,n=n,k=k),\n        xlim=c(a-1,b+1),col=\"blue\",\n        main=paste0(\"Función de distribución\\n H(m=\",m,\", n=\",n,\", k=\",k,\")\"))\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactivos_hiper_geom1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n**Comparación $H(m,n,k)$ y $B\\left(k,\\frac{m}{n+m}\\right)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(4,\n         sliderInput(\"mh2\", label = \"Número de bolas blancas m\",\n              min = 1, max = 50, value =15, step = 1)),\n  column(4,\n         sliderInput(\"nh2\", label = \"Número de bolas rojas n\",\n              min = 1, max = 50, value =10 , step = 1)),\n  column(4,\n          sliderInput(\"kh2\", label = \"Número bolas extraídas k\",\n                     min = 1, max=25, value = 3, step = 1)\n         )\n  )\n)\n\nrenderPlot({\n  m=input$mh2\n  n=input$nh2\n  k=input$kh2\n  #n=10\n  #k=3\n  #m=15\n  pr=round(m/(n+m),4)\n  a=max(c(0,k-n))\n  b=min(c(m,k))\n  l=b-a+1\n  aux=rep(0,times=2*l)\n  auxB=rep(0,times=2*(k+1))\n  aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)\n  x=a:b\n  auxB[seq(2,2*(k+1),2)]=dbinom(0:k,k,pr)\n  par(mfrow=c(1,2))\n  plot(x=c(0:k),y=dbinom(c(0:k),size=k,prob=pr),\n       ylim=c(0,0.6),xlim=c(-1,k+1),xlab=\"x\",\n       main=paste0(\"Funciones de probabilidad\\n B(n=\",n,\"p=\",pr,\")  \n                   H(m=\",m,\"n=\", n,\"k=\",k,\")\"))\n  lines(x=rep(0:k,each=2),y=aux,pch=21, type = \"h\", lty = 2,col=\"blue\")\n  #aux=rep(0,(n+1)*2)\n  #aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),n*pr)\n  points(x=c(a:b),y=dhyper(c(a:b),m=m,n=n,k=k),\n         ylim=c(0,0.6),xlim=c(-1,k+1),xlab=\"x\",pch=25,col=\"red\")\n  lines(x=rep(0:(l-1),each=2),y=aux, type = \"h\", lty = 3,col=\"red\")\n  legend(\"topleft\",legend=c(\"Binomial\",\"Hipergeométrica\"),col=c(\"blue\",\"red\"),\n         pch=c(21,25),lty=c(2,3))\n  curve(pbinom(x,size=k,p=pr),\n        xlim=c(-1,k+1), col=\"blue\", \n         main=paste0(\"Funciones de distribución\\n B(\",k,\",\",pr,\") \n                     H(m=\",m,\"n=\", n,\"k=\",k,\")\"))\n  curve(phyper(x,m=m,n=n,k=k),\n        xlim=c(-1,k+1),col=\"red\",add=TRUE)\n  #if(all(c(n>=20,n*pr<10,pr<= 0.05))){aux_l=\"Condición VERDADERA\"} \n  else {aux_l=\"Condición FALSA\"}\n  #legend(\"topleft\",legend=c(aux_l,paste0(\"n=\",n),paste0(\"n*p=\",n*pr),\n  paste0(\"p=\",pr)),bg=\"transparent\",cex=0.5)\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactivos_hipergeom_binom1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n**Cálculos con `Python`**\n\n\nSea $X$ una $H(m,n,k)$. Las funciones de `scipy.stats` cambian los parámetros de la forma siguiente:\n\n\n* $M$ es el número total de bolas. Con nuestra parametrización $M=m+n$.\n* $n$ es el número de bolas blancas. Con nuestra parametrización $n=m$.\n* $N$  es el número de extracciones. Con nuestra parametrización $N=k$.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import hypergeom\n```\n:::\n\n\nLos cálculos realizados anteriormente en `R` serían: \n\n::: {.cell}\n\n```{.python .cell-code}\nhypergeom.pmf(1,M=15+10,n=15,N=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.2934782608695652\n```\n:::\n\n```{.python .cell-code}\nhypergeom.cdf(1,M=15+10,n=15,N=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.3456521739130434\n```\n:::\n\n```{.python .cell-code}\n1-hypergeom.cdf(1,M=15+10,n=15,N=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.6543478260869566\n```\n:::\n:::\n\n\nUna muestra aleatoria de este experimento sería:\n\n::: {.cell}\n\n```{.python .cell-code}\nhypergeom.rvs(M=15+10,n=15,N=3,size=100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1,\n       2, 1, 3, 1, 2, 0, 2, 1, 3, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 0, 2,\n       3, 0, 1, 1, 3, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 3, 1, 2, 2,\n       1, 2, 1, 3, 3, 1, 1, 2, 2, 2, 3, 1, 1, 1, 2, 2, 1, 3, 2, 2, 1, 2,\n       3, 3, 3, 2, 2, 1, 3, 1, 3, 1, 1, 0], dtype=int64)\n```\n:::\n:::\n\n\n\nLos gráficos de la función de probabilidad y de la función de distribución en python se realizan de la forma siguiente:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import hypergeom\n[M, n, N] = [20, 7, 12] ##20 elementos, 7 del tipo, extraemos 12\nx = np.arange(max(0, N-M+n),min(n, N))\nfig =plt.figure(figsize=(5, 2.7))\n =ax = fig.add_subplot(1,2,1)\n =ax.plot(x, hypergeom.pmf(x, M, n, N), 'bo', ms=5, label='hypergeom pmf')\n =ax.vlines(x, 0, hypergeom.pmf(x, M, n, N), colors='b', lw=2, alpha=0.5)\n =ax.set_ylim([0, max(hypergeom.pmf(x, M, n, N))*1.1])\nfor tick in ax.xaxis.get_major_ticks():\n   =tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n  =tick.label.set_fontsize(5) \nax = fig.add_subplot(1,2,2)\n =ax.plot(x, hypergeom.cdf(x, M, n, N), 'bo', ms=5, label='hypergeom cdf')\n =ax.vlines(x, 0, hypergeom.cdf(x, M, n, N), colors='b', lw=2, alpha=0.5)\nfor tick in ax.xaxis.get_major_ticks():\n   =tick.label.set_fontsize(5)\nfor tick in ax.yaxis.get_major_ticks():\n   =tick.label.set_fontsize(5)\n =fig.suptitle('Distribucion Hipergeometrica')\n =plt.show()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](3_files/figure-html/py_hyper2-1.png){width=480}\n:::\n:::\n\n\n\n## Cuantiles de distribuciones notables discretas\n\n<div class=\"example\">\n**Ejemplo**\n\nConsideremos una v.a. $X$ de distribución $B(5,0.5)$. \n\nLos cuantiles $x_{0.3}$, $x_{0.6}$ y $x_{0.8}$ son los siguientes:\n\n\n::: {.cell sixe='small'}\n\n```{.r .cell-code}\nqbinom(c(0.3,0.6,0.8),5,0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3 3\n```\n:::\n:::\n\n\nCalculemos a mano, el valor $x_{0.3}$ y verifiquemos que da el mismo resultado que nos ha dado `R`.\n\nLa función de distribución de $X$ es:\n$$\n\\small{\nF_x(x)=P(X\\leq x)=\n\\left\\{\n\\begin{array}{ll}\n0, & x< 0, \\\\\n0.03125, & \\mbox{ si } 0 \\leq x< 1, \\\\\n0.18750, & \\mbox{ si } 1 \\leq x< 2, \\\\\n0.50000, & \\mbox{ si } 2 \\leq x< 3, \\\\\n0.81250, & \\mbox{ si } 3 \\leq x< 4, \\\\\n0.96875, & \\mbox{ si } 4 \\leq x< 5, \\\\\n1.00000, & \\mbox{ si }  5\\leq x. \\\\\n\\end{array}\n\\right.}\n$$\n\nEl cuantil $q=0.3$ es el  primer valor $x\\in D_X$  tal que $F_X(x)=P(X\\leq x_{0.3})\\geq 0.3$. Mirando la expresión anterior, comprobamos que $x_{0.3}=2$ ya que $F_X(2)=P(X\\leq 2)=0.5 \\geq 0.3$.\n</div>\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nCalcular los cuantiles de  $0.6$ y $0.8$ de una $B(5,0.5).$\n</div>\n\n\n**Gráfico interactivo que muestra los cuantiles de las distribuciones $B(n,p)$ y $Po(\\lambda)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(3,\n         sliderInput(\"nq\", label = \"Par. n B(n,p)\",\n              min = 1, max = 20, value =10 , step = 1)\n         ),\n  column(3,\n          sliderInput(\"pq\", label = \"Par. p B(n,p)\",\n                     min = 0.01, max = 0.99, value = 0.5, step = 0.1)\n         ),\n  column(3,\n         sliderInput(\"qq\", label=\" Cuantil q\", value=0.75, min = 0.01, max = 0.99, \n                     step = 0.01)\n         ),\n  column(3,\n         sliderInput(\"lq\", label=\"Par. lambda Po(lambda)\", value=5, min = 1, max = 20, \n                     step = 1)\n         )\n  )\n)\n\n  \nrenderPlot({\n  n=input$nq\n  p=input$pq\n  q=input$qq\n  lambda=input$lq\n  par(mfrow=c(1,2))\n  #n=10;p=0.5;q=0.75;lambda=5\n  #xx=c(seq(min(a,x),min(b,x),by=0.001))\n  probsB=pbinom(0:n,n,p)\n  curve(pbinom(x,n,p),xlim=c(0-0.25,n+0.25),ylim=c(0,max(probsB+0.05,0.1)),\n        col=\"blue\",main=paste0(\"Función distribución\\n B(n=\",n,\", p=\",p,\")\"),\n        ylab=paste0(\"dbinom(x,\",n,\", \",p,\")\"),yaxt=\"n\")\n  segments(x0 = qbinom(q,n,p),y0 = 0,x1 = qbinom(q,n,p),y1 = q,lty=2,col=\"red\")\n  segments(x0 = qbinom(q,n,p),y0 = q,x1 = -0.25,y1 = q,lty=2,col=\"red\")\n  ytick=c(0.0,q,1)\n  axis(side=2, at=ytick, labels = TRUE)\n  axis(side=1, at=qbinom(q,n,p), labels = TRUE)\n  curve(ppois(x,lambda),xlim=c(0-0.25,2.5*lambda),ylim=c(0,1+0.1),\n        col=\"blue\",main=paste0(\"Función distribución \\n Po(lambda=\",lambda,\")\"),\n        ylab=paste0(\"dpois(x, lambda\",lambda,\")\"),yaxt=\"n\")\n  segments(x0 = qpois(q,lambda),y0 = 0,x1 = qpois(q,lambda),y1 = q,lty=2,col=\"red\")\n  segments(x0 = qpois(q,lambda),y0 = q,x1 = -0.25,y1 = q,lty=2,col=\"red\")\n  ytick=c(0.0,q,1)\n  axis(side=2, at=ytick, labels = TRUE)\n  axis(side=1, at=qpois(q,lambda), labels = TRUE)\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_cuantiles1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n## Distribuciones continuas\n\n### Distribución uniforme \n\nUna v.a. continua $X$ tiene una distribución uniforme sobre el intervalo real $(a,b)$ ,con $a<b$, si su función de densidad es \n\n$$\nf_X(x)=\\left\\{\\begin{array}{ll}\n\\frac1{b-a}, & \\mbox{si } a<x<b,\\\\ 0,  & \\mbox{en cualquier otro caso.}\n\\end{array}\n\\right. \n$$ \n\n<div class=\"exercise\">\n\n**Ejercicio**\n\nComprobar que el área comprendida entre $f_X$ y la horizontal\nvale 1.\n\n\n<div class=\"exercise-sol\">\nEl área pedida vale:\n$$\n\\int_{-\\infty}^{+\\infty} f_x(x)\\cdot dx=\\int_{a}^{b} \\frac{1}{b-a} \\cdot dx=\\left.\\frac{x}{b-a}\\right]_{x=a}^{x=b}=\\frac{b}{b-a}-\\frac{a}{b-a}=\n\\frac{b-a}{b-a}=1.\n$$\n</div>\n</div>\n\nSu función de distribución es:\n$$\nF_X(x)=\\left\\{\\begin{array}{ll} 0,  & \\mbox{si } x\\leq a,\\\\\n\\frac{x-a}{b-a}, & \\mbox{si } a<x<b,\\\\ 1,  & \\mbox{si } b\\leq x.\n\\end{array}\n\\right. \n$$\nEfectivamente:\n\n* Si $x\\leq a$, entonces \n$$F_X(x)=\\int_{-\\infty}^{x} f(t)\\cdot dt= \\int_{-\\infty}^{x} 0\\cdot dt.$$\n* Si $a<x<b$ entonces ,\n$$\n\\begin{array}{rl}\nF_X(x)&=\\displaystyle\\int_{-\\infty}^{x} f(t)\\cdot dt= \\int_{-\\infty}^{a} 0\\cdot dt+\\int_{a}^{x} \\frac1{b-a} \\cdot dt\\\\\n&= \\displaystyle 0 +\\left.\\frac{t}{b-a}\\right]_{t=a}^{t=x}= \\frac{x}{b-a}-\\frac{a}{b-a}=\\frac{x-a}{b-a}.\n\\end{array}\n$$\n* Por último si $x\\geq b$ entonces,\n\n$$\n\\begin{array}{rl}\nF_X(x)&=\\displaystyle\\int_{-\\infty}^{x} f(t) dt=\\int_{a}^{b} \\frac{1}{b-a} dt=\n  \\left.  \\frac{t}{b-a} \\right]_{t=a}^{t=b}\n\\\\&=\\displaystyle \\frac{b}{b-a}-\\frac{a}{b-a}=\\frac{b-a}{b-a}=1.\n\\end{array}\n$$\n\n\nDenotaremos a la v.a. $X$ uniforme en el intervalo $(a,b)$ por  $U(a,b)$.\n\n\n**Esperanza y varianza  para una v.a. $X$ $U(a,b)$**\n\nCalculemos la esperanza de $X$:\n\n$$\n\\begin{array}{rl}\nE(X)&=\\displaystyle\\int_{-\\infty}^{+\\infty} x\\cdot f_X(x) dx =\\int_{a}^{b} x \\cdot \\frac{1}{b-a} dx =\n\\left.\\frac{x^2}{2\\cdot (b-a)}\\right]_{x=a}^{x=b}\\\\\n&=\\displaystyle \\frac{b^2}{2\\cdot (b-a)}-\\frac{a^2}{2\\cdot (b-a)}=\n\\frac{b^2-a^2}{2\\cdot (b-a)}=\\frac{(b+a)\\cdot (b-a)}{2\\cdot (b-a)}=\n\\frac{b+a}{2}.\n\\end{array}\n$$\n\nDe cara a calcular su varianza, calculemos primero la esperanza de $X^2$:\n\n$$\n\\begin{array}{rl}\nE(X^2)&=\\displaystyle\\int_{-\\infty}^{+\\infty} x^2 f_X(x) dx=\\int_{a}^{b} x^2 \\frac1{b-a}\ndx =\\left.\\frac{x^3}{3\\cdot (b-a)}\\right]_{x=a}^{x=b} \\\\\n&=\\displaystyle\\frac{b^3-a^3}{3\\cdot (b-a)}=\\frac{b^2+ab+a^2}{3}.\n\\end{array}\n$$\n\n<div class=\"exercise\">\n\n**Ejercicio**\n\n* Demostrad que la  igualdad  $b^3-a^3=(b-a)\\cdot (b^2+ab+a^2)$ es cierta.\n\n* Utilizadla para el cálculo final del valor de  $E(X^2)$.\n\n</div>\n\n\nCalculemos $Var(X)$.\n$$\n\\begin{array}{rl}\nVar(X)&=\\displaystyle E(X^2)-(E(X))^2=\\frac{b^2+ab+a^2}3-\\left(\\frac{b+a}2\\right)^2\\\\&=\\displaystyle\n\\frac{b^2+ab+a^2}{3}-\\frac{b^2+2ab+a^2}{4}\\\\\n&=\\displaystyle\n\\frac{4\\cdot (b^2+ab+a^2)-3\\cdot (b^2+2ab+a^2)}{4\\cdot 3}\n\\\\\n&=\\displaystyle\n\\frac{b^2-2ab+a^2}{12}=\n\\frac{(b-a)^2}{12}.\n\\end{array}\n$$\n\n\n\n**Gráficas $U(0,1)$**\n\nEl código en `R` para dibujar la función de densidad y la función de distribución de una distribución $U(0,1)$ es el siguiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\na=0;b=1\ncurve(dunif(x,a,b),xlim=c(a-0.25,b+0.25),ylim=c(0,max(1/(b-a)+0.05,0.1)),\n      col=\"blue\",main=paste0(\"Función densidad  U(\",a,\",\",b,\")\"),\n      ylab=paste0(\"dunif(x,\",a,\", \",b,\")\")\n      )\ncurve(punif(x,a,b),xlim=c(a-1,b+1),ylim=c(0,1.1),\n      col=\"blue\",main=paste0(\"Función de distribución U(\",a,\",\",b,\")\"),\n      ylab=paste0(\"punif(x,\",a,\", \",b,\")\",cex.axis=0.8)\n      )\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/grafica_unif10_vista-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n**Gráficas interactivas  $U(a,b)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(4,\n         sliderInput(\"a1\", label = \"Parámetro a\",\n              min = -5, max = 9, value =0 , step = 0.1)\n         ),\n  column(4,\n          sliderInput(\"b1\", label = \"Parámetro b\",\n                     min = 10, max = 15, value = 5, step = 0.1)\n         ),\n  column(4,\n         sliderInput(\"x1\", label=\"x\", value=9, min = -5, max = 15, step = 0.1)\n         )\n  \n)\n)\n\nrenderPlot({\n  a=input$a1\n  b=input$b1\n  x=input$x1\n  par(mfrow=c(1,2))\n  #a=0;b=1;x=0.25\n  xx=c(seq(min(a,x),min(b,x),by=0.001))\n  curve(dunif(x,a,b),xlim=c(a-0.25,b+0.25),ylim=c(0,max(1/(b-a)+0.05,0.1)),\n        col=\"blue\",main=paste0(\"Función densidad U(\",a,\",\",b,\")\"),\n  ylab=paste0(\"dunif(x,\",a,\", \",b,\")\"),xaxt=\"n\")\n  axis(side=1, at=c(a,x,b), labels = TRUE)\n  polygon(x=c(a,xx,min(x,b)),y=c(0,dunif(xx,a,b),0),\n          density=20,col=\"skyblue\")\n  curve(punif(x,a,b),xlim=c(a-1,b+1),ylim=c(0,1.1),col=\"blue\",\n        main=paste0(\"Función de distribución U(\",a,\",\",b,\")\"),\n  ylab=paste0(\"punif(x,\",a,\", \",b,\")\"),xaxt=\"n\",yaxt=\"n\")\n  segments(x0=x,y0=0,x1=x,y1=punif(x,a,b),col=\"red\",lty=2)\n  segments(x0=a-1.01,y0=punif(x,a,b),x1=x,y1=punif(x,a,b),col=\"red\",lty=2)\n  axis(side=2, at=c(0,round(punif(x,a,b),1),2), labels = TRUE)\n  axis(side=1, at=c(a,x,b), labels = TRUE)\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_uniforme1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n**Transformación lineal de la v.a. uniforme**\n\n\nSi $X$ sigue una distribución $U(a,b)$ entonces  $Z=\\frac{X-a}{b-a}$ sigue una distribución $U(0,1)$.\n\n\n<div class=\"prop\">\n\n**Propiedad: Transformación lineal de la v.a. uniforme**\n</div>\n\nSea $X$ una v.a  $U(a,b)$.\n\nSi $scale\\not=0$ y $loc$ son dos constantes reales, entonces \n\n* si $scale>0$, $T=scale\\cdot X+loc$ sigue una ley $U(scale\\cdot a +loc,scale\\cdot b +loc)$  \n* si $scale<0$, $T=scale\\cdot X+loc$ sigue una ley $U(scale\\cdot b +loc,scale\\cdot a +loc)$\n\n<div class=\"dem\">\n**Demostración**\n\nSupongamos  que $X$ sigue una ley $U(a,b)$, que $scale>0$ y que $T=scale\\cdot X+loc$. Dejamos el caso $scale<0$ como ejercicio.\n\nLa función de distribución de $X$ es:\n$$\nF_X(x)=P(X\\leq x)=\\left\\{\\begin{array}{ll} 0, & \\mbox{ si } x\\leq a,\\\\\\frac{x-a}{b-a}, & \\mbox{ si } a\\leq x\\leq b, \\\\1, & \\mbox{ si } b\\leq x.\\end{array}\\right.\n$$\n\nSi $T$ vale $T=scale\\cdot X+loc$, su función de distribución será:\n$$\n\\begin{array}{rl}\nF_T(t)&=P(T\\leq t)= P(scale\\cdot X+ loc\\leq t)= P\\left(X\\leq \\frac{t-loc}{scale}\\right)=F_X\\left(\\frac{t-loc}{scale}\\right)\\\\\n&=\n\\left\\{\\begin{array}{ll} 0, & \\mbox{ si } \\frac{t-loc}{scale}\\leq a\\\\\\frac{\\frac{t-loc}{scale}-a}{b-a}, & \\mbox{ si } a\\leq \\frac{t-loc}{scale}\\leq b,\\\\1, & \\mbox{ si } b\\leq \\frac{t-loc}{scale},\\end{array}\\right. \\\\ & =\n\\left\\{\\begin{array}{ll} 0, & \\mbox{ si }  t\\leq scale\\cdot a +loc, \\\\\n\\frac{t-(scale\\cdot a+loc)}{scale\\cdot (b-a)}, & \\mbox{ si } scale\\cdot a+loc \\leq t\\leq scale\\cdot b+loc, \\\\\n1, & \\mbox{ si } scale\\cdot b+loc\\leq t, \\end{array}\\right.\\\\\n& = \n\\left\\{\\begin{array}{ll} 0, & \\mbox{ si }  t\\leq scale\\cdot a +loc, \\\\\n\\frac{t-(scale\\cdot a+loc)}{scale\\cdot b+loc-(scale\\cdot a+loc)}, & \\mbox{ si } scale\\cdot a+loc \\leq t\\leq scale\\cdot b+loc, \\\\\n1, & \\mbox{ si } scale\\cdot b+loc\\leq t,\\end{array}\\right.\n\\end{array}\n$$\nfunción que corresponde a la función de distribución de una v.a. $U(scale\\cdot a+loc,scale\\cdot b+loc)$, como queríamos demostrar.\n</div>\n\n\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nSea $X$ una variable $U(0,1)$ y sea $T=scale\\cdot X+loc$:\n\n* Si $T$ es $U(-5,5)$  ¿qué  valores toman $scale$ y $loc$?\n\n* Si $loc=-10$ y $scale=10$ ¿qué distribución de probabilidad sigue  $T$?\n\n* Si $loc=0$ y $scale=-1$ ¿qué distribución probabilidad sigue  $T$?\n\n</div>\n\n**Resumen v.a con distribución uniforme, $U(a,b)$**\n\nDistribución uniforme | $U(a,b)$\n----:|:-----\nDominio | $D_X=(a,b)$\n$f_{X}(x)$ |$\\left\\{\\begin{array}{ll}\\frac1{b-a}, & \\mbox{si } a<x<b,\\\\ 0,  & \\mbox{en cualquier otro caso.}\\end{array} \\right.$\n$F_X(x)=P(X\\leq X)=$ |  $\\left\\{\\begin{array}{ll} 0, & \\mbox{ si } x\\leq a\\\\\\frac{x-a}{b-a}, & \\mbox{ si } a\\leq x\\leq b,\\\\1, & \\mbox{ si } b\\leq x.\\end{array}\\right.$\n$E(X)= \\frac{a+b}2$ | $Var(X)=\\frac{(b-a)^2}{12}$\n\n**Cálculos con `R`**\n\nSea $X$ una $v.a.$ $U(a,b)$. Las funciones `dunif(x,a,b)` y `punif(x,a,b)` calculan la función de densidad y de distribución de $X$ en el valor $X$. Por ejemplo, para $a=-1$, $b=1$ y $x=0.5$, los valores $f_X(x)$ y $F_X(x)$ valen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndunif(x=0.5, min=-1,max=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n\n```{.r .cell-code}\npunif(q=0.5,min=-1,max=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.75\n```\n:::\n:::\n\n\nLa función `runif(n,a,b)` calcula una muestra de observaciones de tamaño $n$ que sigan la distribución $U(a,b)$:\n\n::: {.cell}\n\n```{.r .cell-code}\nrunif(n=5,min=-1,max=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.5502232 -0.4271506 -0.0515360  0.8052209  0.8983523\n```\n:::\n:::\n\n\n\nPor defecto, el valor de los parámetros `a` y `b` son 0 y 1, respectivamente:\n\n::: {.cell}\n\n```{.r .cell-code}\ndunif(x=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\npunif(q=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n\n```{.r .cell-code}\nrunif(n=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.382302539 0.009313886 0.351767001 0.294007361 0.071581515\n```\n:::\n:::\n\n\n\n**Cálculos con `Python`**\n\nSea $X$ una $v.a.$ $U(-1,1)$. Tomando como \"base\" la v.a. $U(0,1)$, los parámetros `loc` y `scale` valen: `loc`$=-1$ y `scale`$=2$, ya que como hemos visto $X=2*U(0,1)-1=U(-1,1)$.\n\nEn `Python`, hay que usar dichos parámetros para calcular la función de densidad y de distribución:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import uniform\nuniform.pdf(0.5,loc=-1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.5\n```\n:::\n\n```{.python .cell-code}\nuniform.ppf(0.5,loc=-1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.0\n```\n:::\n:::\n\n\nPara generar una muestra de valores aleatorios, hay que usar la función `uniform.rvs`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nuniform.rvs(size=30,loc=-1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([-0.04208311,  0.45548824,  0.15187719,  0.4132503 , -0.53019528,\n        0.51809723,  0.02690642, -0.96190905, -0.2792067 , -0.85690832,\n        0.15675933, -0.87506114,  0.1001445 ,  0.03516636, -0.87645003,\n       -0.56584916,  0.21904362, -0.26658281,  0.70775295, -0.34361467,\n       -0.86430923,  0.92457966,  0.22364512, -0.00269087,  0.14790735,\n       -0.66153089,  0.80981738,  0.38044956,  0.57406121,  0.85747765])\n```\n:::\n:::\n\n\nLos valores de los parámetros por defecto son `loc`=0, `scale`=1:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nuniform.pdf(0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.0\n```\n:::\n\n```{.python .cell-code}\nuniform.ppf(0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.5\n```\n:::\n\n```{.python .cell-code}\nuniform.rvs(size=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.93962542, 0.01053494, 0.42834543, 0.35923708, 0.24747305])\n```\n:::\n:::\n\n\n\n\n\n\n\n### Distribución exponencial\n\n**Distribución del tiempo entre dos eventos Poisson**\n\nSupongamos que tenemos un proceso Poisson con parámetro $\\lambda$ en una unidad de tiempo.\n\nDado un tiempo $t$, definimos $N_{t}$ como el número de eventos en el intervalo de tiempo $(0,t]$. La distribución de $N(t)$ es una $Po(\\lambda\\cdot t)$. Consideremos la v.a. $T$ como el tiempo transcurrido entre dos eventos Poisson consecutivos.\n\nSea $t>0$, entonces\n\n$$\n\\begin{array}{rl}\nP(T>t)&=P(\\mbox{Cero eventos en el intervalo}(0,t])\\\\\n&=P(N_{t}=0)=\n         \\frac{(\\lambda t)^0}{0!} e^{-\\lambda\n         t}=e^{-\\lambda t}.\n\\end{array}\n$$\n\nTomando complementarios, la función de distribución de $T$ será:\n$$\nF_{T}(t)= P(T\\leq t)=1-P(T>t)=\\left\\{\\begin{array}{ll} 0, &\\mbox{ si } t\\leq 0,\\\\\n  1-e^{-\\lambda t},& \\mbox{ si } t>0,\\end{array}\\right.\n$$\n\nPara hallar la función de densidad de $T$, basta derivar la expresión anterior:\n\n$$\nf_{T}(t)=\\left\\{\\begin{array}{ll}\\lambda \\cdot e^{-\\lambda t}, & \\mbox{ si }  t>0,\\\\\n0, & \\mbox{ si } t\\leq 0. \\end{array}\\right.\n$$\n\nLlamaremos a la variable $T$ exponencial de parámetro $\\lambda$ y la denotaremos por $Exp(\\lambda)$.\n\n\n**Propiedad de la falta de memoria**\n\nSea $X$  una v.a. $Exp(\\lambda)$, entonces\n\n$$P(X>s+t\\big|X>s)=P(X>t)\\mbox{  para todo } s,t\\in \\mathbb{R}$$\n\n<div class=\"dem\">\n**Demostración**\n\nSi $X$ es una v.a. $Exp(\\lambda)$ tenemos que $P(X>x)=1-P(X\\leq x)=1-(1-e^{-\\lambda\\cdot x})=e^{-\\lambda\\cdot x}$ para todo $x>0$.\n\nPor tanto,\n$$\n\\begin{array}{rl}\nP(X>s+t\\big|X>s) & =\\frac{P(\\{X>s+t\\}\\cap \\{X>s\\})}{P(X>s)}=\\frac{P(X>s+t)}{P(X>s)}=\\frac{e^{-\\lambda\\cdot (s+t)}}{e^{-\\lambda\\cdot s}}=\n\\frac{e^{-\\lambda\\cdot s}\\cdot e^{-\\lambda\\cdot t} }{e^{-\\lambda\\cdot s}}\\\\ & =e^{-\\lambda\\cdot t}=P(X>t).\n\\end{array}\n$$\n</div>\n\n\n<div class=\"example\"> \n**Ejemplo: el clásico problema del peluquero.** \n\nUna pequeña peluquería es regentada por un único peluquero. El peluquero está esperando al próximo cliente mientras lee el periódico. \n\nSupongamos que la v.a. $N_T$, que representa el número de clientes  que llegan en el intervalo $[0,t)$, es una $Po(\\lambda\\cdot t)$ entonces la variable $T$, tiempo entre dos clientes consecutivos, sigue una ley $Exp(\\lambda)$.\n\nSupongamos que $t$ se mide en horas y que $\\lambda=4$ es el promedio de clientes por hora.\n\nSe pide:\n\n1. El tiempo esperado (en horas) y la varianza hasta el siguiente cliente.\n2. ¿Cuál es la probabilidad de que nuestro peluquero esté sin  clientes (leyendo el periódico) más de 30 minutos (0.5 horas)?\n\n\n<div class=\"example-sol\">\n\nEn este ejemplo, la propiedad de la pérdida de memoria significa que\npor ejemplo, si el peluquero lleva ya esperando más de $s>0.25$ (un cuarto de hora),  la probabilidad de que espere $t=1/6$ de hora más (10 minutos) no cambia, sigue siendo $P(T>0.25+1/6|T>0.25)=P(T>1/6).$\n\n**Solución de 1. El tiempo esperado (en horas) y la varianza hasta el siguiente cliente.**\n\nEl tiempo esperado (en horas) hasta el siguiente cliente es\n\n$$\nE(X)=\\frac{1}{\\lambda}=\\frac{1}{4}=0.25,\n$$\ny la varianza es \n$$\nVar(X)=\\frac{1}{\\lambda^2}=\\frac{1}{4^2}=0.0625.\n$$\n**Solución de 2. ¿Cuál es la probabilidad de que nuestro peluquero esté sin  clientes (leyendo el periódico) más de 30 minutos (0.5 horas)?**\n\nLa probabilidad pedida vale:\n$$\nP(X>0.5)=1-P(X\\leq 0.5)=1-(1-e^{-4\\cdot 0.5 })=e^{-2}=0.1353353.\n$$\n\nUsando `R`, la probabilidad anterior puede ser calculada de la forma siguiente: \n\n\n::: {.cell}\n\n```{.r .cell-code}\npexp(0.5,rate=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7768698\n```\n:::\n\n```{.r .cell-code}\n1-pexp(0.5,rate=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2231302\n```\n:::\n\n```{.r .cell-code}\npexp(0.5,rate=3,lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2231302\n```\n:::\n:::\n\n\n</div>\n</div>\n\n**Cálculos  con `R`**\n\nLas funciones de densidad y de distribución de una variable exponencial de parámetro $\\lambda$ en un valor `x` se pueden obtener en `R` usando las funciones `dexp(x,lambda)` y `pexp(x,lambda)`, respectivamente. Para generar `n` valores aleatorios de una  variable exponencial de parámetro $\\lambda$, hay que usar la función  `rexp(n,lambda)`. Veamos un ejemplo de aplicación de las tres funciones anteriores:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndexp(0.001,rate=3) # Alerta! No es una probabilidad, es una densidad y puede ser > 1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.991013\n```\n:::\n\n```{.r .cell-code}\npexp(0.5,rate=3) # P(X<0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7768698\n```\n:::\n\n```{.r .cell-code}\nrexp(10,3) # Diez tiempos de una exponencial con lambda = 3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.32072389 0.57998323 0.26019628 0.48896233 0.31041354 0.11871455\n [7] 0.10798351 0.18699902 0.10023100 0.03619832\n```\n:::\n:::\n\n\n\n**Cálculos  con `Python`**\n\nLas funciones de densidad y de distribución de una variable exponencial de parámetro $\\lambda$ en un valor `x` se pueden obtener en `Python` usando las funciones `expon.pdf(x,scale=1/lambda)` y `expon.cdf(x,scale=1/lambda)`, respectivamente. Para generar `n` valores aleatorios de una  variable exponencial de parámetro $\\lambda$, hay que usar la función  `expon.rvs(scale=1/lambda,size=n)`. Veamos un ejemplo de aplicación de las tres funciones anteriores:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import expon\nexpon.pdf(0.0001,scale= 1./3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.9991001349865014\n```\n:::\n\n```{.python .cell-code}\nexpon.cdf(0.5,scale= 1./3) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.7768698398515702\n```\n:::\n\n```{.python .cell-code}\nexpon.rvs(scale=1./3,size=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.44594051, 0.17501543, 0.15181699, 0.04122309, 0.5163329 ,\n       0.10074632, 0.50528277, 0.12163518, 0.01210824, 0.08287172])\n```\n:::\n:::\n\n\n\n**Resumen v.a con distribución exponencial, $Exp(\\lambda)$**\n\n$X$ | $Exp(\\lambda)$\n------:|:------\n$D_X=$  | $(0,+\\infty)$ \n$f_{X}(x)=$ | $\\left\\{\\begin{array}{ll}\n\\lambda e^{-\\lambda x}, & \\mbox{ si }  x>0,\\\\\n0, & \\mbox{ si } x\\leq 0.\n\\end{array}\\right.$\n$F_X(x)=P(X\\leq X)=$ | $\\left\\{\\begin{array}{ll} 0, &\\mbox{si } x\\leq 0,\\\\\n1-e^{-\\lambda x},& \\mbox{si } x>0.\\end{array}\\right.$\n$E(X)=\\frac{1}{\\lambda}$ | $Var(X)=\\frac{1}{\\lambda^2}$ |\n\n**Gráficas de las funciones de  densidad y de distribución de la variable aleatoria $Exp(\\lambda=10)$**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda=10\npar(mfrow=c(1,2))\ncurve(dexp(x,rate=lambda),xlim=c(-0.05,round(qexp(0.99,rate=lambda,2),2)+0.25),\n      ylim=c(0,dexp(0,lambda)+0.1),col=\"blue\",\n      main=paste0(\"Función densidad Exp(\",lambda,\")\"),\n      ylab=paste0(\"dexp(x,rate=\",lambda,\")\"))\ncurve(pexp(x,rate=lambda),xlim=c(-0.05,qexp(0.999,10)),ylim=c(0,1.1),col=\"blue\",\n      main=paste0(\"Función de distribución Exp(\",lambda,\")\"),\n      ylab=paste0(\"pexp(x,rate=\",lambda,\")\"))\npar(mfrow=c(1,1))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-76-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nConsultad  en el manual de `Python` [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html). \n\nDibujad la función de densidad y de distribución de una $Exp(\\lambda=10).$\n\n</div>\n\n\n**Gráficas interactivas de una variable $Exp(\\lambda)$**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(4,\n         sliderInput(\"le\", label = \"lambda\",\n              min = 0.1, max = 3, value =1 , step = 0.1)\n         ),\n  column(4,\n          sliderInput(\"xe\", label = \"X=x\",\n                     min = 0, max = 5, value = 5, step = 0.1)\n         ),\n  column(4,\n          sliderInput(\"pe\", label = \"Cuantil p\",\n                     min = 0.01, max = 1, value = 0.75, step = 0.01)\n         )\n)\n)\n\nrenderPlot({\n  lambda=input$le\n  p=input$pe\n  x=input$xe\n  #lambda=10;p=0.75;x=0.4\n  xx=seq(0,x,by=0.001)\n  par(mfrow=c(1,2))\n  curve(dexp(x,rate=lambda),xlim=c(-0.05,round(qexp(0.999,rate=lambda),2)),\n        ylim=c(0,dexp(0,lambda)+0.1),col=\"blue\",\n        main=paste0(\"Función densidad Exp(\",lambda,\")\"),\n  ylab=paste0(\"dexp(x,\",lambda,\")\"),xaxt=\"n\")\n  axis(side=1, at=c(0,x,round(qexp(0.999,rate=lambda),2)),cex.axis=0.8)\n  polygon(x=c(0,xx,max(x,xx)),y=c(0,dexp(xx, rate=lambda),0),\n          density=20,col=\"skyblue\")\n  curve(pexp(x,rate=lambda),xlim=c(0.01,qexp(0.999,rate=lambda)+0.1),\n        ylim=c(0,1.1),col=\"blue\",\n        main=paste0(\"Función de distribución Exp(\",lambda,\")\"),\n        ylab=paste0(\"pexp(x,\",lambda,\")\"),xaxt=\"n\",yaxt=\"n\")\n  segments(x0=qexp(p,lambda),x1=qexp(p,lambda),y0=0,y1=p,col=\"red\",lty=2)\n  segments(x0=0-0.05,y0=p,x1=qexp(p,lambda),y1=p,col=\"red\",lty=2)\n  axis(side=2, at=seq(0,1,0.1), labels = TRUE)\n  axis(side=1, at=seq(0,round(qexp(0.999,rate=lambda),2),by=0.1), labels = TRUE)\n  par(mfrow=c(1,1))\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_exponencial1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n<div class=\"exercise\">\n**Ejercicio: las bombillas que no envejecen.**\n\nSupongamos que compramos una bombilla led que promete un **valor esperado** de duración de 10000 (1.14 años) horas de funcionamiento continuo. Además, nos aseguran que la distribución de $X$, el número de horas de funcionamiento continuo de una bombilla led, sigue una ley  exponencial.\n\n* Si $X$ es $Exp(\\lambda)$ ¿cuál es el valor del parámetro  $\\lambda$?.\n* ¿Cuál es la probabilidad de que una bombilla led ilumine más de 2 años?\n* Supongamos que ya tengo una bombilla led funcionando 1 año ¿Cuál es la probabilidad de que dure dos años más?\n* ¿Cuál es la varianza de la duración  en horas de este tipo de bombillas?\n\n</div>\n\n\n\n### Distribución normal o Gaussiana\n\n\n\nUna de las variables  aleatorias  continua más populares  es la llamada    distribución normal o [Gaussiana](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal).\n\n<l class=\"def\"> **Distribución normal o de Gauss**</l>\nDiremos que una v.a. $X$ sigue una ley normal de parámetros\n$\\mu$ y $\\sigma$ y la denotaremos por $N(\\mu,\\sigma)$\nsi tiene por función de densidad:\n\n$$\nf_{X}(x)=\\frac1{\\sqrt{2\\cdot\\pi\\cdot\\sigma^2}}\ne^{-\\frac{1}{2}\\cdot\\left(\\frac{x-\\mu}{\\sigma}\\right)^2},\n$$\npara todo $x\\in \\mathbb{R}.$\n\n\nLa gráfica de esta función de densidad es conocida como **campana de Gauss.**\n\nLa v.a. normal con $\\mu=0$ y $\\sigma=1$ recibe el nombre de\nnormal estándar y se suele denotar por la letra $Z\\sim N(0,1)$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncurve(dnorm(x),main=\"Función de densidad de una normal estándar\",xlim=c(-3.9,3.9))\n```\n\n::: {.cell-output-display}\n![](3_files/figure-html/normaldensidad1-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n<l class=\"prop\"> **Propiedades de la función de densidad de la distribución normal**</l>\n\nSea $X$ una v.a. $N(\\mu,\\sigma)$ y sean $f_{X}$ su función de densidad y $F_X(x)=\\displaystyle\\int_{-\\infty}^x f_X(t)\\, dt$ su función de distribución. Entonces:\n\n1. La función $f_{X}$ verifica todas las propiedades de las funciones de densidad: $f_X(x)>0$, para todo $x\\in\\mathbb{R}$ y $\\displaystyle\\int_{-\\infty}^\\infty f_X(x)\\,dx=1$.\n1. La función $f_X(x)$ es simétrica respecto de la recta $x=\\mu$: $f_{X}(\\mu-x)=f_{X}(\\mu+x)$, para todo $x\\in\\mathbb{R}$.\n1. $f_{X}$ tiene un único máximo absoluto en $x=\\mu$ que vale $f_X(\\mu)=\\frac1{\\sqrt{2\\pi\\sigma^2}}$.\n1. Si $F_{X}$ es la función de distribución de $X$, entonces $F_{X}(\\mu+x)=1-F_{X}(\\mu-x)$, para todo $x\\in\\mathbb{R}$. \n1. En particular, si $Z$ es una $N(0,1)$, entonces $F_{Z}(-x)=1-F_{Z}(x)$ para todo $x\\in\\mathbb{R}$.\n1. $Z=\\frac{X-\\mu}{\\sigma}$ es una v.a. $N(0,1)$ y $X=\\sigma\\cdot Z+\\mu$ es una $N(\\mu,\\sigma)$ donde $Z$ es la normal estándar.\n1. La función $f_X$ es continua.\n1.  $\\lim\\limits_{x\\to+\\infty}f(x)=\\lim\\limits_{x\\to-\\infty}f(x)=0$ es decir tiene asíntota horizontal a derecha e izquierda.\n1. $f$ es estrictamente creciente si $x<\\mu$ y decreciente si $x>\\mu$.\n1. Tiene dos puntos de inflexión en $x=\\mu+\\sigma$ y en $x=\\mu-\\sigma$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-77-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](3_files/figure-html/unnamed-chunk-78-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n**Función de distribución de la N(0,1)**\n\nSu función de distribución es, como sabemos:\n\n$$\nF(x)=\\displaystyle\\int_{-\\infty}^{x} {1\\over{\\sqrt{2\\cdot \\pi}}}\ne^{-{{x^2}\\over 2}} dt.\n$$\n\nLa función $F(x)$ no tiene ninguna expresión algebraica \"decente\". Es por esta razón, y  por comodidad, que esta función está tabulada o hay que calcularla usando un software estadístico.\n\n\n\n**Resumen v.a con distribución normal, $N(\\mu,\\sigma)$**\n\n$X$  | $N(\\mu,\\sigma)$ \n-----:|:--------\n$D_X=$ | $\\mathbb{R}=(-\\infty,+\\infty)$\n$f_{X}(x)$ |$=\\frac{1}{\\sqrt{2\\pi\\cdot\\sigma^2}}\\cdot e^{\\frac{-(x-\\mu)^2}{2\\cdot \\sigma^2}}\\mbox{ para todo }x\\in \\mathbb{R}.$\n$F_X(x)=P(X\\leq X)=$ | Utilizad la función de `R` `pnorm(x,mean=mu,sd=sigma)` o la función correspondiente en `Python `\n$E(X)=\\mu.$ | $Var(X)=\\sigma^2.$\n\n\n**Cálculos con `R`**\n\nLas funciones que calculan la función de densidad y de distribución de una variable $N(\\mu,\\sigma)$ en un valor `x` son `dnorm(x,mean=mu,sd=sigma)` y `pnorm(x,mean=mu,sd=sigma)`, respectivamente. Por ejemplo, para una variable $X\\sim N(\\mu=1,\\sigma=2)$, la función de densidad $f_X(2)$ se puede calcular de la forma siguiente:\n \n\n::: {.cell}\n\n```{.r .cell-code}\ndnorm(2,mean=1,sd=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1760327\n```\n:::\n:::\n\ny la función de distribución $F_X(2) = P(X\\leq 2)$ de la forma siguiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(2,mean=1,sd=2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6914625\n```\n:::\n:::\n\n\n\nSi queremos calcular el cuantil $x_{q}$ de una distribución normal $N(\\mu,\\sigma)$ que, recordemos es el valor que cumple  que $P(X\\leq x_{q})=q$, tenemos que usar la función `qnorm(q,mean=mu,sd=sigma)`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(0.95,mean=1,sd=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.289707\n```\n:::\n:::\n\n\nPara generar `n` valores aleatorios de una distribución normal $N(\\mu,\\sigma)$, hay que usar la función `rnorm(n,mean=mu,sd=sigma)`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrnorm(n=5,mean=1,sd=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1.7813382  0.7320555  2.7209162  2.9098518  2.5098235\n```\n:::\n:::\n\n\n\n**Cálculos con `Python`**\n \nPara poder trabajar con una distribución normal $N(\\mu,\\sigma)$ en `Python`, tenemos que importar `norm` de `scipy.stas`. Los parámetros $\\mu$ y $\\sigma$ son `loc` y `scale`, respectivamente.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom scipy.stats import norm\n```\n:::\n\n\nPor ejemplo, para una variable $X\\sim N(\\mu=1,\\sigma=2)$, la función de densidad $f_X(2)$ se puede calcular de la forma siguiente:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnorm.pdf(2,loc=1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.17603266338214976\n```\n:::\n:::\n\n\ny la función de distribución $F_X(2) = P(X\\leq 2)$, de la forma siguiente:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnorm.cdf(2,loc=1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.6914624612740131\n```\n:::\n:::\n\n\nSi queremos calcular el cuantil $x_{q}$ de una distribución normal $N(\\mu,\\sigma)$, tenemos que usar la función `norm.ppf(q,loc=mu,scale=sigma)`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnorm.ppf(0.95,loc=1,scale=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4.289707253902945\n```\n:::\n:::\n\n\nPara generar `n` valores aleatorios de una distribución normal $N(\\mu,\\sigma)$, hay que usar la función `norm.rvs(loc=mu,scale=sigma,size=n)`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnorm.rvs(loc=1,scale=2,size=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([ 0.78810709,  0.53449512, -2.4886133 , -2.4283068 ,  2.43413703])\n```\n:::\n:::\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nConsultad [SciPy.org](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) para dibujar las funciones de densidad y de distribución con `Python`.\n</div>\n\n\n**Gráficas interactivas usando los parámetros de la distribución normal**\n\nPara ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfluidPage(\nfluidRow(\n  column(3,\n         sliderInput(\"m1\", label = \"mu1\",\n              min = -10, max = 10, value =0 , step = 0.05)\n         ),\n  column(3,\n          sliderInput(\"s1\", label = \"sigma1\",\n                     min =0.1, max = 5, value = 1, step = 0.1)\n         ),\n  column(3,\n         sliderInput(\"m2\", label=\"mu2\", value=4, min = -10, max = 10, step = 0.05)\n         ),\n  column(3,\n          sliderInput(\"s2\", label = \"sigma2\",\n                     min =0.1, max = 5, value = 1, step = 0.1)\n         )\n  \n)\n)\n\nrenderPlot({\n  m1=input$m1\n  m2=input$m2\n  s1=input$s1\n  s2=input$s2\n  mins2=min(c(s1^2,s2^2))\nm=min(c(qnorm(0.01,m1,s1),qnorm(0.01,m2,s2)))\nM=max(c(qnorm(0.99,m1,s1),qnorm(0.99,m2,s2)))\n\ncurve(dnorm(x,m1,s1),xlim=c(m,M),ylim=c(0,1/sqrt(2*pi*mins2)),col=\"red\",lty=1)\nlegend(\"toplef\",legend=c(expression(N(mu[1],sigma[1])),\n                         expression(N(mu[2],sigma[2]))),\n       col=c(\"red\",\"blue\"),lty=c(1,2))\ncurve(dnorm(x,m2,s2),add=TRUE,col=\"blue\",lty=2)\n})\n```\n:::\n\n\n<!--[![](Images/noshinyImages/interactiva_normal1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)-->\n\n\n**Transformaciones lineales de variables aleatorias normales**\n\n<l class=\"prop\"> **Propiedad: transformación lineal la distribución  normal** </l>\n\nSea $X$ una variable  $N(\\mu,\\sigma)$  entonces la variable $Y=a X+b$ con\n$a\\not=0,b\\in\\mathbb{R}$ tiene distribución $N(a\\mu+b, |a|\\cdot\\sigma)$\n\nEn el caso particular en que $a=\\frac1{\\sigma}$ y $b=\n\\frac{-\\mu}{\\sigma}$ obtenemos la v.a. $Z={{X-\\mu}\\over {\\sigma}}$, que\nse distribuye según una normal estándar $N(0,1)$, es decir $E(X)=0$ y $Var(X)=1$. Dicha operación se denomina estandarización de la \ndistribución normal.\n\nLa propiedad anterior nos permite calcular la función de distribución de cualquier v.a. $N(\\mu,\\sigma)$ a partir de la función de distribución de la distribución $Z=N(0,1)$:\n$$\nF_X(x)=P(X\\leq x)=P\\left(\\frac{X-\\mu}{\\sigma}\\leq \\frac{x-\\mu}{\\sigma}\\right)=P\\left(Z\\leq \\frac{x-\\mu}{\\sigma}\\right)=F_Z \\left(\\frac{x-\\mu}{\\sigma}\\right).\n$$\nEntonces, basta conocer la manera de calcular $F_Z$ para poder calcular $F_X$, para $X=N(\\mu,\\sigma)$, para cualquier $\\mu$ y cualquier $\\sigma>0$.\n\n**Propiedades de la distribución normal estándar**\n\nSea $Z$ una $N(0,1)$.\n\nEn este caso, $\\mu=0$ y $\\sigma=1$. Podemos escribir algunas de las propiedades vistas para una distribución normal cualquiera de la forma siguiente:\n\n* La propiedad $f_X(\\mu-x)=f_X(\\mu+x)$ se traduce a $f_Z(-x)=f_Z(x)$\n* La propiedad $F_X(\\mu-x)=1-F_X(\\mu+x)$ se traduce a $F_Z(-x)=1-F(x).$\n* Dado $\\delta>0$, \n$$\nP(-\\delta\\leq Z \\leq \\delta)=F_{Z}(\\delta)-F_{Z}(-\\delta)=F_Z(\\delta)-(1-F_Z(\\delta))=\n2\\cdot F_Z(\\delta)-1.\n$$\n\n\n<div class=\"exercise\"> \n\n**Ejercicio: cálculos con la distribución normal estándar** \n\nSea  $Z$  una distribución $N(0,1)$. Calcular las siguientes probabilidades en función de $F_Z$:\n\n* $P(-4\\leq Z \\leq 4).$\n* $P(-2\\leq Z \\leq 2).$\n* $P(Z\\leq -2).$\n* $P( Z \\leq 2).$\n* $P( Z \\geq 2).$\n* $P( Z > 2).$\n* $P( Z = 2).$\n* $P( Z \\geq -2).$\n\n\n\n\n<div class=\"example-sol\">\n\nResolución:\n\n* $P(-4\\leq Z \\leq 4)=F_{Z}(4)-F_{Z}(-4)=2\\cdot F_Z(4)-1$.\n* $P(-2\\leq Z \\leq 2)=F_{Z}(2)-F_{Z}(-2)=2\\cdot F_Z(2)-1$.\n* $P(Z\\leq -2)=F_Z(-2)=1-F_Z(2)$.\n* $P( Z \\leq 2)=F_{Z}(2)$.\n* $P( Z \\geq 2)=1-P(Z<2)=1-F_{Z}(2)$.\n* $P( Z > 2)=1-P(Z\\leq 2)=1-F_{Z}(2)$.\n* $P( Z = 2)=0$ ya que es una distribución continua.\n* $P( Z \\geq -2)=1-P(Z< -2)=1-F_{Z}(-2)=1-(1-F_Z(2))=F_Z(2).$\n</div>\n</div>\n\n\n**Cálculo de probabilidades de la distribución normal $X=N(\\mu,\\sigma)$ en un intervalo usando la distribución $Z=N(0,1)$**\n\nPara hallar la probabilidad de que $X$ esté en un intervalo $(a,b)$ cualquiera, podemos usar la función de distribución de $Z$ de la siguiente manera:\n$$\n\\begin{array}{ll}\nP(a<X<b)&=P\\left(\\frac{a-\\mu}{\\sigma}<\\frac{X-\\mu}{\\sigma}<\\frac{b-\\mu}{\\sigma}\\right)= \\\\\n&=P\\left(\\frac{a-\\mu}{\\sigma}<Z<\\frac{b-\\mu}{\\sigma}\\right)=F_{Z}\\left(\\frac{b-\\mu}{\\sigma}\\right)-\nF_{Z}\\left(\\frac{a-\\mu}{\\sigma}\\right).\n\\end{array}\n$$\n\nPara el caso particular en que el intervalo esté centrado en la media $\\mu$, o sea existe un valor $\\delta>0$ tal que $(a,b)=(\\mu-\\delta,\\mu+\\delta)$, obtenemos:\n$$\nP\\left(\\mu-\\delta\\leq X \\leq\\mu+\\delta\\right)=2\\cdot  F_Z\\left(\\frac{\\delta}{\\sigma}\\right)-1.\n$$\n\n\n\n<div class=\"exercise\">\n**Ejercicio: cálculo de probabilidades de una distribución normal**\n\nSea $X$ una normal con media $2$ y varianza $4$. Calcular \n\n* $P(1< X< 2).$\n* $P(X>3).$\n\n<div class=\"example-sol\">\n**Solución**\n\nLa primera probabilidad se calcula de la forma siguiente:\n$$\n\\begin{array}{ll}\nP(1< X< 2)&= P\\left(\\frac{1-2}{2}<\\frac{X-2}{2}<\\frac{2-2}{2}\\right)= P\\left(\\frac{-1}{2}<Z<0\\right)\\\\\n&= F_{Z}(0)-F_{Z}(-0.5)=\\frac12-1+F_{Z}(0.5)=-\\frac12+F_Z(0.5).\n\\end{array}\n$$\n\nLa segunda probabilidad se calcular de la forma siguiente:\n$$\nP(X>3)=P\\left(\\frac{X-2}2>\\frac{3-2}{2}\\right)=P(Z>0.5)=1-F_{Z}(0.5).\n$$\n\n</div>\n</div>\n\n\n<div class=\"exercise\">\n**Ejercicio**\n\nSea $X$ una normal con media $2$ y varianza $4$. Calcular  usando `R` y con `Python` las probabilidades siguientes:\n\n* $P(1< X< 2).$\n* $P(X>3).$\n\n<div class=\"example-sol\">\n**Solución usando `R`**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(2,mean=2,sd=2)-pnorm(1,mean=2,sd=2) #P(1< X< 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1914625\n```\n:::\n\n```{.r .cell-code}\npnorm(3,mean=2,sd=2,lower.tail =FALSE) #P(X>3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3085375\n```\n:::\n\n```{.r .cell-code}\n1-pnorm(3,mean=2,sd=2,lower.tail=TRUE) #P(X>3) = 1-P(X<=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3085375\n```\n:::\n:::\n\n\n**Solución usando `Python`**\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnorm.cdf(2,loc=2,scale=2)-norm.cdf(1,loc=2,scale=2) #P(1< X< 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.19146246127401312\n```\n:::\n\n```{.python .cell-code}\n1-norm.cdf(3,loc=2,scale=2) #P(X>3) = 1-P(X<=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.3085375387259869\n```\n:::\n:::\n\n</div>\n</div>\n\n**La distribución normal aproxima otras distribuciones**\n\nEn los temas que siguen veremos como, bajo determinadas condiciones,\n\n* la distribución normal puede aproximar la distribución binomial,\n* la distribución normal puede aproximar la distribución Poisson\n* la distribución normal es la distribución límite de la media aritmética de una muestra de variables aleatorias.\n\n\n\n\n\n\n",
    "supporting": [
      "3_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}