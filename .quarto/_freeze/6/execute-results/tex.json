{
  "hash": "7645ce8e5b54e80343c2a7db15d90347",
  "result": {
    "markdown": "---\noutput:\n  pdf_document: default\n  html_document: default\n---\n\n\n# Vectores aleatorios\n\n## Varias variables aleatorias\n\nEn el capítulo anterior trabajamos con **variables aleatorias bidimensionales**\n\nEn este capítulo vamos a generalizar los conceptos introducidos para **variables aleatorias $n$-dimensionales**, con $n\\geq 3$.\n\nEl ejemplo que comentamos en el capítulo de variables aleatorias de medir la temperatura media un día determinado del año durante 10 años es un ejemplo de variable aleatoria 10-dimensional.\n\n###  Definición\n\nLa generalización de la noción de **variable aleatoria $n$-dimensional** a partir de la noción de **variable aleatoria bidimensional** es bastante obvia:\n\n<l class=\"definition\">Definición de variable aleatoria $n$-dimensional:</l>\nDado un experimento aleatorio con **espacio muestral** $\\Omega$, definimos **variable aleatoria $n$-dimensional** $\\mathbf{X}=(X_1,X_2,\\ldots,X_n)$ a toda aplicación \n$$\n\\begin{array}{rl}\n\\mathbf{X}=(X_1,X_2,\\ldots,X_n): \\Omega & \\longrightarrow \\mathbb{R}^n\\\\\nw & \\longrightarrow \\mathbf{X}(w)=(X_1(w),X_2(w),\\ldots,X_n(w)).\n\\end{array}\n$$\n\n<div class=\"example\">\n**Ejemplo: puertos entrada internet**\n\nTenemos tres puertos de entrada de paquetes de internet. \n\nSupongamos que cada milisegundo llega un paquete y el switch lo asigna a cada uno de los puertos con probabilidad $\\frac{1}{3}$.\n\nEstudiamos cómo se distribuyen los paquetes en 4 milisegundos. \n\n<div class=\"example-sol\">\nSea $\\mathbf{X}=(X_1,X_2,X_3)$ la variable aleatoria 3-dimensional, donde $X_i$ nos da el número de paquetes que ha recibido el puerto $i$-ésimo durante estos 4 milisegundos.\n\nPor ejemplo, el suceso $\\{X_1\\leq 1, X_2\\geq 3, X_3\\leq 1\\}$ es $\\{(0,3,0),(0,3,1),(0,4,0),(0,4,1),(1,3,0),(1,3,1),(1,4,0),(1,4,1)\\}$.\n\n</div>\n</div>\n\n### Representación del dominio de una variable aleatoria $n$-dimensional\n\nLos sucesos que se derivan de una **variable aleatoria $n$-dimensional** estan especificados por regiones del espacio $n$-dimensional.\n\nVeamos algunos ejemplos:\n\nSuceso: $\\{X_1+X_2+X_3\\leq 1\\}$. En el gráfico siguiente, el plano $x_1+x_2+x_3=1$ separa el espacio en dos partes. Es la parte que corresponde al punto $(0,0,0)$.\n\nSi pensamos el plano anterior como un \"espejo\" es la parte de atrás del mismo.\n\n<div class=\"center\">\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/EjPlano3D.png){width=1.48in}\n:::\n:::\n\n\n</div>\n\nSuceso: $\\{X_1^2+X_2^2+X_3^2\\leq 1\\}$. Es el interior de la esfera del gráfico siguiente:\n\n<div class=\"center\">\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/EjEsfera3D.png){width=1.48in}\n:::\n:::\n\n\n</div>\n\nSuceso: $\\{0\\leq X_1\\leq 1,\\ 0\\leq X_2\\leq 1,\\ 0\\leq X_3\\leq 1\\}$. Es el interior del cubo del gráfico siguiente:\n\n<div class=\"center\">\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/Ej3DCubo.png){width=1.81in}\n:::\n:::\n\n\n</div>\n\nLa probabilidad de que la **variable $n$-dimensional** pertenezca a una cierta **región del $n$-espacio $B\\subset \\mathbb{R}^n$** se define de la forma siguiente:\n$$\nP((X_1,X_2,\\ldots,X_n)\\in B)=P\\{w\\in \\Omega,\\ |\\ (X_1(w),X_2(w),\\ldots,X_n)\\in B\\},\n$$\ndicho de otra manera, la probabilidad anterior es la probabilidad del suceso formado por los elementos de $w\\in\\Omega$ que cumplen que su **imagen** por la **variable aleatoria $n$-dimensional $(X_1,X_2,\\ldots,X_n)$** esté en $B$.\n\n\nPor ejemplo, si consideramos $B=\\{X_1+X_2+\\cdots +X_n\\leq 1\\}$, $P((X_1,X_2,\\ldots,X_n)\\in B)$ es la probabilidad del suceso formado por los elementos $w$ de $\\Omega$ tal que la suma de las imágenes por $X_i$ desde $i=1$ hasta $n$ sea menor o igual que 1: $X_1(w)+\\cdots +X_n\\leq 1$.\n\n## Función de distribución conjunta\n\n### Definición\n\nDada una **variable aleatoria $n$-dimensional** $(X_1,X_2,\\ldots,X_n)$, queremos estudiar cómo se distribuye la probabilidad de sucesos cualesquiera de la forma $\\{(X_1,X_2,\\ldots,X_n)\\in B\\}$, donde $B$ es una región del espació $n$-dimensional $\\mathbb{R}^n$.\n\nPara ello, definimos la **función de distribución conjunta**:\n\n<l class=\"definition\">Definición de función de distribución conjunta:</l>\nDada una variable $n$-dimensional $(X_1,X_2,\\ldots,X_n)$, definimos su **función de distribución conjunta** $F_{X_1\\ldots X_n}$ a la función definida sobre $\\mathbb{R}^n$ de la manera siguiente:\n$$\n\\begin{array}{rl}\nF_{X_1\\ldots X_n}: \\mathbb{R}^n & \\longrightarrow \\mathbb{R}\\\\\n(x_1,\\ldots,x_n) & \\longrightarrow F_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=P(X_1\\leq x_1,\\ldots,X_n\\leq x_n).\n\\end{array}\n$$\n\nEs decir, dado un valor $(x_1,\\ldots,x_n)\\in \\mathbb{R}^n$, consideramos la región del espacio $n$-dimensional $(-\\infty,x_1]\\times\\cdots\\times (-\\infty,x_n]$.\n\nEntonces la **función de distribución conjunta** en el valor $(x_1,\\ldots,x_n)$ es la probabilidad del suceso formado por aquellos elementos tal que la imagen por la **variable aleatoria $n$-dimensional** $(X_1,X_2,\\ldots,X_n)$ caen dentro de la región anterior:\n\n$$\n\\begin{array}{rl}\nF_{X_1\\ldots X_n}(x_1,\\ldots,x_n) & =P\\{w\\in\\Omega,\\ |\\ (X_1(w),\\ldots,X_n(w)) \\\\ & \\qquad\\qquad\\in (-\\infty,x_1]\\times\\cdots\\times (-\\infty,x_n]\\} \\\\ & = P\\{w\\in\\Omega,\\ |\\ X_1(w)\\leq x_1,\\ldots, X_n(w)\\leq x_n\\}.\n\\end{array}\n$$\n\nEl gráfico siguiente muestra el conjunto $(-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3]$ en $\\mathbb{R}^3$ para un valor $(x,y,z)$:\n\n<div class=\"center\">\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/Fx1x2x3.png){width=0.94in}\n:::\n:::\n\n\n</div>\n\n\n###  Propiedades\nSea $(X_1,X_2,\\ldots,X_n)$ una variable $n$-dimensional. Sean $F_{X_1\\ldots X_n}$ su **función de distribución conjunta**. Dicha función satisface las propiedades siguientes:\n\n* La función de distribución conjunta es no decreciente en cada una de las variables:\n$$\n\\mbox{Si }x_i\\leq x_i', \\mbox{ para todo $i$, }\\mbox{ entonces, }F_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\leq F_{X_1\\ldots X_n}(x_1',\\ldots,x_n').\n$$\n\n* $F_{X_1\\ldots X_n}(x_1,\\ldots,x_{i-1},\\stackrel{(i)}{-\\infty},x_{i+1},\\ldots,x_n)=0,$ para todo $i$ y  $F_{X_1\\ldots X_n}(\\infty,\\ldots,\\infty)=1$, para todo $x_1,\\ldots,x_n\\in\\mathbb{R}$.\n\n* Las variables aleatorias $X_1,\\ldots, X_n$ se llaman **variables aleatorias marginales** y sus funciones de distribución $F_{X_1},\\ldots, F_{X_n}$ pueden hallarse de la forma siguiente como función de la **función de distribución conjunta** $F_{X_1\\ldots X_n}$:\n$$\nF_{X_i}(x_i)=F_{X_1\\ldots X_n}(\\infty,\\ldots,\\infty,\\stackrel{(i)}{x_i},\\infty,\\ldots,\\infty),\n$$\npara todo $x_1,\\ldots,x_n\\in\\mathbb{R}$ y para todo $i=1,\\ldots,n$.\n\n* La función de distribución conjunta es continua por la derecha en todas las variables $x_i$:\n$$\n\\begin{array}{rl}\n & \\lim\\limits_{x_i\\to a^+}F_{X_1\\ldots X_n}(x_1,\\ldots,x_{i-1},\\stackrel{(i)}{x_i},x_{i+1},\\ldots,x_n) \\\\ &\\qquad =\\lim\\limits_{x_i\\to a, x_i> a}F_{X_1\\ldots X_n}(x_1,\\ldots,x_{i-1},\\stackrel{(i)}{x_i},x_{i+1},\\ldots,x_n)\\\\ &\\qquad =F_{X_1\\ldots X_n}(x_1,\\ldots,x_{i-1},\\stackrel{(i)}{a},x_{i+1},\\ldots,x_n),\n\\end{array}\n$$\npara todo $a\\in\\mathbb{R}$ y para todo $i=1,\\ldots,n$.\n\n\n\n<div class=\"example\">\n**Ejemplo: densidad tridimensional**\n\nConsideremos una variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de distribución conjunta**:\n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\nx_1^2\\cdot x_2^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n x_2^2\\cdot x_3^2, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_3^2, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_2^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n x_1^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n x_2^2, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n1, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1.\n\\end{cases}\n$$\n\nEn las figuras siguientes, hemos representado por zonas cómo está definida $F_{X_1X_2X_3}$.\n\nLa primera figura muestra las zonas en la \"planta baja\" o para $0\\leq x_3\\leq 1$.\nEn color marrón, está representada la región $0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1$, en color amarillo, la región $x_1> 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1$, en color verde, la región $x_1>1,\\ x_2>1,\\ 0\\leq x_3\\leq 1$ y en color violeta, la región $0\\leq x_1\\leq 1,\\ x_2>1,\\ 0\\leq x_3\\leq 1$.\n\n\nLa segunda figura muestra las zonas del \"primer piso\" o para $x_3>1$. Los colores tienen un significado similar a los de la primera figura: en color marrón, está representada la región $0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\  x_3> 1$, en color amarillo u ocre, la región $x_1> 1,\\ 0\\leq x_2\\leq 1,\\ x_3> 1$, en color verde, la región $x_1>1,\\ x_2>1,\\ x_3> 1$ y en color violeta, la región $0\\leq x_1\\leq 1,\\ x_2>1,\\ x_3> 1$.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Images/Ej3DFxyz.png){fig-align='center' width=0.94in}\n:::\n\n::: {.cell-output-display}\n![](Images/Ej3DFxy2pis.png){fig-align='center' width=1.08in}\n:::\n:::\n\n\n\n\nComprobemos algunas de las propiedades que hemos enunciado anteriormente:\n\n* Claramente $F_{X_1X_2X_3}(x_1,x_2,-\\infty)=F_{X_1X_2X_3}(x_1,-\\infty,x_3)=F_{X_1X_2X_3}(-\\infty,x_2,x_3)=0$ ya que $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$ si $x_1<0$ o $x_2<0$ o $x_3<0$. Por tanto, si hacemos tender $x_1$ o $x_2$ o $x_3$ hacia $-\\infty$, obtendremos que $F_{X_1X_2X_3}(x_1,x_2,-\\infty)=F_{X_1X_2X_3}(x_1,-\\infty,x_3)=F_{X_1X_2X_3}(-\\infty,x_2,x_3)=0$.\n\n* De la misma manera $F_{X_1X_2X_3}(\\infty,\\infty,\\infty)=1$ ya que $F_{X_1X_2X_3}(x_1,x_2,x_3)=1$ para $x_1>1$, $x_2>1$ y $x_3>1$. Por tanto, si hacemos tender $x_1$, $x_2$ y $x_3$ hacia $\\infty$, obtendremos $F_{X_1X_2X_3}(\\infty,\\infty,\\infty)=1$.\n\n* Hallemos las marginales:\n$$\nF_{X_1}(x_1)=F_{X_1X_2X_3}(x_1,\\infty,\\infty)=\\begin{cases}\n0, & \\mbox{ si }x_1 < 0,\\\\\nx_1, & \\mbox{ si } 0\\leq x_1\\leq 1,\\\\\n1, & \\mbox{ si } x_1>1.\n\\end{cases}\n$$\nPara ver la expresión anterior basta trazar el plano $X_1=x_1$ en el gráfico anterior y ver hacia dónde tiende a medida que las variables $x_2$ y $x_3$ se van hacia $\\infty$. \n\n¿Habéis averiguado cuál es la distribución de $X_1$?\n\n¡Efectivamente!, $X_1$ es la uniforme en el intervalo $(0,1)$.\n\nDejamos como ejercicio hallar la distribución marginal para las variables $X_2$ e $X_3$.\n\n* Comprobemos que $F_{X_1X_2X_3}$ es continua por la derecha para las variables $x_1$, $x_2$ y $x_3$ en el punto $(1,1,1)$ que es un punto problemático:\n\n$$\n\\begin{array}{rl}\n \\lim_{x_1\\to 1,x_1> 1} F_{X_1X_2X_3}(x_1,1,1) & =\\lim_{x_1\\to 1,x_1> 1} 1  = F_{X_1X_2X_3}(1,1,1),\\\\\n \\lim_{x_2\\to 1,x_2> 1} F_{X_1X_2X_3}(1,x_2,1) & =\\lim_{x_2\\to 1,x_2> 1} 1 = F_{X_1X_2X_3}(1,1,1),\\\\  \n\\lim_{x_3\\to 1,x_3> 1} F_{X_1X_2X_3}(1,1,x_3) & =\\lim_{x_3\\to 1,x_3> 1} 1  = F_{X_1X_2X_3}(1,1,1).\n\\end{array}\n$$\n\n</div>\n\n\n<div class=\"example\">\n\n**Ejemplo: cálculo  con `R` distribución conjunta**\n\nRealizar un gráfico 3D de la **función de distribución conjunta** no es posible ya que deberíamos pasar a $\\mathbb{R}^4$. \n\nLo que sí es posible es dibujar las curvas de nivel de dicha función para un valor de $x_3$ fijado. \n\nEl los gráficos siguientes dibujamos las curvas de nivel para $x_3=0,0.5,1$ i $x_3=1.5$.\n\n<div class=\"example-sol\">\n\nPrimero definimos la **función** y luego la dibujamos para $x_1$ y $x_2$ entre $-1$ y $3$:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nf.dist.con = function(x1,x2,x3){ifelse(x1<0 | x2<0 | x3 <0,0,\n          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,\n                 x1^2*x2^2*x3^2,\n          ifelse(x1>1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,\n                 x2^2*x3^2,\n          ifelse(x1>=0 & x1<=1 & x2>1 & x3>=0 & x3<=1,\n                 x1^2*x3^2,\n          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>1,\n                 x1^2*x2^2,\n          ifelse(x1>=0 & x1<=1 & x2 >1 & x3 >1,x1^2,\n          ifelse(x1>1 & x2 >=0 & x2<=1 & x3 >1,x2^2,\n          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3 >1,\n                 x3^2,1))))))))}\nx1=seq(from=-1,to=3,by=0.05)\nx2=seq(from=-1,to=3,by=0.05)\ncurva.nivel.0=outer(x1,x2,f.dist.con,x3=0)\ncurva.nivel.0.5=outer(x1,x2,f.dist.con,x3=0.5)\ncurva.nivel.1=outer(x1,x2,f.dist.con,x3=1)\ncurva.nivel.1.5=outer(x1,x2,f.dist.con,x3=1.5)\nimage(x1,x2,curva.nivel.0)\n```\n\n::: {.cell-output-display}\n![](6_files/figure-pdf/unnamed-chunk-1-1.pdf){fig-align='center' fig-pos='H'}\n:::\n\n```{.r .cell-code}\nimage(x1,x2,curva.nivel.0.5)\n```\n\n::: {.cell-output-display}\n![](6_files/figure-pdf/unnamed-chunk-1-2.pdf){fig-align='center' fig-pos='H'}\n:::\n\n```{.r .cell-code}\nimage(x1,x2,curva.nivel.1)\n```\n\n::: {.cell-output-display}\n![](6_files/figure-pdf/unnamed-chunk-1-3.pdf){fig-align='center' fig-pos='H'}\n:::\n\n```{.r .cell-code}\nimage(x1,x2,curva.nivel.1.5)\n```\n:::\n\n\n\n</div>\n</div>\n\n<div class=\"example\">\n**Ejemplo del lanzamiento de un dado tres veces**\n\nConsideremos el experimento aleatorio que consiste en lanzar un dado tres veces. \n\nEl espacio $\\Omega$ de resultados es:\n$$\n\\Omega =\\{(i,j,k),\\ | i,j,k=1,2,3,4,5,6\\}.\n$$\nEn total tendremos $6\\cdot 6\\cdot 6=6^3=216$ resultados posibles.\n\nConsideremos la variable 3-dimensional $\\mathbf{X}=(X_1,X_2,X_3)$, donde $X_1$ nos da el número de 1's obtenidos, $X_2$, el número de 2's y $X_3$, el número de 3's.\n\n<div class=\"example-sol\">\n\nEl conjunto $\\mathbf{X}(\\Omega)$ tiene en total 64 elementos ya que cada componente $X_i$ puede tener en total 4 resultados: 0, 1, 2 o 3. Por tanto el conjunto total de resultados es: $4\\cdot 4\\cdot 4=4^3=64$.\n\n\nEl valor de función de distribución conjunta en el resultado $(0,0,0)$ es:\n\n$$\nF_{X_1X_2X_3}(0,0,0)=p(X_1\\leq 0,\\ X_2\\leq 0,\\ X_3\\leq 0)=\\frac{3^3}{6^3}=\\left(\\frac{1}{2}\\right)^3 =0.125,\n$$\nya que si $X_1\\leq 0$, $X_2\\leq 0$ y $X_3\\leq 0$, significa que no ha salido ni ningún 1, ni ningún 2 ni ningún 3. Sólo pueden salir 4's, 5's o 6's y existen $3\\cdot 3\\cdot 3=3^3=27$ posibilidades de que esto pase entre $6^3=216$ posibilidades posibles.\n</div>\n</div>\n\n## Variables aleatorias $n$-dimensionales discretas\n\n<l class=\"definition\">Definición de variable aleatoria $n$-dimensional discreta:</l>\nSea $(X_1,\\ldots,X_n)$ una **variable aleatoria $n$-dimensional**. Diremos que es discreta cuando su conjunto de valores en $\\mathbb{R}^n$, $(X_1,\\ldots,X_n)(\\Omega)$ es un conjunto finito o numerable. \n\nEn la mayoría de los casos, dicho conjunto es un subconjunto de los enteros naturales.\n\n<div class=\"example\">\n**Ejemplo**\n\nLa variable aleatoria 3-dimensional anterior que nos daba el número de 1's obtenidos, el número de 2's y el número de 3's es discreta ya que\n\n<div class=\"example-sol\">\n\n$$\n\\begin{array}{rl}\n\\mathbf{X}(\\Omega) =& \\{\n  (0,0,0),(1,0,0),(0,1,0),(0,0,1),(2,0,0),(0,2,0),\\\\\n& (0,0,2),(3,0,0),(0,3,0),(0,0,3),(0,1,1),(1,0,1),\\\\\n&  (1,1,0),(0,1,2),(0,2,1),(1,0,2),(2,0,1),(1,2,0),\\\\\n&  (2,1,0),(0,1,3),(0,3,1),(1,0,3),(3,0,1),(1,3,0),\\\\\n&  (3,1,0),(0,2,2),(2,0,2),(2,2,0),(0,2,3),(3,2,0),\\\\\n&  (2,0,3),(3,0,2),(2,3,0),(3,2,0),(0,3,3),(3,0,3),\\\\\n&  (3,3,0),(1,1,1),(1,1,2),(1,2,1),(2,1,1),(1,1,3),\\\\\n& (1,3,1),(3,1,1),(1,2,2),(2,1,2),(2,2,1),(1,2,3),\\\\\n& (2,1,3),(1,3,2),(3,1,2),(2,3,1),(3,2,1),(1,3,3),\\\\\n& (3,1,3),(3,3,1),(2,2,2),(2,2,3),(2,3,2),(3,2,2),\\\\\n& (2,3,3),(3,2,3),(3,3,2),(3,3,3)\\}.\n\\end{array}\n$$\n</div>\n</div>\n\n\n### Función de probabilidad conjunta\n\n<l class=\"definition\">Definición de función de probabilidad conjunta:</l>\nDada una **variable aleatoria $n$-dimensional discreta** $(X_1\\ldots,X_n)$ con $(X_1\\ldots,X_n)(\\Omega)=\\{(x_{i_1},x_{i_2},\\ldots,x_{i_n}),\\ i_1=1,2,\\ldots,\\ i_n=1,2,\\ldots,\\}$, definimos la función de probabilidad discreta $P_{X_1\\ldots X_n}$ para un valor $(x_{i_1},x_{i_2},\\ldots,x_{i_n})\\in\\mathbb{R}^n$ de la siguiente forma:\n\n$$\n\\begin{array}{rl}\nP_{X_1\\ldots X_n}: \\mathbb{R}^n & \\longrightarrow \\mathbb{R}\\\\\n(x_{i_1},x_{i_2},\\ldots,x_{i_n}) & \\longrightarrow P_{X_1\\ldots X_n}(x_{i_1},x_{i_2},\\ldots,x_{i_n})=P(X= x_{i_1},\\ldots X_n= x_{i_n}).\n\\end{array}\n$$\n\n<l class=\"observ\">Observación:</l>\nSi $(x_{i_1},x_{i_2},\\ldots,x_{i_n})\\not\\in (X_1\\ldots,X_n)(\\Omega)$, el valor de la **función de probabilidad conjunta** en $(x_{i_1},x_{i_2},\\ldots,x_{i_n})$ en nulo: $P_{X_1\\ldots X_n}(x_{i_1},x_{i_2},\\ldots,x_{i_n})=0$, ya que, en este caso, el conjunto $\\{w\\in\\Omega,\\ | (X_1(w),\\ldots,X_n(w))=(x_{i_1},x_{i_2},\\ldots,x_{i_n})\\}=\\emptyset$ ya que recordemos $(x_{i_1},x_{i_2},\\ldots,x_{i_n})\\not\\in (X_1\\ldots,X_n)(\\Omega)$.\n\n\nPor tanto, de cara a calcular $P_{X_1\\ldots X_n}$ basta calcular $P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n})$ para $(x_{i_1},\\ldots,x_{i_n})\\in (X_1\\ldots,X_n)(\\Omega)$.\n\nLos valores de $P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n})$ estarían organizados en una tabla $n$-dimensional.\n\n<div class=\"example\">\n**Ejemplo de la variable 3-dimensional que nos da el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces**\n\nPara mostrar la **función de probabilidad conjunta** haremos una tabla bidimensional para cada valor de $X_3$. \n\nComo $X_3(\\Omega)=\\{0,1,2,3\\}$, en total mostraremos 4 tablas bidimensionales.\n\n<div class=\"example-sol\">\n\nTabla para $X_3=0$:\n\n<div class=\"center\">\n| $X_1/X_2$| 0 | 1 | 2 | 3 \n|--|--|--|--|--\n| 0  | $\\frac{1}{8}$ | $\\frac{1}{8}$ | $\\frac{1}{24}$ | $\\frac{1}{216}$\n| 1  | $\\frac{1}{8}$ | $\\frac{1}{12}$ | $\\frac{1}{72}$ | $0$\n| 2  | $\\frac{1}{24}$ | $\\frac{1}{72}$ | $0$ | $0$\n| 3  | $\\frac{1}{216}$ | $0$ | $0$ | $0$\n\n</div>\n\nTabla para $X_3=1$:\n\n<div class=\"center\">\n| $X_1/X_2$| 0 | 1 | 2 | 3 \n|--|--|--|--|--\n| 0  | $\\frac{1}{8}$ | $\\frac{1}{12}$ | $\\frac{1}{72}$ | $0$\n| 1  | $\\frac{1}{12}$ | $\\frac{1}{36}$ | $0$ | $0$\n| 2  | $\\frac{1}{72}$ | $0$ | $0$ | $0$\n| 3  | $0$ | $0$ | $0$ | $0$\n\n</div>\n\nTabla para $X_3=2$:\n\n<div class=\"center\">\n| $X_1/X_2$| 0 | 1 | 2 | 3 \n|--|--|--|--|--\n| 0  | $\\frac{1}{24}$ | $\\frac{1}{72}$ | $0$ | $0$\n| 1  | $\\frac{1}{72}$ | $0$ | $0$ | $0$\n| 2  | $0$ | $0$ | $0$ | $0$\n| 3  | $0$ | $0$ | $0$ | $0$\n\n</div>\n\nTabla para $X_3=3$:\n\n<div class=\"center\">\n| $X_1/X_2$| 0 | 1 | 2 | 3 \n|--|--|--|--|--\n| 0  | $\\frac{1}{216}$ | $0$ | $0$ | $0$\n| 1  | $0$ | $0$ | $0$ | $0$\n| 2  | $0$ | $0$ | $0$ | $0$\n| 3  | $0$ | $0$ | $0$ | $0$\n\n</div>\n\n</div>\n\n\n\n\nLa función `fun.prod.con` nos da la **función de probabilidad conjunta** de la variable aleatoria $\\mathbf{X}$ cuando lanzamos un dado tres veces:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfun.prob.con=function(x1,x2,x3){\n  n=6\n  cuenta.1 =function(x){length(x[x==1])}\n  cuenta.2 =function(x){length(x[x==2])}\n  cuenta.3 =function(x){length(x[x==3])}\n  Dxyz=data.frame(d1=rep(1:n,each=n),d2=rep(1:n,times=n),\n                  d3=rep(1:n,each=n*n))\n  X1=apply(Dxyz,1,cuenta.1)\n  X2=apply(Dxyz,1,cuenta.2)\n  X3=apply(Dxyz,1,cuenta.3)\n  frecuencia = table(X1==x1 & X2==x2 & X3==x3)\n  res=ifelse(length(frecuencia)==2,frecuencia[2],0)\n  return(res/6^3)\n}\n```\n:::\n\n\n\nPara construir la tabla de la **función de probabilidad conjunta** para la variable $\\mathbf{X}=(X_1,X_2,X_3)$ con $X_3=0$ hacemos lo siguiente:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalores.variables=0:3\ntabla.0 = c()\nfor (i in 1:length(valores.variables)){\n  for (j in 1:length(valores.variables)){\n  tabla.0=c(tabla.0,\n            fun.prob.con(valores.variables[i],\n                         valores.variables[j],0));\n  }\n  }\ntabla.0 = matrix(tabla.0,length(valores.variables),\n                 length(valores.variables))\nrownames(tabla.0)=valores.variables\ncolnames(tabla.0)=valores.variables\nknitr::kable(tabla.0)\n```\n:::\n\n\nCon los demás valores de $X_3$, lo haríamos de forma similar.\n\nTabla con $X_3=0$:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n|   |         0|         1|         2|         3|\n|:--|---------:|---------:|---------:|---------:|\n|0  | 0.1250000| 0.1250000| 0.0416667| 0.0046296|\n|1  | 0.1250000| 0.0833333| 0.0138889| 0.0000000|\n|2  | 0.0416667| 0.0138889| 0.0000000| 0.0000000|\n|3  | 0.0046296| 0.0000000| 0.0000000| 0.0000000|\n:::\n:::\n\n\n\nTabla con $X_3=1$:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n|   |         0|         1|         2|  3|\n|:--|---------:|---------:|---------:|--:|\n|0  | 0.1250000| 0.0833333| 0.0138889|  0|\n|1  | 0.0833333| 0.0277778| 0.0000000|  0|\n|2  | 0.0138889| 0.0000000| 0.0000000|  0|\n|3  | 0.0000000| 0.0000000| 0.0000000|  0|\n:::\n:::\n\n\n\nTabla con $X_3=2$:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n|   |         0|         1|  2|  3|\n|:--|---------:|---------:|--:|--:|\n|0  | 0.0416667| 0.0138889|  0|  0|\n|1  | 0.0138889| 0.0000000|  0|  0|\n|2  | 0.0000000| 0.0000000|  0|  0|\n|3  | 0.0000000| 0.0000000|  0|  0|\n:::\n:::\n\n\n\nTabla con $X_3=3$:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n|   |         0|  1|  2|  3|\n|:--|---------:|--:|--:|--:|\n|0  | 0.0046296|  0|  0|  0|\n|1  | 0.0000000|  0|  0|  0|\n|2  | 0.0000000|  0|  0|  0|\n|3  | 0.0000000|  0|  0|  0|\n:::\n:::\n\n\n\n</div>\n</div>\n\n\n### Propiedades de la función de probabilidad conjunta\n\nDada $(X_1\\ldots,X_n)$ una **variable aleatoria $n$-dimensional discreta** con conjunto de valores $(X_1\\ldots,X_n)(\\Omega)=\\{(x_{i_1},\\ldots,x_{i_n})\\, \\mid i_1=1,2\\ldots,\\ i_n=1,2\\ldots\\}$. Entonces su **función de probabilidad conjunta** verifica las propiedades siguientes:\n\nLa suma de todos los valores de la **función de probabilidad conjunta** sobre el conjunto de valores siempre vale 1: $$\\sum_{i_1}\\cdots\\sum_{i_n} P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n})=1.$$\n\nSea $B$ una región del espacio $\\mathbb{R}^n$. El valor de la probabilidad $P((X_1\\ldots,X_n)\\in B)$ se puede calcular de la forma siguiente:\n$$\nP((X_1\\ldots,X_n)\\in B) =\\sum_{(x_{i_1},\\ldots,x_{i_n})\\in B} P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n}).\n$$\nEs decir, la probabilidad de que la variable $n$-dimensional tome valores en $B$ es igual a la suma de todos aquellos valores de la función de probabilidad conjunta que están en $B$.\n\nEn particular, tenemos la  siguiente expresión relaciona la **función de distribución conjunta** con la **función de probabilidad conjunta**:\n\n$$\nF_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=\\sum_{x_{i_1}\\leq x_1,\\ldots, x_{i_n}\\leq x_n} P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n}).\n$$\nDicha expresión se deduce de la expresión anterior considerando $B=(-\\infty,x_1]\\times\\cdots\\times (-\\infty,x_n]$.\n\n\n<div class=\"example-sol\">\n**Ejemplo anterior del lanzamiento de un dado tres veces**\n\n<div class=\"exercise\">\n**Ejercicio**\n\nComprobad usando la tabla de la función de probabilidad conjunta que la suma de todos sus valores suma 1.\n</div>\n\nApliquemos la fórmula que relaciona la función de distribución conjunta con la función de probabilidad conjunta para $(x_1,x_2,x_3)=(1,2,2)$.\n\n<div class=\"example-sol\">\nObservamos que los únicos valores $(x_{i_1},x_{i_2},x_{i_3})\\in (X_1 X_2,X_3)(\\Omega)$ que verifican $x_{i_1}\\leq 1$, $x_{i_2}\\leq 2$ y $x_{i_3}\\leq 2$ son $(0,0,0)$, $(0,0,1)$, $(0,0,2)$, $(0,1,0)$, $(0,1,1)$, $(0,1,2)$, $(0,2,0)$, $(0,2,1)$, $(0,2,2)$, $(1,0,0)$, $(1,0,1)$, $(1,0,2)$, $(1,1,0)$, $(1,1,1)$, $(1,1,2)$, $(1,2,0)$, $(1,2,1)$ y $(1,2,2)$:\n\n\n$$\n\\begin{array}{rl}\nF_{X_1X_2X_3}(1,2,2) \n& =P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)\\\\\n& +P_{X_1X_2X_3}(0,1,0)+P_{X_1X_2X_3}(0,1,1)+P_{X_1X_2X_3}(0,1,2)\\\\\n& +P_{X_1X_2X_3}(0,2,0)+P_{X_1X_2X_3}(0,2,1)+P_{X_1X_2X_3}(0,2,2)\\\\\n& +P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)\\\\ \n& +P_{X_1X_2X_3}(1,1,0)+P_{X_1X_2X_3}(1,1,1)+P_{X_1X_2X_3}(1,1,2)\\\\\n& +P_{X_1X_2X_3}(1,2,0)+ P_{X_1X_2X_3}(1,2,1)+P_{X_1X_2X_3}(1,2,2)\\\\ \n&=\\frac{1}{8}+\\frac{1}{8}+\\frac{1}{24}+\\frac{1}{8}+\\frac{1}{12}+\\frac{1}{72}+\\frac{1}{24}+\\frac{1}{72}+0\\\\\n& +\\frac{1}{8}+\\frac{1}{12}+\\frac{1}{72}+\\frac{1}{12}+\\frac{1}{36} +0+\\frac{1}{72}+0+0=\\\\\n& \\frac{11}{12}=0.9167.\n\\end{array}\n$$\n\n\nLa función de distribución conjunta es con código  `R`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfun.dis.con = function(x1,x2,x3){\n  suma=0\n  i1=0; i2=0; i3=0;\n  while(i1 <=x1 & i1<=3){\n    while(i2 <= x2 & i2<=3){\n      while(i3<= x3 & i3 <=3){\n        suma=suma+fun.prob.con(i1,i2,i3); i3=i3+1;\n      }\n      i3=0; i2=i2+1;\n    }\n    i2=0; i3=0; i1=i1+1;\n  }\n  return(suma)\n}\n```\n:::\n\n\n\n\nComprobemos que la **función de distribución conjunta** en el valor $(1,2,2)$ nos da el mismo resultado que vimos anteriormente:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfun.dis.con(1,2,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9166667\n```\n:::\n:::\n\n\n</div>\n</div>\n\n### Funciones de distribución marginales\n\nConsideremos una variable aleatoria **$n$-dimensional discreta $(X_1\\ldots,X_n)$** con **función de probabilidad conjunta**\n\n$P_{X_1\\ldots,X_n}(x_{i_1},\\ldots,x_{i_n})$, con $(x_{i_1},\\ldots,x_{i_n})\\in (X_1\\ldots,X_n)(\\Omega)$, $i_1=1,2,\\ldots$, $i_n=1,2,\\ldots$.\n\nLa tabla de la **función de probabilidad conjunta** contiene suficiente información para obtener las **funciones de probabilidad conjunta** de cualquier **variable aleatoria $k$-dimensional** $(X_{s_1},\\ldots,X_{s_k})$ donde $\\{s_1,\\ldots,s_k\\}$ es un subconjunto de las componentes $\\{1,\\ldots,n\\}$ de la variable aleatoria $n$-dimensional.  . \n\n<l class=\"prop\">Proposición. Expresión de las funciones de probabilidad marginales. </l>\n\nSea $\\mathbf{X}=(X_1\\ldots,X_n)$ una variable aleatoria **$n$-dimensional discreta** con **función de probabilidad conjunta** $P_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n})$, con $(x_{i_1},\\ldots,x_{i_n})\\in (X_1\\ldots,X_n)(\\Omega)$, $i_1=1,2,\\ldots$, $i_n=1,2,\\ldots$.\n\nSea $\\{s_1,\\ldots,s_k\\}$ un subconjunto del conjunto de las componentes $\\{1,\\ldots,n\\}$ donde suponemos que $s_1 < s_2<\\cdots < s_k$. Entonces la **función de probabilidad conjunta** $P_{X_{s_1}\\ldots X_{s_k}}$ de la variable aleatoria $k$-dimensional $(X_{s_1},\\ldots, X_{s_k})$ se calcula usando la expresión siguiente:\n\n$$\n\\begin{array}{rl}\nP_{X_{s_1}\\ldots X_{s_k}}(x_{s_1},\\ldots,x_{s_k})  & = \\sum_{x_t} P_{X_1\\ldots X_n}(\\mathbf{x}_s,\\mathbf{x}_t),\n\\end{array}\n$$\n\ndonde $(\\mathbf{x}_s,\\mathbf{x}_t)$ es un valor de $\\mathbf{X}(\\Omega)$ tal que tiene como componente $s_i$ el valor $x_{s_i}$ para $i=1,\\ldots, k$ y con $\\mathbf{x}_t$ queremos decir todas las demás componentes que no son las $s_i$. La suma tiene todos los sumandos $\\mathbf{x}_t$ para los que se cumpla que $(\\mathbf{x}_s,\\mathbf{x}_t)\\in \\mathbf{X}(\\Omega)$.\n\nEn el caso particular de $n=3$, podemos calcular las **funciones de probabilidad conjunta** de las variables unidimensionales $X_1$, $X_2$ y $X_3$ y de las variables bidimensionales $(X_1,X_2)$, $(X_1,X_3)$ y $(X_2,X_3)$.\n\n\n<div class=\"example\">\n**Ejemplo de la variable 3-dimensional que nos da el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces**\n\nHallemos, en primer lugar, la **función de probabilidad marginal** de las variable $X_1$, $X_2$ y $X_3$. Empecemos con $X_1$:\n\n<div class=\"example-sol\">\n\n\n$$\n\\begin{array}{rl}\nP_{X_1}(0) \n& = P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)\\\\\n& +P_{X_1X_2X_3}(0,0,3)+P_{X_1X_2X_3}(0,1,0)+P_{X_1X_2X_3}(0,1,1)\\\\\n& +P_{X_1X_2X_3}(0,1,2)+P_{X_1X_2X_3}(0,1,3)+P_{X_1X_2X_3}(0,2,0)\\\\\n& +P_{X_1X_2X_3}(0,2,1)+P_{X_1X_2X_3}(0,2,2)+P_{X_1X_2X_3}(0,2,3)\\\\\n& +P_{X_1X_2X_3}(0,3,0)+P_{X_1X_2X_3}(0,3,1)+P_{X_1X_2X_3}(0,3,2)\\\\\n& +P_{X_1X_2X_3}(0,3,3)=0.5787,\\\\\nP_{X_1}(1) \n& = P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)\\\\\n& +P_{X_1X_2X_3}(1,0,3)+P_{X_1X_2X_3}(1,1,0)+P_{X_1X_2X_3}(1,1,1)\\\\\n& +P_{X_1X_2X_3}(1,1,2)+P_{X_1X_2X_3}(1,1,3)+P_{X_1X_2X_3}(1,2,0)\\\\\n& +P_{X_1X_2X_3}(1,2,1)+P_{X_1X_2X_3}(1,2,2)+P_{X_1X_2X_3}(1,2,3)\\\\\n& +P_{X_1X_2X_3}(1,3,0)+P_{X_1X_2X_3}(1,3,1)+P_{X_1X_2X_3}(1,3,2)\\\\ \n& + P_{X_1X_2X_3}(1,3,3)=0.3472,\\\\\n\\end{array}\n$$\n\n\n$$\n\\begin{array}{rl}\nP_{X_1}(2) \n& = P_{X_1X_2X_3}(2,0,0)+P_{X_1X_2X_3}(2,0,1)+P_{X_1X_2X_3}(2,0,2)\\\\\n& + P_{X_1X_2X_3}(2,0,3)+P_{X_1X_2X_3}(2,1,0)+P_{X_1X_2X_3}(2,1,1)\\\\\n& + P_{X_1X_2X_3}(2,1,2)+P_{X_1X_2X_3}(2,1,3)+P_{X_1X_2X_3}(2,2,0)\\\\\n& + P_{X_1X_2X_3}(2,2,1)+P_{X_1X_2X_3}(2,2,2)+P_{X_1X_2X_3}(2,2,3)\\\\\n& + P_{X_1X_2X_3}(2,3,0)+P_{X_1X_2X_3}(2,3,1)+P_{X_1X_2X_3}(2,3,2)\\\\\n& + P_{X_1X_2X_3}(2,3,3)=0.0694,\\\\\nP_{X_1}(3) \n& = P_{X_1X_2X_3}(3,0,0)+P_{X_1X_2X_3}(3,0,1)+P_{X_1X_2X_3}(3,0,2)\\\\\n& + P_{X_1X_2X_3}(3,0,3)+P_{X_1X_2X_3}(3,1,0)+P_{X_1X_2X_3}(3,1,1)\\\\\n& + P_{X_1X_2X_3}(3,1,2)+P_{X_1X_2X_3}(3,1,3)+P_{X_1X_2X_3}(3,2,0)\\\\\n& + P_{X_1X_2X_3}(3,2,1)+P_{X_1X_2X_3}(3,2,2)+P_{X_1X_2X_3}(3,2,3)\\\\\n& + P_{X_1X_2X_3}(3,3,0)+P_{X_1X_2X_3}(3,3,1)+P_{X_1X_2X_3}(3,3,2)\\\\ \n& + P_{X_1X_2X_3}(3,3,3)=0.0046\n\\end{array}\n$$\n\n\nLa distribución marginal de la variable $X_1$ es la siguiente:\n\n<div class=\"center\">\n| $X_1$ | 0 | 1| 2 |3 \n|--|--|--|--|--\n| $P_{X_1}$|$0.5787$|$0.3472$|$0.0694$|$0.0046$\n\n</div>\n\nLas distribuciones marginales de las variables $X_2$ y $X_3$ coinciden con la distribución marginal de la variable $X_1$. Lo dejamos como ejercicio.\n\nA continuación, calculemos la **función de probabilidad marginal conjunta** de la variable $(X_1,X_2)$:\n\n$$\n\\begin{array}{rl}\nP_{X_1X_2}(0,0) \n& = P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)\\\\\n& +P_{X_1X_2X_3}(0,0,3)=0.2963, \\\\\nP_{X_1X_2}(0,1) & = P_{X_1X_2X_3}(0,1,0)+P_{X_1X_2X_3}(0,1,1)+P_{X_1X_2X_3}(0,1,2)\\\\\n& +P_{X_1X_2X_3}(0,1,3)=0.2222, \\\\\nP_{X_1X_2}(0,2) & = P_{X_1X_2X_3}(0,2,0)+P_{X_1X_2X_3}(0,2,1)+P_{X_1X_2X_3}(0,2,2)\\\\\n& +P_{X_1X_2X_3}(0,2,3)=0.0556, \\\\\nP_{X_1X_2}(0,3) & = P_{X_1X_2X_3}(0,3,0)+P_{X_1X_2X_3}(0,3,1)+P_{X_1X_2X_3}(0,3,2)\\\\\n& +P_{X_1X_2X_3}(0,3,3)=0.0046, \\\\\nP_{X_1X_2}(1,0) & = P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)\\\\\n& +P_{X_1X_2X_3}(1,0,3)=0.2222, \\\\\nP_{X_1X_2}(1,1) & = P_{X_1X_2X_3}(1,1,0)+P_{X_1X_2X_3}(1,1,1)\\\\\n& +P_{X_1X_2X_3}(1,1,2)+P_{X_1X_2X_3}(1,1,3)=0.1111, \\\\\nP_{X_1X_2}(1,2) & = P_{X_1X_2X_3}(1,2,0)+P_{X_1X_2X_3}(1,2,1)+P_{X_1X_2X_3}(1,2,2)\\\\\n& +P_{X_1X_2X_3}(1,2,3)=0.0139, \\\\\nP_{X_1X_2}(1,3) & = P_{X_1X_2X_3}(1,3,0)+P_{X_1X_2X_3}(1,3,1)+P_{X_1X_2X_3}(1,3,2)\\\\\n& +P_{X_1X_2X_3}(1,3,3)=0, \\\\\nP_{X_1X_2}(2,0) & = P_{X_1X_2X_3}(2,0,0)+P_{X_1X_2X_3}(2,0,1)+P_{X_1X_2X_3}(2,0,2)\\\\\n& +P_{X_1X_2X_3}(2,0,3)=0.0556, \\\\\nP_{X_1X_2}(2,1) & = P_{X_1X_2X_3}(2,1,0)+P_{X_1X_2X_3}(2,1,1)+P_{X_1X_2X_3}(2,1,2)\\\\\n& +P_{X_1X_2X_3}(2,1,3)=0.0139, \\\\\nP_{X_1X_2}(2,2) & = P_{X_1X_2X_3}(2,2,0)+P_{X_1X_2X_3}(2,2,1)+P_{X_1X_2X_3}(2,2,2)\\\\\n& +P_{X_1X_2X_3}(2,2,3)=0, \\\\\nP_{X_1X_2}(2,3) & = P_{X_1X_2X_3}(2,3,0)+P_{X_1X_2X_3}(2,3,1)+P_{X_1X_2X_3}(2,3,2)\\\\\n& +P_{X_1X_2X_3}(2,3,3)=0, \\\\\nP_{X_1X_2}(3,0) \n& = P_{X_1X_2X_3}(3,0,0)+P_{X_1X_2X_3}(3,0,1)+P_{X_1X_2X_3}(3,0,2)\\\\\n& +P_{X_1X_2X_3}(3,0,3)=0.0046, \\\\\nP_{X_1X_2}(3,1) & = P_{X_1X_2X_3}(3,1,0)+P_{X_1X_2X_3}(3,1,1)\\\\\n& +P_{X_1X_2X_3}(3,1,2)+P_{X_1X_2X_3}(3,1,3)=0, \\\\\nP_{X_1X_2}(3,2) & = P_{X_1X_2X_3}(3,2,0)+P_{X_1X_2X_3}(3,2,1)\\\\\n& + P_{X_1X_2X_3}(3,2,2)+P_{X_1X_2X_3}(3,2,3)=0, \\\\\nP_{X_1X_2}(3,3) & = P_{X_1X_2X_3}(3,3,0)+P_{X_1X_2X_3}(3,3,1)\\\\\n& + P_{X_1X_2X_3}(3,3,2)+P_{X_1X_2X_3}(3,3,3)=0, \\\\\n\\end{array}\n$$\n\n\nLa **función de probabilidad marginal conjunta** de la variable $(X_1,X_2)$ queda resumida en la tabla siguiente:\n\n<div class=\"center\">\n| $X_1/X_2$ | 0 | 1| 2 |3 \n|--|--|--|--|--\n|$0$|$0.2963$|$0.2222$|$0.0556$|$0.0046$\n|$1$|$0.2222$|$0.1111$|$0.0139$|$0$\n|$2$|$0.0556$|$0.0139$|$0$|$0$\n|$3$|$0.0046$|$0$|$0$|$0$\n</div>\n\nLas **funciones de probabilidad marginales** de las variables $(X_1,X_3)$ y $(X_2,X_3)$ dan el mismo resultado que la tabla anterior.\n\n\nLa **función de probabilidad marginal** de la variable $X_1$ en `R` se halla de la forma siguiente:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfun.marginal.X1 = function(x){\n  suma=0;\n  for (i in 0:3){for (j in 0:3){suma=suma+fun.prob.con(x,i,j)}}\n  return(suma)\n}\ntabla.fun.marginal.X1=data.frame(fun.marginal.X1(0),fun.marginal.X1(1),\n                            fun.marginal.X1(2),fun.marginal.X1(3));\ncolnames(tabla.fun.marginal.X1)=0:3\nknitr::kable(tabla.fun.marginal.X1)\n```\n\n::: {.cell-output-display}\n|         0|         1|         2|         3|\n|---------:|---------:|---------:|---------:|\n| 0.5787037| 0.3472222| 0.0694444| 0.0046296|\n:::\n:::\n\n\n\nLa **función de probabilidad marginal** de la variable $(X_1,X_2)$ en `R` se halla de la forma siguiente:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfun.marginal.X1.X2 = function(x,y){\n  suma=0;\n  for (i in 0:3){suma=suma+fun.prob.con(x,y,i)}\n  return(suma)\n}\ntabla.fun.marginal.X1.X2=c()\nfor (i in 0:3){\n  tabla.fun.marginal.X1.X2=cbind(\n    tabla.fun.marginal.X1.X2,\n    c(fun.marginal.X1.X2(i,0),                                                            fun.marginal.X1.X2(i,1),                                                            fun.marginal.X1.X2(i,2),                                                            fun.marginal.X1.X2(i,3)\n    )\n  )\n  }\ntabla.fun.marginal.X1.X2=as.data.frame(tabla.fun.marginal.X1.X2)\nrownames(tabla.fun.marginal.X1.X2)=0:3\ncolnames(tabla.fun.marginal.X1.X2)=0:3\nknitr::kable(tabla.fun.marginal.X1.X2)\n```\n\n::: {.cell-output-display}\n|   |         0|         1|         2|         3|\n|:--|---------:|---------:|---------:|---------:|\n|0  | 0.2962963| 0.2222222| 0.0555556| 0.0046296|\n|1  | 0.2222222| 0.1111111| 0.0138889| 0.0000000|\n|2  | 0.0555556| 0.0138889| 0.0000000| 0.0000000|\n|3  | 0.0046296| 0.0000000| 0.0000000| 0.0000000|\n:::\n:::\n\n\n\nlo cual concluye nuestros cálculos con `R`.\n</div>\n</div>\n\n\n## Variables aleatorias $n$-dimensionales continuas\n\n### Definición\n\nRecordemos la definición de **variable continua bidimensional**: $(X,Y)$ es continua si existe una función $f_{XY}:\\mathbb{R}^2\\longrightarrow \\mathbb{R}$, llamada **función de densidad conjunta** no negativa $f_{XY}(x,y)\\geq 0$, para todo $(x,y)\\in\\mathbb{R}^2$ tal que para cualquier región $B$ del plano, la probabilidad de que $(X,Y)$ esté en $B$ se calcula de la forma siguiente:\n$$\nP((X,Y)\\in B)=\\int\\int_B f_{XY}(x,y)\\,dx\\, dy.\n$$\n\nLa generalización natural es, entonces:\n\n<l class=\"definition\">Definición de variable aleatoria $n$-dimensional continua. </l>\nSea $(X_1\\ldots,X_n)$ una variable aleatoria $n$-dimensional. Diremos que $(X_1\\ldots,X_n)$ es continua si existe una función \n$f_{X_1\\ldots X_n}:\\mathbb{R}^n\\longrightarrow \\mathbb{R}$ llamada **función de densidad conjunta** no negativa $f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\geq 0$ para todo $(x_1,\\ldots,x_n)\\in\\mathbb{R}^n$ tal que dado cualquier región $B$ del espacio $n$-dimensional, la probabilidad de que $(X_1\\ldots,X_n)$ esté en $B$ se calcula de la forma siguiente:\n$$\nP((X_1\\ldots,X_n)\\in B)=\\int\\cdots\\int_B f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\cdots\\,dx_n.\n$$\n\n#### Ejemplos\n\n<div class=\"example\">\n**Ejemplo**\n\nConsideremos una variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de densidad conjunta**:\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\n<div class=\"example-sol\">\nEn la figura siguiente hemos dibujado en rosa la región donde $f_{X_1X_2X_3}$ no es cero, es decir $[0,1]\\times [0,1]\\times [0,1]$.\n\n<div class=\"center\">\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/Cubo3D2.png){width=1.48in}\n:::\n:::\n\n\n</div>\n\n</div>\n</div>\n### Propiedades de la función de densidad\n\nConsideremos $(X_1\\ldots,X_n)$ una **variable aleatoria $n$-dimensional continua** con **función de densidad conjunta** $f_{X_1\\ldots X_n}$. Esta función verifica las propiedades siguientes:\n\n* La integral de dicha función sobre todo el espacio $n$-dimensional vale 1: \n$$\n\\int\\int_{\\mathbb{R}^n} f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\cdots dx_n =1.\n$$\nPara ver dicha propiedad, basta considerar $B=\\mathbb{R}^n$, tener en cuenta que el suceso $(X_1\\ldots,X_n)\\in \\mathbb{R}^n$ es el total $\\Omega$ y aplicar la definición de $f_{X_1\\ldots X_n}$:\n$$\nP((X_1\\ldots,X_n)\\in \\mathbb{R}^n)=1= \\int\\cdots\\int_{\\mathbb{R}^n} f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\cdots dx_n.\n$$\n\n* La relación que hay entre la **función de distribución conjunta** $F_{X_1\\ldots X_n}$ y la **función de densidad conjunta** $f_{X_1\\ldots X_n}$ es la siguiente:\n$$\nF_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=\\int_{-\\infty}^{x_1}\\cdots\\int_{-\\infty}^{x_n} f_{X_1\\ldots X_n}(u_1,\\ldots,u_n)\\,du_1\\cdots du_n.\n$$\nPara ver dicha propiedad, basta considerar $B=(-\\infty,x_1]\\times\\cdots\\times (-\\infty,x_n]$ y aplicar la definición de **función de distribución conjunta**:\n$$\n\\begin{array}{rl}\n& F_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=P((X_1\\ldots,X_n)\\in (-\\infty,x_1]\\times\\cdots (-\\infty,x_n])\\\\ &\\qquad =\\int_{-\\infty}^{x_1}\\cdots\\int_{-\\infty}^{x_n} f_{X_1\\ldots X_n}(u_1,\\ldots,u_n)\\,du_1\\cdots du_n.\n\\end{array}\n$$\n\n* La relación que hay entre la **función de densidad** $F_{X_1\\ldots X_n}$ y la **función de distribución** $f_{X_1\\ldots X_n}$ es la siguiente:\n$$\nf_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=\\frac{\\partial^n F_{X_1\\ldots X_n}(x_1,\\ldots,x_n)}{\\partial x_1\\cdots\\partial x_n}.\n$$\nDicha propiedad se deduce de la anterior, derivando primero respecto a $x_1$, después respecto a $x_2$ y sucesivamente hasta llegar a $x_n$ para eliminar las $n$ integrales.\n\n* La **función de densidad marginal** de la variable $k$ dimensional $(X_{s_1},\\ldots,X_{s_k})$ con $\\{s_1,\\ldots, s_k\\}$ un subconjunto de $\\{1,\\ldots,n\\}$, $f_{X_{s_1}\\ldots,X_{s_k}}$ se calculan de la forma siguiente:\n$$\nf_{X_{s_1}\\ldots,X_{s_k}}(x_{s_1},\\ldots,x_{s_k})=\\int_{x_{t_1}=-\\infty}^{x_{t_1}=\\infty}\\cdots \\int_{x_{t_{n-k}}=-\\infty}^{x_{t_{n-k}}=\\infty} f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\, dx_{t_1}\\cdots dx_{t_{n-k}},\n$$\ncon $\\{t_1,\\ldots,t_{n-k}\\}=\\{1,\\ldots,n\\}\\setminus \\{s_1,\\ldots,s_k\\}.$ Es decir, las variables $t$'s son las que no aparecen en la definición de la variable aleatoria $k$ dimensional $(X_{s_1},\\ldots,X_{s_k})$.\n\n\n\n#### Ejemplos\n\n<div class=\"example\">\n**Ejemplo anterior**\n\nComprobemos las propiedades usando la **función de densidad** del ejemplo anterior: \n\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\n\n<div class=\"example-sol\">\nLa integral de $f_{X_1X_2X_3}$ sobre todo el espacio 3D vale 1:\n\n$$\n\\begin{array}{rl}\n& \\int\\int\\int_{\\mathbb{R}^3} f_{X_1X_2X_3}(x_1,x_2,x_3)\\,dx\\, dy=\\int_0^1\\int_0^1\\int_0^1 8 x_1\\cdot x_2\\cdot x_3\\, dx_1\\,dx_2\\,dx_3\\\\ & \\qquad=8\\int_0^1 x_1\\, dx_1\\int_0^1 x_2\\, dx_2\\int_0^1 x_3\\,dx_3=8\\left[\\frac{x_1^2}{2}\\right]_0^1\\cdot\\left[\\frac{x_2^2}{2}\\right]_0^1\\cdot \\left[\\frac{x_3^2}{2}\\right]_0^1\\\\\n& \\qquad = 8\\cdot\\left(\\frac{1}{2}\\right)^3 =1.\n\\end{array}\n$$\n\nVamos a calcular la función de distribución $F_{X_1X_2X_3}$. \n\nRecordemos que la expresión de la función de distribución en función de la función de densidad era:\n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\int_{-\\infty}^{x_1}\\int_{-\\infty}^{x_2}\\int_{-\\infty}^{x_3}f_{X_1X_2X_3}(u_1,u_2,u_3)\\,du_1\\, du_2\\, du_3.\n$$\nComo la región del espacio 3D donde $f_{X_1X_2X_3}(x_1,x_2,x_3)$ es no nula es el cubo unidad $[0,1]\\times [0,1]\\times [0,1]$, fijado un punto del espacio $(x_1,x_2,x_3)$ es fundamental calcular la intersección de dicho cubo unidad con la región $(-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3]$. \n\nDicha intersección $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$ es la región donde tendremos que integrar la función de densidad para hallar la función de distribución en el punto $(x_1,x_2,x_3)$.\n\nPara hallar la región anterior, vamos a dividir el espacio 3D en tres \"pisos\": \n\n* \"Sótano \" o zona donde $x_3<0$.\n* \"Planta baja\" o zona donde $0\\leq x_3\\leq 1$.\n* \"Primer piso\" o zona donde $x_3>1$.\n\n\n* Si $(x_1,x_2,x_3)$ está en el \"sótano\" o $x_3<0$, claramente, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])=\\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.\n\n* Si $(x_1,x_2,x_3)$ está en la planta baja o $0\\leq x_3\\leq 1$, vamos a distinguir cuatro casos dependiendo de los valores de $x_1$ y $x_2$:\n\n  * $x_1 <0$ o $x_2 <0$. En este caso, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])=\\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.\n  * $0\\leq x_1\\leq 1$ y $0\\leq x_2\\leq 1$. En este caso: \n  $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$ que es igual a $[0,x_1]\\times [0,x_2]\\times [0,x_3]$, ver figura adjunta.\n\nPor tanto,\n$$\n\\begin{array}{rl}\nF_{X_1X_2X_3}(x_1,x_2,x_3) & =\\int_{0}^{x_1}\\int_{0}^{x_2}\\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3\\\\\n& = 8\\left[\\frac{x_1^2}{2}\\right]_0^{x_1}\\left[\\frac{x_2^2}{2}\\right]_0^{x_2}\\left[\\frac{x_3^2}{2}\\right]_0^{x_3} = x_1^2 x_2^2 x_3^2.\n\\end{array}\n$$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Images/Fx1x2x3bajos.png){fig-align='center' width=1.25in}\n:::\n:::\n\n\n\nSeguimos en la planta \"baja\",\n\n* Si $x_1 >1$ y $0\\leq x_2\\leq 1$, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$ que es igual a $[0,1]\\times [0,x_2]\\times [0,x_3]$, ver figura adjunta. Hemos dibujado sólo la parte \"positiva\" de la región $(-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3]$ ya que la parte \"negativa\" claramente no interseca con $[0,1]\\times [0,1]\\times [0,1]$ para no complicar demasiado la figura.\n\nEn este caso,\n\n$$\n\\begin{array}{rl}\nF_{X_1X_2X_3}(x_1,x_2,x_3) & =\\int_{0}^{1}\\int_{0}^{x_2}\\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3 \\\\\n& = \n8\\left[\\frac{x_1^2}{2}\\right]_0^{1}\\left[\\frac{x_2^2}{2}\\right]_0^{x_2}\\left[\\frac{x_3^2}{2}\\right]_0^{x_3} = x_2^2 x_3^2.\n\\end{array}\n$$\n\n* Si $0\\leq x_1$ y $x_2>1$, es un caso parecido al caso anterior pero \"cambiando los papeles\" de $x_1$ y $x_2$. \nPor tanto, \n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2 x_3^2.\n$$\n\n<div class=\"center\">\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Images/Fx1x2x3bajosx1.png){fig-align='center' width=1.25in}\n:::\n:::\n\n\n</div>\n\nSeguimos en la planta \"baja\",\n\n* Si $x_1>1$ y $x_2>1$,  entonces $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$ que es igual a $[0,1]\\times [0,1]\\times [0,x_3]$, ver figura adjunta. También hemos dibujado sólo la parte \"positiva\" de la región $(-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3]$ ya que la parte \"negativa\" claramente no interseca con $[0,1]\\times [0,1]\\times [0,1]$ para no complicar demasiado la figura.\n\nEn este caso,\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\int_{0}^{1}\\int_{0}^{1}\\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3 = \n8\\left[\\frac{x_1^2}{2}\\right]_0^{1}\\left[\\frac{x_2^2}{2}\\right]_0^{1}\\left[\\frac{x_3^2}{2}\\right]_0^{x_3} = x_3^2.\n$$\n\n<div class=\"center\">\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Images/Fx1x2x3bajosx1x2.png){width=1.25in}\n:::\n:::\n\n\n</div>\n\nSupongamos ahora que $(x_1,x_2,x_3)$ está en el \"primer piso\" o $x_3>1$. Aquí también vamos a distinguir 4 casos:\n\n\n* $x_1 <0$ o $x_2 <0$. En este caso, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])=\\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.\n\n* $0\\leq x_1\\leq 1$ y $0\\leq x_2\\leq 1$. En este caso: $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])=[0,x_1]\\times [0,x_2]\\times [0,1]$, ver figura adjunta.\n\nEn este caso,\n\n$$\n\\begin{array}{rl}\nF_{X_1X_2X_3}(x_1,x_2,x_3) & =\\int_{0}^{x_1}\\int_{0}^{x_2}\\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3\\\\\n& = 8\\left[\\frac{x_1^2}{2}\\right]_0^{x_1}\\left[\\frac{x_2^2}{2}\\right]_0^{x_2}\\left[\\frac{x_3^2}{2}\\right]_0^{1} = x_1^2 x_2^2.\n\\end{array}\n$$\n\n<div class=\"center\">\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![center](Images/Fx1x2x3piso.png){width=1.25in}\n:::\n:::\n\n\n</div>\n\n\nSeguimos en el \"primer piso\",\n\n* Si $x_1 >1$ y $0\\leq x_2\\leq 1$, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$\n que es igual a $[0,1]\\times [0,x_2]\\times [0,1]$, ver figura adjunta. \n\nEn este caso,\n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\int_{0}^{1}\\int_{0}^{x_2}\\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3 = \n8\\left[\\frac{x_1^2}{2}\\right]_0^{1}\\left[\\frac{x_2^2}{2}\\right]_0^{x_2}\\left[\\frac{x_3^2}{2}\\right]_0^{1} = x_2^2.\n$$\n\n* Si $0\\leq x_1 \\leq 1$ y $ x_2> 1$. Este caso es parecido al caso anterior pero \"cambiando los papeles\" de $x_1$ y $x_2$. \nPor tanto, \n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2.\n$$\n\n<div class=\"center\">\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Images/Fx1x2x3pisox1.png){fig-align='center' width=1.25in}\n:::\n:::\n\n\n</div>\n\nSeguimos en el \"primer piso\",\n\n* Si $x_1>1$ y $x_2>1$, $([0,1]\\times [0,1]\\times [0,1])\\cap ((-\\infty,x_1]\\times (-\\infty,x_2]\\times (-\\infty,x_3])$ que es iguala a $[0,1]\\times [0,1]\\times [0,1]$, ver figura adjunta. \n\nEn este caso,\n$$\n\\begin{array}{rl}\nF_{X_1X_2X_3}(x_1,x_2,x_3)& =\\int_{0}^{1}\\int_{0}^{1}\\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\\, dx_2\\ dx_3 \\\\\n& = 8\\left[\\frac{x_1^2}{2}\\right]_0^{1}\\left[\\frac{x_2^2}{2}\\right]_0^{1}\\left[\\frac{x_3^2}{2}\\right]_0^{1} = 1.\n\\end{array}\n$$\n\n\n<div class=\"center\">\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Images/Fx1x2x3pisox1x2.png){fig-align='center' width=1.25in}\n:::\n:::\n\n\n</div>\n\n\n\nEn resumen:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\nx_1^2\\cdot x_2^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n x_2^2\\cdot x_3^2, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_3^2, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_2^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n x_1^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n x_2^2, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n1, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1.\n\\end{cases}\n$$\n\nDicha función era la función que nos sirvió como ejemplo a la hora de introducir la variables aleatorias $n$-dimensionales. Ahora sabemos que es continua y conocemos su función de densidad.\n\n\nComprobemos seguidamente que si derivamos tres veces la expresión de $F_{X_1X_2X_3}$, primero respecto $x_1$, luego respecto $x_2$ y finalmente respecto $x_3$, obtendremos la **función de densidad** $f_{X_1X_2X_3}$.\n\nSi derivamos respecto $x_1$ obtenemos:\n$$\n\\frac{\\partial F_{X_1X_2X_3}(x_1,x_2,x_3)}{\\partial x_1}=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\n2 x_1\\cdot x_2^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n 2 x_1 \\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 2 x_1\\cdot x_2^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n 2 x_1, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n 0, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n0, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1.\n\\end{cases}\n$$\n\n\nSi ahora derivamos respecto $x_2$ obtenemos:\n$$\n\\frac{\\partial^2 F_{X_1X_2X_3}(x_1,x_2,x_3)}{\\partial x_2\\partial x_1}=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\n4 x_1\\cdot x_2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 4 x_1\\cdot x_2, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n 0, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n 0, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n0, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1.\n\\end{cases}\n$$\n\nPor último, si derivamos respecto $x_3$, obtenemos:\n$$\n\\frac{\\partial^3 F_{X_1X_2X_3}(x_1,x_2,x_3)}{\\partial x_3\\partial x_2\\partial x_1}=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n 0, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n 0, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n 0, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n0, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1,\n\\end{cases}\n$$\nexpresión que coincide con la función de densidad $f_{X_1X_2X_3}(x_1,x_2,x_3)$.\n\n\nAcabemos el ejemplo calculando las **funciones de densidad marginales** de las variables $X_1$, $X_2$, $X_3$, $(X_1,X_2)$, $(X_1,X_3)$, $(X_2,X_3)$.\n\nDebido a la simetría de la región donde $f_{X_1X_2X_3}(x_1,x_2,x_3)$ no se anula, es suficiente calcular la función de densidad marginal para las variables $X_1$ y $(X_1,X_2)$. Para ver las demás, basta cambiar los \"papeles\" de las variables correspondientes. Por ejemplo, la función de densidad de la variable $X_2$ es la misma que la de la variable $X_1$ cambiando $x_1$ por $x_2$.\n\n\nPara hallar la función de densidad de la variable $X_1$, aplicamos la fórmula vista anteriormente:\n$$\nf_{X_1}(x_1)=\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty  f_{X_1X_2X_3}(x_1,x_2,x_3)\\, dx_2\\, dx_3.\n$$\nRecordemos que la región donde no se anulaba la **función de densidad conjunta** $f_{X_1X_2X_3}$ era el cubo $[0,1]\\times [0,1]\\times [0,1]$. Por tanto, fijado $x_1$, el valor de $f_{X_1}(x_1)$ es no nulo si el plano \"vertical\" $X_1=x_1$ interseca dicho cubo. Y esto ocurre siempre que $x_1\\in (0,1)$. Por tanto,\n$$\nf_{X_1}(x_1)=\\begin{cases}\n\\int_{0}^1\\int_0^1 8 x_1x_2 x_3  \\, dx_2\\, dx_3=8x_1\\left[\\frac{x_2^2}{2}\\right]_0^1 \\left[\\frac{x_3^2}{2}\\right]_0^1 =2 x_1, & \\mbox{ si }x_1\\in (0,1),\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\n$$\n\n\nPara hallar la función de densidad conjunta de la variable $(X_1,X_2)$, aplicamos la expresión siguiente:\n$$\nf_{X_1X_2}(x_1,x_2)=\\int_{-\\infty}^\\infty  f_{X_1X_2X_3}(x_1,x_2,x_3)\\, dx_3.\n$$\nEn este caso, fijado $x_1$ y $x_2$, tenemos que ver cuando la recta \"vertical\" $X_1=x_1$, $X_2=x_2$ intersecta el cubo $[0,1]\\times [0,1]\\times [0,1]$ y esto ocurre siempre que $(x_1,x_2)\\in [0,1]\\times [0,1]$.\nPor tanto,\n\n$$\nf_{X_1X_2}(x_1,x_2)=\\begin{cases}\n\\begin{array}{rl}\n\\int_{0}^1 8 x_1x_2 x_3  \\, dx_3\\\\ & =8x_1x_2 \n\\left[\\frac{x_3^2}{2}\\right]_0^1 =4 x_1 x_2\\end{array},\n& \\mbox{ si }(x_1,x_2)\\in [0,1]\\times [0,1],\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\n$$\n</div>\n</div>\n\n### La distribución gaussiana $n$-dimensional\nVamos a generalizar la distribución normal a $n$ dimensiones.\n\n<l class=\"definition\">Definición de distribución gaussiana $n$-dimensional. </l>\nDiremos que la distribución de la variable aleatoria $n$-dimensional $(X_1\\ldots,X_n)$ es **gaussiana $n$-dimensional** dependiendo del **vector de medias** $\\mathbf{\\mu}$ y de la **matriz de covarianzas** $\\Sigma$ si su **función de densidad conjunta** es:\n$$\n\\begin{array}{rl}\n& f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{\\mathbf{|\\Sigma|}}}\\mathrm{e}^{-\\frac{1}{2}(\\mathbf{x-\\mu})^\\top\\mathbf{\\Sigma}^{-1}(\\mathbf{x-\\mu})},\\\\ & \\qquad  -\\infty <x_1,\\ldots,x_n<\\infty,\n\\end{array}\n$$\nSe denota $\\mathbf{X}=(X_1,\\ldots,X_n)$ con $\\mathbf{X}={\\cal N}(\\mathbf{\\mu},\\mathbf{\\Sigma})$, donde $\\mathbf{x}=\\begin{pmatrix}x_1\\\\\\vdots\\\\ x_n\\end{pmatrix}$, $\\mathbf{\\mu}=\\begin{pmatrix}\\mu_1\\\\\\vdots\\\\ \\mu_n\\end{pmatrix}$ es el **vector de medias** de cada variable aleatoria $X_1,\\ldots, X_n$ y $\\mathbf{\\Sigma}$ es la denominada **matriz de covarianzas** que nos sirve para estudiar la relación lineal entre las variables $X_i$, $i=1,\\ldots, n$.\n\nDe hecho la componente $(i,j)$ de la **matriz de covarianzas** $\\mathbf{\\Sigma}$, $\\sigma_{ij}$ es la **covarianza** entre las variables $X_i$ y $X_j$. \n\nPor tanto, los elementos de la diagonal de la **matriz de covarianzas** $\\mathbf{\\Sigma}$, $\\sigma_{ii}$, es las varianzas de las variables $X_i$, $i=1,\\ldots,n$.\n\n\nPropiedades de la **función de densidad de la variable gaussiana $n$-dimensional**:\n\n* Para cualquier punto $(x_1,\\ldots,x_n)\\in\\mathbb{R}^n$, la **función de densidad** es no nula: $f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)>0$.\n\n* La **función de densidad** tiene un único máximo absoluto en el punto $\\mathbf{\\mu}$ que vale $f_{X_1\\ldots X_n}(\\mathbf{\\mu})=\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{\\mathbf{|\\Sigma|}}}$. \n\nAntes de estudiar cómo son las distribuciones de las **marginales** de una distribución **normal $n$-dimensional**, enunciemos el resultado siguiente:\n\n<l class=\"prop\">Proposición (transformación afín de una **normal $n$-dimensional**)</l>\nSea $\\mathbf{X}={\\cal N}(\\mathbf{\\mu},\\mathbf{\\Sigma})$ una distribución **normal $n$-dimensional**. Sea la variable $k$-dimensional $\\mathbf{Y}$ construida como $\\mathbf{Y}=\\mathbf{c}+\\mathbf{C}\\mathbf{X}$, con $\\mathbf{C}$ una matriz $k\\times n$ y $\\mathbf{c}$ un vector $k$-dimensional. Entonces la variable $Y$ se distribuye como una variable **normal $k$-dimensional** de media $\\mathbf{\\mu}_{\\mathbf{Y}}=\\mathbf{c}+\\mathbf{C}\\mathbf{\\mu}$ y matriz de covarianzas $\\mathbf{\\Sigma}_{\\mathbf{Y}}=\\mathbf{C}\\mathbf{\\Sigma}\\mathbf{C}^\\top$: $\\mathbf{Y}={\\cal N}(\\mathbf{c}+\\mathbf{C}\\mathbf{\\mu},\\mathbf{C}\\mathbf{\\Sigma}\\mathbf{C}^\\top)$.\n\nUsando la proposición anterior, podemos afirmar:\n\n<l class=\"prop\">Proposición (distribución marginal de una **variable normal $n$-dimensional**)</l>\nSea $\\mathbf{X}={\\cal N}(\\mathbf{\\mu},\\mathbf{\\Sigma})$ una distribución **normal $n$-dimensional**. Sea $(X_{s_1},\\ldots,X_{s_k})$ la variable $k$ dimensional con las componentes $s_1,\\ldots,s_k$, con $s_i\\in\\{1,\\ldots,n\\}$, entonces la variable $(X_{s_1},\\ldots,X_{s_k})$ se distribuye según una **normal $k$-dimensional** de media $(\\mu_{s_1},\\ldots,\\mu_{s_k})$ y matriz de covarianzas $\\mathbf{\\Sigma'}$ formada por las $s_1,\\ldots,s_k$ filas y columnas de la matriz de covarianzas de la variable $\\mathbf{X}$, $\\mathbf{\\Sigma}$.\n\nPara ver la proposición anterior a partir de la proposición de la transformación afín, hagamos un ejemplo concreto:\n\n<div class=\"example\">\n**Ejemplo: normal multidemisional de dimensión 5**\n\nConsideremos una variable normal $5$-dimensional de **vector de medias** general $\\mathbf{\\mu}=(\\mu_1,\\mu_2,\\mu_3,\\mu_4,\\mu_5)$ y **matriz de covarianzas**\n$$\n\\mathbf{\\Sigma}=\\begin{pmatrix}\n\\sigma_{11} & \\sigma_{12} & \\sigma_{13} & \\sigma_{14} & \\sigma_{15} \\\\\n\\sigma_{21} & \\sigma_{22} & \\sigma_{23} & \\sigma_{24} & \\sigma_{25} \\\\\n\\sigma_{31} & \\sigma_{32} & \\sigma_{33} & \\sigma_{34} & \\sigma_{35} \\\\\n\\sigma_{41} & \\sigma_{42} & \\sigma_{43} & \\sigma_{44} & \\sigma_{45} \\\\\n\\sigma_{51} & \\sigma_{52} & \\sigma_{53} & \\sigma_{54} & \\sigma_{55} \n\\end{pmatrix}\n$$\n\n\nQueremos estudiar cuál es la distribución de la variable $3$-dimensional $(X_2,X_4,X_5)$.\n\n<div class=\"example-sol\">\n\nPara ello consideramos el vector $\\mathbf{c}=0$ y la matriz $\\mathbf{C}$ siguiente:\n$$\n\\mathbf{C}=\\begin{pmatrix}\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 \\\\\n\\end{pmatrix}\n$$\n Esta matriz $\\mathbf{C}$ es  de dimensiones$3\\times 5$ y  vale 1 en los lugares $(1,2)$, $(2,4)$ y $(3,5)$. Fijémonos que las segundas componentes de los lugares anteriores son precisamente las componentes elegidas de la variable $\\mathbf{X}$.\n\nLa matriz $\\mathbf{Y}=\\mathbf{C}\\cdot \\mathbf{X}=\\begin{pmatrix}X_2\\\\X_4\\\\X_5\\end{pmatrix}$ vale precisamente la variable marginal que queremos estudiar.\n\n\nAplicando la proposición de la transformación afín, podemos afirmar que la distribución de la variable $\\mathbf{Y}=\\begin{pmatrix}X_2\\\\X_4\\\\X_5\\end{pmatrix}$ es una normal $3$ dimensional de **vector de medias** $\\mu_{\\mathbf{Y}}=\\mathbf{C}\\mathbf{\\mu}=\\begin{pmatrix}\\mu_2\\\\\\mu_4\\\\\\mu_5\\end{pmatrix}$ y vector de covarianzas\n\n$$\n\\mathbf{\\Sigma'}=\\mathbf{C}\\mathbf{\\Sigma}\\mathbf{C}^\\top = \\begin{pmatrix}\\sigma_{22} & \\sigma_{24} & \\sigma_{25}\\\\ \\sigma_{42} & \\sigma_{44} & \\sigma_{45} \\\\  \\sigma_{52} & \\sigma_{54} & \\sigma_{55}\\end{pmatrix}, \n$$\ntal como indica la última proposición sobre distribuciones marginales.\n</div>\n</div>\n\n## Independencia de variables aleatorias\n\n\n### Independencia de variables aleatorias discretas\n\nLa generalización de **independencia** a variables aleatorias $n$-dimensionales es clara:\n\n<l class=\"definition\">Definición de independencia para variables aleatorias multidimensionales discretas.</l>\n\nSean $(X_1\\ldots,X_n)$ una **variable aleatoria $n$-dimensional discreta** con $(X_1\\ldots,X_n)(\\Omega)=\\{(x_{i_1},\\ldots,x_{i_n}),\\ i_1=1,2,\\ldots,i_n=1,2,\\ldots\\}$ y **función de probabilidad conjunta** $P_{X_1\\ldots X_n}$ y **funciones de probabilidad marginales** $P_{X_1},\\ldots P_{X_n}$. Entonces $X_1,\\ldots X_n$ son independientes si:\n\n$$\nP_{X_1\\ldots X_n}(x_{i_1},\\ldots,x_{i_n})=P_{X_1}(x_{i_1})\\cdots P_{X_n}(x_{i_n}),\\ i_1=1,2,\\ldots,i_n=1,2,\\ldots\n$$\n\no dicho de otra forma:\n\n$$\nP(X_1=x_{i_1},\\ X_n=x_{i_n})=P(X_1=x_{i_1})\\cdots P(X_n=x_{i_n}),\\ i_1=1,2,\\ldots,i_n=1,2,\\ldots\n$$\n\n\n<div class=\"example\">\n**Ejemplo del lanzamiento de un dado tres veces**\n\nConsideremos el experimento aleatorio que consiste en lanzar un dado tres veces. \n\nRecordemos que hemos estudiado la variable aleatoria $(X_1,X_2,X_3)$ donde $X_1$ nos daba el número de 1's que han salido, $X_2$, el número de 2's y $X_3$, el número de 3's.\n\n<div class=\"example-sol\">\nLas variables aleatorias anteriores no son independientes ya que, por ejemplo:\n$$\n\\scriptsize{\nP_{X_1,X_2,X_3}(1,1,3)=0\\neq P_{X_1}(1)\\cdot P_{X_2}(1)\\cdot P_{X_3}(3)=0.3472\\cdot 0.3472\\cdot 0.0046=\\ensuremath{6\\times 10^{-4}}.}\n$$\n\n</div>\n</div>\n\n<l class=\"observ\">Observación. </l>\nAl igual que pasaba con las variables bidimensionales, si la tabla de la **función de probabilidad conjunta** de $(X_1,\\ldots,X_n)$ contiene algún $0$, las variables $X_1,\\ldots, X_n$ no pueden ser independientes. ¿Podéis decir por qué?\n\n<l class=\"observ\"> Observación. </l>\nSi $X_1,\\ldots, X_n$ son variables aleatorias independientes, y consideramos una distribución marginal, por ejemplo $(X_{s_1},\\ldots,X_{s_k})$, entonces las variables $X_{s_1},\\ldots,X_{s_k}$ también son independientes.\n\n\n### Independencia de variables aleatorias continuas\nLa definición dada para **variables aleatorias discretas** se traslada de forma natural a las **variables aleatorias continuas**:\n\n<l class=\"definition\">Definición de independencia para variables aleatorias multidimensionales continuas. </l>\n\nSean $(X_1\\ldots,X_n)$ una **variable aleatoria $n$-dimensional continua** con **función de densidad conjunta** $f_{X_1\\ldots X_n}$ y **funciones de densidad marginales** $f_{X_1},\\ldots,f_{X_n}$. Entonces $X_1,\\ldots, X_n$ son independientes si:\n\n$$\nf_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=f_{X_1}(x_1)\\cdots f_{X_n}(x_n),\\ \\mbox{para todo $x_1,\\ldots,x_n\\in\\mathbb{R}$.}\n$$\n\n<div class=\"example\">\n**Ejemplo: variable aleatoria tridimensional continua**\n\nRecordemos el ejemplo siguiente visto donde teníamos una **variable aleatoria $3$-dimensional continua** $(X_1,X_2,X_3)$ con **función de densidad conjunta**:\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\ny con densidad marginales:\n$$\n\\begin{array}{rl}\nf_{X_1}(x_1) & =\\begin{cases}\n2x_1, & \\mbox{ si }0\\leq x\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\quad f_{X_2}(x_2)=\\begin{cases}\n2x_2, & \\mbox{ si }0\\leq x_2\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\\\ f_{X_3}(x_3) & =\\begin{cases}\n2x_3, & \\mbox{ si }0\\leq x_3\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\n\\end{array}\n$$\n\nVeamos que son independientes.\n<div class=\"example-sol\">\n\nConsideremos dos casos:\n\n* $(x_1,x_2,x_3)\\in [0,1]\\times [0,1]\\times [0,1]$. En este caso:\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3) =8 x_1 x_2 x_3 =2 x_1 2 x_2 2 x_3=f_{X_1}(x_1)\\cdot f_{X_2}(x_2)\\cdot f_{X_3}(x_3).\n$$\n\n* $(x_1,x_2,x_3)\\not\\in [0,1]\\times [0,1]\\times [0,1]$. En este caso:\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)  =0 = f_{X_1}(x_1)\\cdot f_{X_2}(x_2)\\cdot f_{X_3}(x_3),\n$$\nya que si $(x_1,x_2,x_3)\\not\\in  [0,1]\\times [0,1]\\times [0,1]$, o $x_1\\not\\in [0,1]$ o $x_2\\not\\in [0,1]$, o $x_3\\not\\in [0,1]$. Por tanto $f_{X_1}(x_1)=0$ o $f_{X_2}(x_2)=0$ o $f_{X_3}(x_3)=0$. En cualquier caso, $f_{X_1}(x_1)\\cdot f_{X_2}(x_2)\\cdot f_{X_3}(x_3)=0$.\n</div>\n</div>\n\n#### Ejemplo de la variable gaussiana $n$-dimensional\nEn este caso, recordemos que la **función de densidad conjunta** de $(X_1,\\ldots,X_n)$ es:\n$$\n\\begin{array}{rl}\n& f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{\\mathbf{|\\Sigma|}}}\\mathrm{e}^{-\\frac{1}{2}(\\mathbf{x-\\mu})^\\top\\mathbf{\\Sigma}^{-1}(\\mathbf{x-\\mu})},\\\\ & \\qquad  -\\infty <x_1,\\ldots,x_n<\\infty,\n\\end{array}\n$$\ndonde $\\mathbf{\\mu}$ es el vector de medias y $\\mathbf{\\Sigma}$, la matriz de covarianzas.\n\nRecordemos también que las **funciones de densidad marginales** de $X_1,\\ldots, X_n$ correspondían a $N(\\mu_i,\\sqrt{\\sigma_{ii}})$, con $i=1,\\ldots, n$:\n$$\nf_{X_i}(x_i)  =\\frac{1}{\\sqrt{2\\pi\\sigma_{ii}}}\\mathrm{e}^{-\\frac{(x_i-\\mu_i)^2}{2\\sigma_{ii}}},\\ -\\infty <x_i<\\infty,\\ i=1,\\ldots,n.\n$$\n\n¿Cómo tiene que ser la matriz de covarianzas $\\mathbf{\\Sigma}$ para que las variables $X_1,\\ldots,X_n$ sean independientes?\n\nO, expresado matemáticamente,\n$$\n\\begin{array}{rl}\nf_{X_1}(x_1)\\cdots f_{X_n}(x_n) & =\\frac{1}{\\left(2\\pi\\right)^{\\frac{n}{2}}\\sqrt{\\sigma_{11}\\cdots \\sigma_{nn}}}\\mathrm{e}^{-\\sum\\limits_{i=1}^n\\frac{(x_i-\\mu_i)^2}{2\\sigma_{ii}}}=f_{X_1\\ldots X_n}(x_1,\\ldots,x_n) \\\\ & =\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sqrt{\\mathbf{|\\Sigma|}}}\\mathrm{e}^{-\\frac{1}{2}(\\mathbf{x-\\mu})^\\top\\mathbf{\\Sigma}^{-1}(\\mathbf{x-\\mu})}.\n\\end{array}\n$$\n\nLa respuesta es claramente cuando la matriz de covarianzas $\\mathbf{\\Sigma}$ es diagonal, es decir, si $\\sigma_{ij}=0,$ para $i\\neq j$, para todo $i,j=1,\\ldots,n$.\n\nEn resumen, cuando la covarianza entre dos variables cualesquiera $X_i$ y $X_j$ distintas es cero, las variables normales $X_1,\\ldots,X_n$ son independientes.\n\n\n### Relación de la independencia y la función de distribución\n\nEl siguiente resultado nos da la relación entre la **independencia de variables aleatorias** y su **función de distribución conjunta**:\n\n<l class=\"prop\">Teorema. </l>\nSea $(X_1\\ldots,X_n)$ una variable aleatoria $n$-dimensional. Entonces \n$X_1,\\ldots,X_n$ son independientes si, y sólo si, la **función de distribución conjunta** es el producto de las **funciones de distribución marginales** en todo valor $(x_1,\\ldots,x_n)\\in\\mathbb{R}^n$:\n$$\nF_{X_1\\ldots X_n}(x_1,\\ldots,x_n)=F_{X_1}(x_1)\\cdots F_{X_n}(x_n),\\ (x_1,\\ldots,x_n)\\in\\mathbb{R}^n.\n$$\n\n\n\n#### Ejemplos \n<div class=\"example\">\n**Ejemplo:  densidad tridimensional continuación**\n\nRecordemos la variable aleatoria $3$-dimensional continua con **función de densidad conjunta**:\n\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\nRecordemos también **función de distribución conjunta** es: \n\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n0, & \\mbox{si }x_1<0,\\mbox{ o }x_2<0,\\mbox{ o }x_3 <0\\\\\nx_1^2\\cdot x_2^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n x_2^2\\cdot x_3^2, & \\mbox{si }x_1> 1,\\ 0\\leq x_2\\leq  1,\\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_3^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_3^2, & \\mbox{si }x_1> 1,\\ x_2> 1,\\ \\ 0\\leq x_3\\leq  1, \\\\\n x_1^2\\cdot x_2^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n x_1^2, & \\mbox{si }0\\leq x_1\\leq  1,\\ x_2 >  1,\\ x_3> 1,\\\\\n x_2^2, & \\mbox{si }x_1>1,\\ 0\\leq x_2\\leq  1,\\ x_3> 1,\\\\\n1, & \\mbox{si }x_1\\geq 1,\\ x_2\\geq 1,\\ x_3\\geq 1.\n\\end{cases}\n$$\n\nRecordemos las **funciones de densidad** de las **distribuciones marginales**:\n\n$$\n\\begin{array}{rl}\nf_{X_1}(x_1) & =\\begin{cases}\n2x_1, & \\mbox{ si }0\\leq x\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\\\ \nf_{X_2}(x_2)&=\\begin{cases}\n2x_2, & \\mbox{ si }0\\leq x_2\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\\\ f_{X_3}(x_3) & =\\begin{cases}\n2x_3, & \\mbox{ si }0\\leq x_3\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\n\\end{array}\n$$\n\n\n\n<div class=\"example-sol\">\nDejamos como ejercicio verificar que las expresiones siguientes correspondes a las **funciones de distribución marginales**: \n\n\n$$\n\\begin{array}{rl}\nF_{X_1}(x_1) & =\\begin{cases}\n0, & \\mbox{ si }x_1<0, \\\\\nx_1^2, & \\mbox{ si }0\\leq x_1\\leq 1,\\\\\n1, & \\mbox{ si }x_1 > 1.\n\\end{cases}\\\\\nF_{X_2}(x_2) & =\\begin{cases}\n0, & \\mbox{ si }x_2<0, \\\\\nx_2^2, & \\mbox{ si }0\\leq x_2\\leq 1,\\\\\n1, & \\mbox{ si }x_2 > 1.\n\\end{cases}\\\\ F_{X_3}(x_3) & =\\begin{cases}\n0, & \\mbox{ si }x_3<0, \\\\\nx_3^2, & \\mbox{ si }0\\leq x_3\\leq 1,\\\\\n1, & \\mbox{ si }x_3 > 1.\n\\end{cases}\n\\end{array}\n$$\n\nRecordemos que $X_1$, $X_2$ y $X_3$ son independientes. Por tanto verifiquemos que $F_{X_1X_2X_3}(x_1,x_2,x_3)=F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3)$ para todos los valores $x_1,x_2,x_3\\in\\mathbb{R}$.\n\nDistingamos los mismos casos que en la **función de distribución conjunta**:\n\n* $x_1<0$, o $x_2<0$, o $x_3 <0$. En este caso, o $F_{X_1}(x_1)=0$, o $F_{X_2}(x_2)=0$ o $F_{X_3}(x_3)=0$. En cualquier caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=0= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $0\\leq x_1\\leq 1$, y $0\\leq x_2\\leq 1$, y $0\\leq x_3\\leq 1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\\cdot x_2^2\\cdot x_3^2= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $x_1> 1$, y $0\\leq x_2\\leq  1$, y $0\\leq x_3\\leq  1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_2^2\\cdot x_3^2=1\\cdot x_2^2\\cdot x_3^2= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $0\\leq x_1\\leq  1,$ y $x_2> 1$, y $0\\leq x_3\\leq  1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\\cdot x_3^2=x_1^2\\cdot 1\\cdot x_3^2= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $x_1> 1$, y $x_2> 1$, y $0\\leq x_3\\leq  1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_3^2=1\\cdot 1\\cdot x_3^2= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $0\\leq x_1\\leq  1$, y $0\\leq x_2\\leq  1$, y $x_3> 1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\\cdot x_2^2=x_1^2\\cdot x_2^2\\cdot 1= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $0\\leq x_1\\leq  1$, y $x_2 >  1$, y $x_3> 1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2=x_1^2\\cdot 1\\cdot 1= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $x_1>  1$, y $0\\leq x_2 \\leq   1$, y $x_3> 1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=x_2^2=1\\cdot x_2^2\\cdot 1= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n\n* $x_1>  1$, y $x_2>1$, y $x_3> 1$. En este caso:\n$$\nF_{X_1X_2X_3}(x_1,x_2,x_3)=1=1\\cdot 1\\cdot 1= F_{X_1}(x_1)\\cdot F_{X_2}(x_2)\\cdot F_{X_3}(x_3).\n$$\n</div>\n</div>\n\n## Momentos conjuntos y valores esperados conjuntos\n\n### Valor esperado de una función de $n$ variables aleatorias\nSea $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional. \n\nSea $P_{X_1\\ldots X_n}$ su **función de probabilidad conjunta** en el caso en que $(X_1,\\ldots,X_n)$ sea **discreta** y $f_{X_1\\ldots X_n}$ su **función de densidad conjunta** en el caso en que $(X_1,\\ldots,X_n)$ sea **continua**.\n\nSea $Z=g(X_1,\\ldots,X_n)$ una **variable aleatoria unidimensional** función de las variables $X_1,\\ldots,X_n$. Por ejemplo: \n\n* Media aritmética de las $n$ variables $g(x_1,\\ldots,x_n)=\\frac{x_1+\\cdots + x_n}{n}$: $Z=\\frac{X_1+\\cdots +X_n}{n}$.\n* Media geométrica de las $n$ variables $g(x_1,\\ldots,x_n)=\\sqrt[n]{x_1\\cdots x_n}$: $Z=\\sqrt[n]{X_1\\cdots X_n}$.\n* Suma de los cuadrados de las variables $g(x_1,\\ldots,x_n)=x_1^2+\\cdots +x_n^2$: $Z=X_1^2+\\cdots +X_n^2$.\n\nHay que tener en cuenta que $Z$, como **variable aleatoria unidimensional** tiene una **función de probabilidad** $P_Z$ en el caso en que $(X_1,\\ldots,X_n)$ sea discreta y una **función de densidad** $f_Z$ en el caso en que $(X_1,\\ldots,X_n)$ sea continua.\n\nEl siguiente resultado nos dice cómo calcular el **valor esperado** de $Z$ sin tener que calcular $P_Z$ o $f_Z$, sólo usando la información de la **variable aleatoria conjunta** $(X_1,\\ldots,X_n)$:\n\n<l class=\"prop\">Proposición. </l>\nEl valor esperado de $Z$ se puede hallar usando la expresión siguiente:\n\n* en el caso en que $(X_1,\\ldots,X_n)$ sea discreta con $(X_1,\\ldots,X_n)(\\Omega)=\\{(x_{i_1},\\ldots,x_{i_n}),\\ i_1=1,2,\\ldots, i_n=1,2,\\ldots\\}$,\n$$\nE(Z)  = E(g(X_1\\ldots,X_n))  =\\sum_{x_{i_1}}\\cdots\\sum_{x_{i_n}}g(x_{i_1},\\ldots,x_{i_n})P(x_{i_1},\\ldots,x_{i_n}),\n$$\n\n* en el caso en que $(X_1,\\ldots,X_n)$ sea continua:\n$$\n\\begin{array}{rl}\n& E(Z)=E(g(X_1\\ldots,X_n)) \\\\ & \\quad =\\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty g(x_1,\\ldots,x_n)f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\, dx_1\\ldots dx_n.\n\\end{array}\n$$\n\n### Ejemplos\n<div class=\"example\">\n**Ejemplo del lanzamiento de un dado tres veces**\n\nConsideremos el ejemplo de la variable $(X_1,X_2,X_3)$ que nos daba el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces.\n\nVamos a calcular $E\\left(X_1\\cdot X_2\\cdot X_3\\right)$. \n<div class=\"example-sol\">\n\nEl valor esperado anterior se calcula como sigue:\n$$\nE\\left(X_1\\cdot X_2\\cdot X_3\\right)\\displaystyle =\\sum_{i_1=0}^3\\sum_{i_2=0}^3\n\\sum_{i_3=0}^3 i_1\\cdot i_2\\cdot i_3\\cdot P_{X_1X_2X_3}(i_1,i_2,i_3),\n$$\nen total $4^3=64$ términos. Como el cálculo es tedioso, lo vamos a realizar con ayuda de `R`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalor.esperado=0;\nfor (i1 in 0:3){\n  for (i2 in 0:3){\n    for (i3 in 0:3){\n      valor.esperado=valor.esperado+i1*i2*i3*fun.prob.con(i1,i2,i3)\n    }\n  }\n}\nvalor.esperado\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02777778\n```\n:::\n:::\n\n\n</div>\n</div>\n\n<div class=\"example\">\n**Ejemplo: densidad tridimensional (continuación)**\n\nRecordemos la variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de densidad conjunta**:\n\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\nCalculemos $E(X_1^2+X_2^2+X_3^2)$:\n<div class=\"example-sol\">\n$$\n\\scriptsize{\n\\begin{array}{rl}\nE(X_1^2+X_2^2+X_3^2) & \\displaystyle=\\int_{x_1=0}^{x_1=1} \\int_{x_2=0}^{x_2=1}\\int_{x_3=0}^{x_3=1} (x_1^2+x_2^2+x_3^2) 8\\cdot x_1\\cdot x_2\\cdot  x_3 \\,dx_1\\, dx_2\\, dx_3\\\\ & =8\\cdot \\left(\\int_{x_1=0}^{x_1=1} \\int_{x_2=0}^{x_2=1}\\int_{x_3=0}^{x_3=1}   x_1^3\\cdot  x_2\\cdot  x_3 \\,dx_1\\, dx_2\\, dx_3 + \\int_{x_1=0}^{x_1=1} \\int_{x_2=0}^{x_2=1}\\int_{x_3=0}^{x_3=1}   x_1 \\cdot x_2^3 \\cdot x_3 \\,dx_1\\, dx_2\\, dx_3 \\right.\\\\ & \\left. + \\int_{x_1=0}^{x_1=1} \\int_{x_2=0}^{x_2=1}\\int_{x_3=0}^{x_3=1}   x_1\\cdot  x_2\\cdot  x_3^3 \\,dx_1\\, dx_2\\, dx_3\\right) \\\\ & =\n8\\left(\\left[\\frac{x_1^4}{4}\\right]_0^1 \\left[\\frac{x_2^2}{2}\\right]_0^1 \\left[\\frac{x_3^2}{2}\\right]_0^1 + \\left[\\frac{x_1^2}{2}\\right]_0^1 \\left[\\frac{x_2^4}{4}\\right]_0^1 \\left[\\frac{x_3^2}{2}\\right]_0^1 + \\left[\\frac{x_1^2}{2}\\right]_0^1 \\left[\\frac{x_2^2}{2}\\right]_0^1 \\left[\\frac{x_3^4}{4}\\right]_0^1\\right) \\\\ & =8\\cdot 3\\cdot \\frac{1}{16}=\\frac{3}{2}=1.5.\n\\end{array}}\n$$\n</div>\n\n### Propiedad del valor esperado de la suma de variables\nEn estos momentos estamos en condiciones de demostrar el resultado siguiente:\n\n<l class=\"prop\">Proposición. Valor esperado de la suma de variables aleatorias.</l>\nSea $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional. Entonces el valor esperado de la variable aleatoria suma de las variables es igual a la suma de los valores esperados de cada variable:\n$$\nE(X_1+\\cdots + X_n)=E(X_1)+\\cdots + E(X_n).\n$$\n\n<div class=\"dem\">\n**Demostración**\n\nHaremos la demostración para el caso continuo. Dejamos como ejercicio la demostración en el caso discreto.\n\nPara calcular valor esperado de la suma de variables  necesitamos la  **función de densidad conjunta** $f_{X_1\\ldots X_n}$:\n\n$$\n\\begin{array}{rl}\nE(X_1+\\cdots + X_n) & = \\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty (x_1+\\cdots + x_n)f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\ldots dx_n \\\\ & = \\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty x_1f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\ldots dx_n+ \\cdots \\\\ & + \\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty x_n f_{X_1\\ldots X_n}(x_1,\\ldots,x_n)\\,dx_1\\ldots dx_n \\\\ & = E(X_1)+\\cdots + E(X_n).\n\\end{array}\n$$\n\n</div>\n\n#### Ejemplos\n<div class=\"example\">\n**Ejemplo del lanzamiento de un dado tres veces**\n\nConsideremos el ejemplo de la variable $(X_1,X_2,X_3)$ que nos daba el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces.\n\nComprobemos en este caso que $E(X_1+X_2+X_3)=E(X_1)+E(X_2)+E(X_3)$.\n\nCalculemos $E(X_1+X_2+X_3)$ con `R` usando la misma técnica que en el ejemplo donde calculábamos $E(X_1\\cdot X_2\\cdot X_3)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalor.esperado=0;\nfor (i1 in 0:3){\n  for (i2 in 0:3){\n    for (i3 in 0:3){\n      valor.esperado=valor.esperado+(i1+i2+i3)*fun.prob.con(i1,i2,i3)\n    }\n  }\n}\nvalor.esperado\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.5\n```\n:::\n:::\n\n\n\n\nLa distribución marginal de cada una de las variables $X_1$, $X_2$ y $X_3$ recordemos que es la siguiente:\n\n<div class=\"center\">\n| $X_1$ | 0 | 1| 2 |3 \n|--|--|--|--|--\n| $P_{X_1}$|$0.5787$|$0.3472$|$0.0694$|$0.0046$\n</div>\n\n\n\nEl valor de $E(X_1)=E(X_2)=E(X_3)$ es:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nesperanza.X1=0\nfor (i in 0:3){\n  esperanza.X1=esperanza.X1+i*fun.marginal.X1(i)\n}\nesperanza.X1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n:::\n\n\nClaramente:\n$$\nE(X_1+X_2+X_3)=1.5=E(X_1)+E(X_2)+E(X_3)=0.5+0.5+0.5.\n$$\n\n</div>\n\n\n### Valor esperado de una función de $n$ variables aleatorias independientes\n\nEl siguiente resultado nos simplifica el cálculo del **valor esperado de una función de $n$ variables aleatorias** en el caso en que sean **independientes**:\n\n<l class=\"prop\">Proposición: cálculo del valor esperado de una función de $n$ variables aleatorias en el caso de independencia. </l>\nSea $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional donde suponemos que $X_1,\\ldots,X_n$ son independientes. \nSea $Z=g(X_1,\\ldots,X_n)$ una variable aleatoria unidimensional función de $X_1,\\ldots,X_n$ donde suponemos que podemos \"separar\" las variables $x_1,\\ldots, x_n$ en la función $g$. O lo que es lo mismo, existen $n$ funciones $g_1,\\ldots, g_n$  tal que $g(x_1,\\ldots,x_n)=g_1(x_1)\\cdots g_n(x_n)$ para todo valor $x_1,\\ldots,x_n\\in\\mathbb{R}$. En este caso, el valor esperado de $Z$ se puede calcular como:\n$$\nE(Z)=E(g(X_1\\ldots,X_n))=E_{X_1}(g_1(X_1))\\cdots E_{X_n}(g_n(X_n)).\n$$\n\nEl cálculo de $E(g(X_1\\ldots,X_n))$ que es una suma múltiple en el caso de que $(X_1,\\ldots,X_n)$ sea **discreta** o una integral múltiple en el caso en que $(X_1,\\ldots,X_n)$ sea continua se transforma en el producto de $n$ sumas simples (caso **discreto**) o el producto de $n$ integrales simples (caso **continuo**):\n\n$$\n\\begin{array}{rl}\nE(Z) & =E(g(X_1\\ldots,X_n))\\\\ & =\\left(\\sum_{x_{i_1}} g_1(x_{i_1})\\cdot P_{X_1}(x_{i_1})\\right)\\cdots \\left(\\sum_{x_{i_n}} g_n(x_{i_n})\\cdot P_{X_n}(x_{i_n})\\right), \\ \\mbox{caso discreto},\\\\\nE(Z) & =E(g(X_1\\ldots,X_n)) \\\\ & =\\left(\\int_{-\\infty}^\\infty g_1(x_1)\\cdot f_{X_1}(x_1)\\, dx_1\\right)\\cdots \\left(\\int_{-\\infty}^\\infty g_n(x_n)\\cdot f_{X_n}(x_n)\\right), \\ \\mbox{caso continuo}.\n\\end{array}\n$$\n\nUn caso particular de aplicación de la proposición anterior se produce  cuando queramos calcular $E(X_1\\cdots X_n)$. En este caso $g(x_1,\\ldots,x_n)=x_1\\cdots x_n$, $g_1(x_1)=x_1$, y $g_n(x_n)=x_n$. \n\nPodemos escribir, por tanto:\n$$\nE(X_1\\cdots X_n)=E_{X_1}(X_1)\\cdots E_{X_n}(X_n),\n$$\nsi $X_1,\\ldots,X_n$ son independientes.\n\n\n#### Ejemplos\n<div class=\"example\">\n**Ejempo: densidad tridimensional (continuación)**\n\nRecordemos el ejemplo con función de densidad conjunta:\n\n$$\nf_{X_1X_2X_3}(x_1,x_2,x_3)=\\begin{cases}\n8 x_1\\cdot x_2\\cdot x_3, & \\mbox{si }0\\leq x_1\\leq 1,\\ 0\\leq x_2\\leq 1,\\ 0\\leq x_3\\leq 1, \\\\\n0, & \\mbox{en caso contrario.}\\\\\n\\end{cases}\n$$\ndel que ya sebemos que ls tres variables son independientes. \nComprobemos que $E(X_1\\cdot X_2\\cdot X_3)=E(X_1)\\cdot E(X_2)\\cdot E(X_3)$.\n\nCalculemos $E(X_1\\cdot X_2\\cdot X_3)$:\n\n\n<div class=\"example-sol\">\n\n$$\n\\begin{array}{rl}\nE(X_1\\cdot X_2\\cdot X_3)  & = \\int_0^1\\int_0^1\\int_0^1 x_1\\cdot x_2\\cdot x_3\\cdot 8 x_1\\cdot x_2\\cdot x_3\\,dx_1\\, dx_2\\, dx_3 \\\\ & = 8\\int_0^1\\int_0^1\\int_0^1 x_1^2\\cdot x_2^2\\cdot x_3^2\\,dx_1\\, dx_2\\, dx_3 =8\\left[\\frac{x_1^3}{3}\\right]_0^1\\left[\\frac{x_2^3}{3}\\right]_0^1\n\\left[\\frac{x_3^3}{3}\\right]_0^1 \\\\\n& = 8\\cdot \\frac{1}{3^3}=\\frac{8}{27}=0.2963.\n\\end{array}\n$$\n\nRecordemos que las **densidades marginales** son:\n\n$$\n\\begin{array}{rl}\nf_{X_1}(x_1) & =\\begin{cases}\n2x_1, & \\mbox{ si }0\\leq x\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\quad f_{X_2}(x_2)=\\begin{cases}\n2x_2, & \\mbox{ si }0\\leq x_2\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\\\\ f_{X_3}(x_3) & =\\begin{cases}\n2x_3, & \\mbox{ si }0\\leq x_3\\leq 1,\\\\\n0, & \\mbox{en caso contrario.}\n\\end{cases}\n\\end{array}\n$$\n\nPor tanto:\n$$\nE(X_1)=E(X_2)=E(X_3)=\\int_0^1 x\\cdot 2 x\\, dx =2 \\int_0^1 x^2\\, dx=2\\left[\\frac{x^3}{3}\\right]_0^1=\\frac{2}{3}.\n$$\nClaramente, se verifica:\n$$\nE(X_1\\cdot X_2\\cdot X_3)=\\frac{8}{27}=E(X_1)\\cdot E(X_2)\\cdot E(X_3)=\\left(\\frac{2}{3}\\right)^3.\n$$\n</div>\n\n### Propiedades de la covarianza\n\nVeamos cómo se calcula la **covarianza** de dos combinaciones lineales de variables aleatorias:\n\n<l class=\"prop\">Proposición (covarianza de dos combinaciones lineales de variables aleatorias). </l>\nSean $(X_1,\\ldots,X_n)$ e $(Y_1,\\ldots, Y_n)$ dos variables aleatorias $n$-dimensionales. Sean $a_1, \\ldots, a_n$ y $b_1,\\ldots, b_n$  $n$ parejas de valores reales. Sean $U$ y $V$ las variables aleatorias siguientes: \n$U=\\sum\\limits_{i=1}^n a_i X_i,\\  V=\\sum\\limits_{i=1}^n b_i Y_i.$\nEntonces la **covarianza** de las variables $U$ y $V$ se calcula usando la expresión siguiente:\n$$\n\\mathrm{Cov}(U,V)=\\sum_{i=1}^n\\sum_{j=1}^n a_i b_j \\mathrm{Cov}(X_i,Y_j).\n$$\n\n<div class=\"dem\">\n**Demostración**\n\nUsando la expresión de la **covarianza** podemos calcular la covarianza entre las variables $U$ y $V$ como:\n$$\n\\scriptsize{\n\\begin{array}{rl}\n\\mathrm{Cov}(U,V) & =E(UV)-E(U)\\cdot E(V)=E\\left(\\sum\\limits_{i=1}^n a_i \\cdot X_i\\cdot \\sum\\limits_{j=1}^n b_j \\cdot Y_j\\right)- E\\left(\\sum\\limits_{i=1}^n a_i \\cdot X_i\\right)E\\left(\\sum\\limits_{j=1}^n b_j \\cdot Y_j\\right) \\\\ & =\\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^n a_i\\cdot  b_j \\cdot E\\left(X_i Y_j\\right)-\\sum\\limits_{i=1}^n a_i\\cdot  E(X_i)\\sum\\limits_{j=1}^n b_j \\cdot E(Y_j) \\\\\n&= \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^n a_i\\cdot  b_j\\cdot E\\left(X_i Y_j\\right)-\\sum\\limits_{i=1}^n\\sum\\limits_{j=1}^n a_i\\cdot  b_j\\cdot  E(X_i)\\cdot  E(Y_j) \\\\ & = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^n a_i b_j \\left(E\\left(X_i Y_j\\right) - E(X_i)\\cdot  E(Y_j)\\right) = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^n a_i\\cdot  b_j\\cdot  \\mathrm{Cov}(X_i,Y_j),\n\\end{array}}\n$$\ntal como queríamos ver.\n\n</div>\n\nSi en la combinación lineal sólo hay las componentes de una sola variable aleatoria $n$-dimensional, la proposición anterior se convierte en la proposición siguiente:\n\n<l class=\"prop\">Proposición (covarianza de una combinación lineal de variables aleatorias). </l>\nSean $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional.  Sean $a_1, \\ldots, a_n$ y $b_1,\\ldots, b_n$  $n$ parejas de valores reales. Sean $U$ y $V$ las variables aleatorias siguientes:\n$U=\\sum\\limits_{i=1}^n a_i X_i,\\  V=\\sum\\limits_{i=1}^n b_i X_i.$\nEntonces la **covarianza** de las variables $U$ y $V$ se calcula usando la expresión siguiente:\n$$\n\\mathrm{Cov}(U,V)=\\sum_{i=1}^n a_i b_i \\mathrm{Var}(X_i)+\\sum_{i=1}^n\\sum_{j=1,j\\neq i}^n a_i b_j \\mathrm{Cov}(X_i,X_j).\n$$\n\n<div class=\"dem\">\n**Demostración**\n\nUsando la misma técnica de demostración que en la proposición anterior, podemos calcular la covarianza entre las variables $U$ y $V$ como:\n$$\n\\begin{array}{rl}\n\\mathrm{Cov}(U,V) & = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^n a_i\\cdot  b_j\\cdot  \\left(E\\left(X_i \\cdot X_j\\right) - E(X_i)\\cdot  E(X_j)\\right) \\\\\n&= \\sum\\limits_{i=1}^n a_i\\cdot  b_i \\cdot \\left(E\\left(X_i^2\\right) - E(X_i)^2\\right)+\\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n a_i \\cdot b_j\\cdot  \\mathrm{Cov}(X_i,X_j) \\\\ & = \\sum\\limits_{i=1}^n a_i\\cdot  b_i\\cdot  \\mathrm{Var}(X_i)+\\sum\\limits_{i=1}^n \\sum\\limits_{j=1,j\\neq i}^n a_i b_j \\mathrm{Cov}(X_i,X_j),\n\\end{array}\n$$\ntal como queríamos ver.\n\n</div>\n\n<l class=\"observ\"> Observación. </l>\nUna forma equivalente de escribir la covarianza anterior es:\n$$\n\\mathrm{Cov}(U,V)=\\sum_{i=1}^n a_i\\cdot  b_i\\cdot  \\mathrm{Var}(X_i)+2\\sum_{i=1}^n\\sum_{j=1,j>i}^n a_i\\cdot  b_j\\cdot  \\mathrm{Cov}(X_i,X_j).\n$$\n\nComo, en general $\\mathrm{Var}(U)=\\mathrm{Cov}(U,U)$, una consecuencia directa de la proposición anterior es la expresión de la varianza de una combinación lineal de variables aleatorias:\n\n<l class=\"prop\">Proposición (varianza de una combinación lineal de variables aleatorias). </l>\nSean $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional.  Sean $a_1, \\ldots, a_n$  $n$ valores reales. Sea $U$ la variable aleatoria siguiente:\n$U=\\sum\\limits_{i=1}^n a_i X_i.$\nEntonces la **varianza** de la variable $U$ se calcula usando la expresión siguiente:\n$$\n\\mathrm{Var}(U)=\\sum_{i=1}^n a_i^2 \\mathrm{Var}(X_i)+\\sum_{i=1}^n\\sum_{j=1,j\\neq i}^n a_i a_j \\mathrm{Cov}(X_i,X_j).\n$$\n\n<div class=\"dem\">\n**Demostración**\n\nPara la demostración, basta tener en cuenta que $\\mathrm{Var}(U)=\\mathrm{Cov}(U,U)$ y aplicar la expresión de la covariancia entre $U$ y $V$ en la proposición que nos da la covarianza de una combinación lineal de variables aleatorias.\n</div>\n\n<l class=\"observ\"> Observación. </l>\nEn este caso, también existe una forma equivalente de escribir la varianza anterior:\n$$\n\\mathrm{Var}(U)=\\sum_{i=1}^n a_i^2 \\mathrm{Var}(X_i)+2\\sum_{i=1}^n\\sum_{j=1,j>i}^n a_i a_j \\mathrm{Cov}(X_i,X_j).\n$$\n\n\nUna consecuencia de la proposición anterior es que si las variables son **independientes**, la **varianza** de la suma es la suma de varianzas:\n\n<l class=\"prop\">Proposición (varianza de la suma de variables aleatorias independientes). </l>\nSean $(X_1,\\ldots,X_n)$ una variable aleatoria $n$-dimensional donde $X_1,\\ldots, X_n$ son independientes.  \nEntonces la **varianza** de la variable $X_1+\\cdots X_n$ es la suma de las varianzas de cada variable aleatoria:\n$$\n\\mathrm{Var}(X_1+\\cdots + X_n)=\\sum_{i=1}^n \\mathrm{Var}(X_i).\n$$\n\n<div class=\"dem\">\n**Demostración**\n\nPara la demostración, basta aplicar la proposición anterior de la varianza de una combinación lineal de variables aleatorias con $a_i=1$, para todo $i=1,\\ldots,n$ y tener en cuenta que como son independientes, $\\mathrm{Cov}(X_i,X_j)=0$, para todo $i\\neq j$.\n</div>\n",
    "supporting": [
      "6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}