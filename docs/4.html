<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introducción a la probabilidad para el análisis de datos - 5&nbsp; Variables Aleatorias. Complementos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./5.html" rel="next">
<link href="./3.html" rel="prev">
<link href="./cover.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./4.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables Aleatorias. Complementos</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introducción a la probabilidad para el análisis de datos</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/RicUIB/Enlaces" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Alternar modo lector">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prerrequisitos: Teoría de conjuntos y combinatoria</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probabilidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Variables Aleatorias</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Distribuciones Notables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables Aleatorias. Complementos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vectores aleatorios bidimensionales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Vectores aleatorios</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Ley de los grandes números y Teorema Central del Límite</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#momentos-de-variables-aleatorias" id="toc-momentos-de-variables-aleatorias" class="nav-link active" data-scroll-target="#momentos-de-variables-aleatorias"><span class="header-section-number">5.1</span> Momentos de variables aleatorias</a>
  <ul class="collapse">
  <li><a href="#momento-de-orden-n" id="toc-momento-de-orden-n" class="nav-link" data-scroll-target="#momento-de-orden-n"><span class="header-section-number">5.1.1</span> Momento de orden <span class="math inline">\(n\)</span></a></li>
  <li><a href="#momento-central-de-orden-n" id="toc-momento-central-de-orden-n" class="nav-link" data-scroll-target="#momento-central-de-orden-n"><span class="header-section-number">5.1.2</span> Momento central de orden <span class="math inline">\(n\)</span></a></li>
  </ul></li>
  <li><a href="#asimetría-de-una-variable-aleatoria" id="toc-asimetría-de-una-variable-aleatoria" class="nav-link" data-scroll-target="#asimetría-de-una-variable-aleatoria"><span class="header-section-number">5.2</span> Asimetría de una variable aleatoria</a></li>
  <li><a href="#curtosis-o-apuntamiento-de-una-variable-aleatoria" id="toc-curtosis-o-apuntamiento-de-una-variable-aleatoria" class="nav-link" data-scroll-target="#curtosis-o-apuntamiento-de-una-variable-aleatoria"><span class="header-section-number">5.3</span> Curtosis o apuntamiento de una variable aleatoria</a></li>
  <li><a href="#métodos-de-transformación" id="toc-métodos-de-transformación" class="nav-link" data-scroll-target="#métodos-de-transformación"><span class="header-section-number">5.4</span> Métodos de transformación</a>
  <ul class="collapse">
  <li><a href="#función-generatriz-de-momentos" id="toc-función-generatriz-de-momentos" class="nav-link" data-scroll-target="#función-generatriz-de-momentos"><span class="header-section-number">5.4.1</span> Función generatriz de momentos</a></li>
  <li><a href="#función-característica" id="toc-función-característica" class="nav-link" data-scroll-target="#función-característica"><span class="header-section-number">5.4.2</span> Función característica</a></li>
  </ul></li>
  <li><a href="#fiabilidad" id="toc-fiabilidad" class="nav-link" data-scroll-target="#fiabilidad"><span class="header-section-number">5.5</span> Fiabilidad</a>
  <ul class="collapse">
  <li><a href="#tiempo-medio-de-vida" id="toc-tiempo-medio-de-vida" class="nav-link" data-scroll-target="#tiempo-medio-de-vida"><span class="header-section-number">5.5.1</span> Tiempo medio de vida</a></li>
  </ul></li>
  <li><a href="#generación-de-muestras-de-variables-aleatorias-por-ordenador" id="toc-generación-de-muestras-de-variables-aleatorias-por-ordenador" class="nav-link" data-scroll-target="#generación-de-muestras-de-variables-aleatorias-por-ordenador"><span class="header-section-number">5.6</span> Generación de muestras de variables aleatorias por ordenador</a>
  <ul class="collapse">
  <li><a href="#método-de-transformación" id="toc-método-de-transformación" class="nav-link" data-scroll-target="#método-de-transformación"><span class="header-section-number">5.6.1</span> Método de transformación</a></li>
  <li><a href="#método-de-rechazo" id="toc-método-de-rechazo" class="nav-link" data-scroll-target="#método-de-rechazo"><span class="header-section-number">5.6.2</span> Método de rechazo</a></li>
  </ul></li>
  <li><a href="#entropía" id="toc-entropía" class="nav-link" data-scroll-target="#entropía"><span class="header-section-number">5.7</span> Entropía</a>
  <ul class="collapse">
  <li><a href="#entropía-de-una-variable-aleatoria" id="toc-entropía-de-una-variable-aleatoria" class="nav-link" data-scroll-target="#entropía-de-una-variable-aleatoria"><span class="header-section-number">5.7.1</span> Entropía de una variable aleatoria</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/RicUIB/Enlaces/edit/main/4.qmd" class="toc-action"><i class="bi bi-github"></i>Editar esta página</a></li><li><a href="https://github.com/RicUIB/Enlaces/issues/new" class="toc-action"><i class="bi empty"></i>Informar de un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables Aleatorias. Complementos</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<section id="momentos-de-variables-aleatorias" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="momentos-de-variables-aleatorias"><span class="header-section-number">5.1</span> Momentos de variables aleatorias</h2>
<section id="momento-de-orden-n" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="momento-de-orden-n"><span class="header-section-number">5.1.1</span> Momento de orden <span class="math inline">\(n\)</span></h3>
<p><l class="definition"> <strong>Definición.</strong> </l> Sea <span class="math inline">\(X\)</span> una variable aleatoria. Definimos el <strong>momento de orden <span class="math inline">\(n\)</span></strong> como <span class="math inline">\(m_n = E\left(X^n\right)\)</span>.</p>
<p><l class="observ"> <strong>Observación.</strong></l> El momento de orden <span class="math inline">\(1\)</span> de una variable aleatoria es su valor medio o <span class="math inline">\(E(X)\)</span>.</p>
<p>Los momentos de orden <span class="math inline">\(n\)</span> caracterizan una variable <span class="math inline">\(X\)</span>. O sea, que si conocemos todos los momentos de orden <span class="math inline">\(n\)</span>, podemos deducir cuál es la distribución de <span class="math inline">\(X\)</span>.</p>
<p>En general, el cálculo de los momentos de orden <span class="math inline">\(n\)</span> para una variable <span class="math inline">\(X\)</span> es bastante tedioso.</p>
<p><strong>Ejemplos de momentos de orden <span class="math inline">\(n\)</span></strong></p>
<div class="example">
<p><strong>Ejemplo: momento de orden <span class="math inline">\(n\)</span> de una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span>. Recordemos que su función de probabilidad es: <span class="math display">\[
P_X(0)=q=1-p,\ p_X(1)=p.
\]</span> Su momento de orden <span class="math inline">\(n\)</span> será: <span class="math display">\[
m_n = E\left(X^n\right)=p\cdot 1^n+(1-p)\cdot 0^n = p.
\]</span> En este caso, todos los momentos de orden <span class="math inline">\(n\)</span> valen <span class="math inline">\(p\)</span>.</p>
</div>
<div class="example">
<p><strong>Ejemplo: momento de orden <span class="math inline">\(n\)</span> de una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Consideremos ahora una variable <span class="math inline">\(X\)</span> exponencial de parámetro <span class="math inline">\(\lambda\)</span>.</p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\lambda \mathrm{e}^{-\lambda x},\)</span> para <span class="math inline">\(x\geq 0\)</span> y <span class="math inline">\(0\)</span>, en caso contrario.</p>
<p>Su momento de orden <span class="math inline">\(n\)</span> será: <span class="math display">\[
m_n = E\left(X^n\right)=\int_0^\infty \lambda \mathrm{e}^{-\lambda x} x^n\, dx =\frac{n!}{\lambda^n}.
\]</span></p>
<p>La expresión anterior se puede obtener integrando por partes <span class="math inline">\(n\)</span> veces y resolviendo los límites correspondientes. Dejámos al lector los cálculos correspondientes.</p>
<p>Fijémonos que los momentos de orden <span class="math inline">\(n\)</span> tienden a infinito a medida que <span class="math inline">\(n\)</span> crece: <span class="math inline">\(\lim\limits_{n\to\infty}m_n = \lim\limits_{n\to\infty}\frac{n!}{\lambda^n}=\infty\)</span>.</p>
</div>
<div class="example">
<p><strong>Ejemplo: momento de orden <span class="math inline">\(n\)</span> de una variable normal de parámetros <span class="math inline">\(m=0\)</span> y <span class="math inline">\(\sigma =1\)</span></strong></p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}},\)</span> para <span class="math inline">\(x\in \mathbb{R}\)</span>.</p>
<p>Su momento de orden 1 será la esperanza de <span class="math inline">\(X\)</span>: <span class="math inline">\(m_1 = 0\)</span> i su momento de orden 2 será: <span class="math inline">\(m_2 = E\left(X^2\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^2\, dx = 1.\)</span> La integral anterior se resuelve usando técnicas de integrales de dos variables. Dicho valor también se puede obtener usando que su varianza vale 1: <span class="math inline">\(m_2 = \mathrm{Var}(X)+E(X)^2 = \sigma^2 +0^2 = 1.\)</span></p>
<p>Los momentos de orden impar <span class="math inline">\(n\)</span> serán cero ya que integramos una función impar: <span class="math inline">\(m_n = E\left(X^n\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^n\, dx = 0.\)</span> O sea, si consideramos <span class="math inline">\(g(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^n\)</span>, se verifica <span class="math inline">\(g(-x)=-g(x)\)</span>, para todo <span class="math inline">\(x\in\mathbb{R}\)</span>.</p>
<p>Si intentamos calcular el momento de orden 4, obtenemos: <span class="math inline">\(m_4 = E\left(X^4\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^4\, dx = 3,\)</span> usando técnicas de integración de dos variables otra vez.</p>
</div>
</section>
<section id="momento-central-de-orden-n" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="momento-central-de-orden-n"><span class="header-section-number">5.1.2</span> Momento central de orden <span class="math inline">\(n\)</span></h3>
<p><l class="definition"> <strong>Definición.</strong> </l> Sea <span class="math inline">\(X\)</span> una variable aleatoria. Definimos el <strong>momento central de orden <span class="math inline">\(n\)</span></strong> como <span class="math inline">\(\mu_n = E\left((X-\mu)^n\right)\)</span>, donde <span class="math inline">\(\mu =E(X)\)</span> es la media o la esperanza de la variable aleatoria <span class="math inline">\(X\)</span>.</p>
<p><l class="observ"> <strong>Observación.</strong></l> El momento central de orden <span class="math inline">\(1\)</span> de una variable aleatoria es siempre 0: <span class="math display">\[
\mu_1 = E\left((X-\mu)\right)=E(X)-E(\mu)=E(X)-E(X)=0.
\]</span></p>
<p><l class="observ"> Observación.</l> El momento central de orden <span class="math inline">\(2\)</span> de una variable aleatoria es la varianza: <span class="math display">\[
\mu_2 = E\left((X-\mu)^2\right):= \mathrm{Var}(X).
\]</span></p>
<p>Los momentos centrales de orden <span class="math inline">\(n\)</span> caracterizan también una variable <span class="math inline">\(X\)</span>. O sea, que si conocemos todos los momentos centrales de orden <span class="math inline">\(n\)</span>, podemos deducir cuál es la distribución de <span class="math inline">\(X\)</span>.</p>
<p><l class="prop"> <strong>Proposición.</strong></l> La relación que hay entre los momentos centrales y los momentos de una variable aleatoria es la siguiente: <span class="math display">\[
\mu_n = \sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} m_k = \sum_{k=0}^n (-1)^{k} \binom{n}{k} \mu^{k} m_{n-k},
\]</span> donde <span class="math inline">\(\mu =E(X)\)</span> recordemos que es la esperanza de la variable aleatoria <span class="math inline">\(X\)</span>.</p>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>Recordemos la definición de momento central de orden <span class="math inline">\(n\)</span> y desarrollemos su expresión aplicando el <strong>binomio de Newton</strong>: <span class="math display">\[
\mu_n = E\left((X-\mu)^n\right) =E\left(\sum_{k=0}^n (-1)^{n-k} \binom{n}{k} X^k\mu^{n-k}\right).
\]</span> Aplicando la propiedad de la esperanza que la esperanza de la suma es la suma de esperanzas, obtenemos la expresión dada por la proposición: <span class="math display">\[
\mu_n =\sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} E\left(X^k\right) = \sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} m_k.
\]</span></p>
</div>
<p><strong>Ejemplos de momentos centrales de orden <span class="math inline">\(n\)</span></strong></p>
<div class="example">
<p><strong>Ejemplo: momento central de orden <span class="math inline">\(n\)</span> de una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span>. Recordemos que su función de probabilidad es: <span class="math display">\[
P_X(0)=q=1-p,\ P_X(1)=p.
\]</span> Usando que <span class="math inline">\(E(X)=p\)</span>, su momento central de orden <span class="math inline">\(n\)</span> será: <span class="math display">\[
\mu_n = E\left((X-p)^n\right)=p\cdot (1-p)^n+(1-p)\cdot (0-p)^n = p(1-p)^n + (-1)^n (1-p) p^n.
\]</span></p>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Demostrar que la expresión anterior corresponde a un polinomio de grado <span class="math inline">\(n\)</span>.</p>
</div>
<div class="example">
<p><strong>Ejemplo: momento central de orden <span class="math inline">\(n\)</span> de una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Consideremos ahora una variable <span class="math inline">\(X\)</span> exponencial de parámetro <span class="math inline">\(\lambda\)</span>.</p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\lambda \mathrm{e}^{-\lambda x},\)</span> para <span class="math inline">\(x\geq 0\)</span>.</p>
<p>Usando que <span class="math inline">\(E(X)=\frac{1}{\lambda}\)</span>, su momento central de orden <span class="math inline">\(n\)</span> será: <span class="math display">\[
\mu_n = E\left(\left(X-\frac{1}{\lambda}\right)^n\right)=\int_0^\infty \lambda \mathrm{e}^{-\lambda x} \left(x-\frac{1}{\lambda}\right)^n\, dx =\frac{a_n}{\lambda^n},
\]</span> donde <span class="math inline">\(a_n = n!\sum\limits_{k=0}^n \frac{(-1)^k}{k!}.\)</span></p>
<p>La expresión anterior fijado <span class="math inline">\(n\)</span> se puede obtener integrando por partes <span class="math inline">\(n\)</span> veces y resolviendo los límites correspondientes. Dejámos al lector los cálculos correspondientes. Sin embargo, la obtención de la fórmula general para <span class="math inline">\(n\)</span> se sale del nivel del curso.</p>
<p>Fijémonos que los momentos centrales de orden <span class="math inline">\(n\)</span> también tienden a infinito a medida que <span class="math inline">\(n\)</span> crece: <span class="math inline">\(\lim\limits_{n\to\infty}\mu_n = \lim\limits_{n\to\infty}\frac{a_n}{\lambda^n}=\infty\)</span>: <span class="math display">\[
\lim_{n\to\infty}\mu_n =\lim_{n\to\infty} \frac{n!\sum\limits_{k=0}^n \frac{(-1)^k}{k!}}{\lambda^n}=
\lim_{n\to\infty}\sum\limits_{k=0}^n \frac{(-1)^k}{k!}\cdot \lim_{n\to\infty} \frac{n!}{\lambda^n}= \mathrm{e}^{-1}\cdot \infty = \infty.
\]</span></p>
</div>
<div class="example">
<p><strong>Ejemplo: momento central de orden <span class="math inline">\(n\)</span> de una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},\)</span> para <span class="math inline">\(x\in \mathbb{R}\)</span>.</p>
<p>Su momento central de orden 2 será la varianza <span class="math inline">\(\sigma^2\)</span>: <span class="math inline">\(\mu_2 =\sigma^2.\)</span></p>
<p>Los momentos centrales de orden impar <span class="math inline">\(n\)</span> serán cero ya que integramos una función impar respecto <span class="math inline">\(x=\mu\)</span>: <span class="math inline">\(\mu_n = E\left((X-\mu)^n\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^n\, dx = 0.\)</span> O sea, si consideramos <span class="math inline">\(g(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^n\)</span>, se verifica <span class="math inline">\(g(\mu-x)=-g(\mu +x)\)</span>, para todo <span class="math inline">\(x\in\mathbb{R}\)</span>.</p>
<p>Si intentamos calcular el momento central de orden 4, obtenemos: <span class="math inline">\(\mu_4 = E\left((X-\mu)^4\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^4\, dx = 3\sigma^4.\)</span> La integral anterior puede resolverse con el cambio de variable <span class="math inline">\(t=\frac{x-\mu}{\sigma}\)</span> y usando que: <span class="math inline">\(\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^4\, dx = 3.\)</span></p>
</div>
</section>
</section>
<section id="asimetría-de-una-variable-aleatoria" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="asimetría-de-una-variable-aleatoria"><span class="header-section-number">5.2</span> Asimetría de una variable aleatoria</h2>
<p>Una variable aleatoria tiene <strong>asimetría positiva</strong> si su función de densidad o de probabilidad presenta una cola a la <strong>derecha</strong> y <strong>asimetría negativa</strong>, si su función de densidad o de probabilidad presenta cola a la <strong>izquierda</strong>.</p>
<p>Por ejemplo, en la figura siguiente, vemos la gráfica de la función de probabilidad de una variable aleatoria que presenta <strong>asimetría negativa</strong> a la izquierda y una función de densidad de una variable aleatoria que presenta <strong>asimetría positiva</strong> a la derecha:</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
<p><strong>¿Cómo calcular la asimetría de una variable aleatoria?</strong></p>
<p>La asimetría de una variable aleatoria <span class="math inline">\(X\)</span> se calcula a partir de sus momentos centrales de segundo y tercer orden: <span class="math display">\[
\gamma_1 = E\left({\left(\frac{X-\mu}{\sigma}\right)}^3\right)=\frac{\mu_3}{\sigma^3},
\]</span> donde <span class="math inline">\(\mu = E(X)\)</span> y <span class="math inline">\(\sigma^2 =\mathrm{Var}(X)\)</span>.</p>
<p>Dicho valor se denomina <strong>coeficiente de asimetría de Pearson</strong>.</p>
<p>Usando la relación ya vista entre los momentos centrales y los momentos, podemos expresar el <strong>coeficiente de asimetría</strong> en función de los momentos: <span class="math display">\[
\gamma_1 = \frac{m_3 -3\mu\sigma^2-\mu^3}{\sigma^3}.
\]</span> Dejamos al lector la comprobación de la expresión anterior.</p>
<p>Por tanto, una variable aleatoria <span class="math inline">\(X\)</span> tendrá simetría positiva o a la derecha si <span class="math inline">\(\gamma_1 &gt;0\)</span> y tendrá asimetría negativa o a la izquierda, si <span class="math inline">\(\gamma_1 &lt;0\)</span>.</p>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de asimetría para una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span>. Usando que <span class="math inline">\(m_n =p\)</span>, para todo <span class="math inline">\(n\)</span> y que <span class="math inline">\(\mu_2 = \sigma^2 = p-p^2\)</span>, el coeficiente de asimetría <span class="math inline">\(\gamma_1\)</span> será: <span class="math display">\[
\gamma_1 = \frac{p-3p(p-p^2)-p^3}{\sqrt{(p-p^2)^3}} = \frac{p (1-p) (1-2p)}{{\sqrt{(p-p^2)^3}}}.
\]</span> Por tanto, la variable de Bernoulli de parámetro <span class="math inline">\(p\)</span> tendrá simetria negativa si <span class="math inline">\(p&gt;\frac{1}{2}\)</span> y positiva, si <span class="math inline">\(p&lt;\frac{1}{2}\)</span>:</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de asimetría para una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span>. Usando que <span class="math inline">\(\sigma^2=\frac{1}{\lambda^2}\)</span> y <span class="math inline">\(\mu_3 =\frac{a_3}{\lambda^3}=\frac{2}{\lambda^3}\)</span>, su coeficiente de asimetría de Pearson será: <span class="math inline">\(\gamma_1 = \frac{\frac{2}{\lambda^3}}{\frac{1}{\lambda^3}}=2.\)</span></p>
<p>Entonces presenta asimetría positiva o a la derecha tal como se observa en su función de densidad:</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de asimetría para una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>Tal como se ha indicado anteriormente, los momentos centrales de orden impar son nulos.</p>
<p>Por tanto, en este caso <span class="math inline">\(\mu_3=0\)</span> y, por tanto, <span class="math inline">\(\gamma_1=0\)</span>.</p>
<p>Deducimos que la distribución normal es totalmente simétrica.</p>
<p>De hecho, usando que su función de densidad es <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},\)</span> para <span class="math inline">\(x\in \mathbb{R}\)</span>, se puede comprobar que <span class="math inline">\(f_X(\mu-x)=f_X(\mu +x)\)</span>, o sea, tiene el eje de simetría <span class="math inline">\(x=\mu\)</span>:</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</section>
<section id="curtosis-o-apuntamiento-de-una-variable-aleatoria" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="curtosis-o-apuntamiento-de-una-variable-aleatoria"><span class="header-section-number">5.3</span> Curtosis o apuntamiento de una variable aleatoria</h2>
<p>La curtosis de una variable aleatoria <span class="math inline">\(X\)</span> es una medida de cómo son las colas de su función de densidad.</p>
<p>Dicho en otras palabras, queremos medir de alguna manera la <em>tendencia</em> que tiene la variable aleatoria a tener valores atípicos o <em>outliers</em>.</p>
<p>La manera estándard de medir la curtosis de una variable aleatoria <span class="math inline">\(X\)</span> es a partir de su <strong>momento central de cuarto orden</strong>: <span class="math display">\[
\gamma_2 = E\left(\left(\frac{X-\mu}{\sigma}\right)^4\right) = \frac{\mu_4}{\sigma^4},
\]</span> donde recordemos que <span class="math inline">\(\mu=E(X)\)</span> y <span class="math inline">\(\sigma^2 =\mathrm{Var}(X)\)</span>.</p>
<p>A la expresión anterior se le denomina <strong>medida de curtosis de Pearson</strong>.</p>
<ul>
<li><p>Diremos que una variable aleatoria no tiene exceso de curtosis o <strong>mesocúrtica</strong> si <span class="math inline">\(\gamma_2 \approx 3\)</span>.</p></li>
<li><p>Diremos que una variable aleatoria tiene exceso positivo de curtosis o <strong>leptocúrtica</strong> si <span class="math inline">\(\gamma_2 &gt;3\)</span>.</p></li>
<li><p>Diremos que una variable aleatoria tiene exceso negativo de curtosis o <strong>platicúrtica</strong> si <span class="math inline">\(\gamma_2 &lt;3\)</span>.</p></li>
</ul>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de curtosis para una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de parámetro <span class="math inline">\(p\)</span>.</p>
<p>El momento central de cuarto orden de <span class="math inline">\(X\)</span> será: <span class="math display">\[
\mu_4 = p (1-p)^4 +(1-p)p^4 = p (1-p) (3 p^2-3p+1).
\]</span> La medida de curtosis de Pearson será: <span class="math display">\[
\gamma_2 = \frac{p (1-p) (3 p^2-3p+1)}{p^2 (1-p)^2} = \frac{3 p^2-3p+1}{p(1-p)}.
\]</span> Se puede comprobar (ejercicio para el lector) que si <span class="math inline">\(p\in \left(\frac{3-\sqrt{3}}{6},\frac{3+\sqrt{3}}{6}\right)\approx (0.211,0.789)\)</span>, <span class="math inline">\(\gamma_2 &lt;3\)</span> y, por tanto <span class="math inline">\(X\)</span> será platicúrtica y en caso contrario, si <span class="math inline">\(p\in \left(0,\frac{3-\sqrt{3}}{6}\right)\cup \left(\frac{3+\sqrt{3}}{6},1\right)\)</span>, <span class="math inline">\(\gamma_2 &gt;3\)</span> y, por tanto, <span class="math inline">\(X\)</span> será leptocúrtica.</p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de curtosis para una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span>. Usando que <span class="math inline">\(\sigma^2=\frac{1}{\lambda^2}\)</span> y <span class="math inline">\(\mu_4 =\frac{a_4}{\lambda^3}=\frac{9}{\lambda^4}\)</span>, su coeficiente de asimetría de Pearson será: <span class="math inline">\(\gamma_2 = \frac{\frac{9}{\lambda^4}}{\frac{1}{\lambda^4}}=9.\)</span></p>
<p>Como <span class="math inline">\(\gamma_2 &gt;3\)</span>, se trataría de una distribución leptocúrtica.</p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo del coeficiente de curtosis para una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>Tal como se ha indicado anteriormente, el momento central de orden 4 vale: <span class="math inline">\(\mu_4 = 3\sigma^4\)</span>.</p>
<p>Su coeficiente de curtosis será: <span class="math display">\[
\gamma_2 =\frac{\mu_4}{\sigma^4}=\frac{3\sigma^4}{\sigma^4}=3.
\]</span> Deducimos, por tanto, que toda distribución normal es mesocúrtica o no tiene exceso (ni positivo ni negativo) de curtosis.</p>
</div>
</section>
<section id="métodos-de-transformación" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="métodos-de-transformación"><span class="header-section-number">5.4</span> Métodos de transformación</h2>
<p>Hemos visto anteriormente que el cálculo de los <strong>momentos</strong> o los <strong>momentos centrados</strong> de una variable aleatoria <span class="math inline">\(X\)</span> puede ser muy complicado y muy tedioso.</p>
<p>Por dicho motivo, vamos a introducir un conjunto de funciones que nos permitirán calcular los <strong>momentos</strong> de la variable <span class="math inline">\(X\)</span> de forma relativamente sencilla.</p>
<section id="función-generatriz-de-momentos" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="función-generatriz-de-momentos"><span class="header-section-number">5.4.1</span> Función generatriz de momentos</h3>
<p><l class="definition"><strong>Definición de función generatriz de momentos:</strong> </l> Sea <span class="math inline">\(X\)</span> una variable aleatoria <span class="math inline">\(X\)</span> con función de probabilidad <span class="math inline">\(P_X\)</span> en el caso discreto o función de densidad <span class="math inline">\(f_X\)</span> en el caso continuo.</p>
<p>Sea <span class="math inline">\(t\in\mathbb{R}\)</span> un valor real cualquiera.</p>
<p>Definimos la función generatriz de momentos <span class="math inline">\(m_X(t)\)</span> en el valor <span class="math inline">\(t\)</span> como: <span class="math inline">\(m_X(t)=E\left(\mathrm{e}^{tX}\right).\)</span></p>
<div class="example">
<p><strong>Ejemplo: cálculo de la función generatriz de momentos para una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de Bernoulli de parámetro <span class="math inline">\(p\)</span>. Recordemos que su función de probabilidad es: <span class="math display">\[
P_X(0)=q=1-p,\ p_X(1)=p.
\]</span> Su función generatriz de momentos será: <span class="math display">\[
m_X (t)=E\left(\mathrm{e}^{tX}\right) =p\mathrm{e}^{t\cdot 1}+(1-p)\mathrm{e}^{t\cdot 0}=p\mathrm{e}^t+(1-p)=1+p\left(\mathrm{e}^t -1 \right).
\]</span></p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo de la función generatriz de momentos para una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria exponencial de parámetro <span class="math inline">\(\lambda\)</span>. Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\lambda \mathrm{e}^{-\lambda x},\)</span> para <span class="math inline">\(x\geq 0\)</span> y <span class="math inline">\(0\)</span>, en caso contrario.</p>
<p>Su función generatriz de momentos será: <span class="math display">\[
m_X (t)=E\left(\mathrm{e}^{tX}\right)=\int_0^\infty \mathrm{e}^{t x}\lambda \mathrm{e}^{-\lambda x}\, dx = \lambda \int_0^\infty\mathrm{e}^{(t-\lambda)x}\, dx = \lambda\left[\frac{\mathrm{e}^{(t-\lambda)x}}{t-\lambda}\right]_{x=0}^{x=\infty} = \frac{\lambda}{\lambda -t},\ \mbox{si } t&lt;\lambda.
\]</span> En este caso vemos que el dominio de la función generatriz de momentos <span class="math inline">\(m_X\)</span> es <span class="math inline">\((-\infty,\lambda)\)</span>, ya que si <span class="math inline">\(t\geq \lambda\)</span>, la integral anterior no es convergente.</p>
<p>Fijémonos por lo que vendrá más adelante que, como <span class="math inline">\(\lambda &gt;0\)</span>, el valor <span class="math inline">\(0\)</span> pertenece al dominio de <span class="math inline">\(m_X\)</span>.</p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo de la función generatriz de momentos para una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},\)</span> para <span class="math inline">\(x\in \mathbb{R}\)</span>.</p>
<p>Su función generatriz de momentos será:</p>
<p><span class="math display">\[
\begin{array}{rl}
m_X (t) &amp; =E\left(\mathrm{e}^{tX}\right)=\displaystyle\int_{-\infty}^\infty \mathrm{e}^{tx}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{tx-\frac{(x-\mu)^2}{2\sigma^2}}\, dx \\[1ex]  &amp; =  \displaystyle\frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}\left((x-(\sigma^2 t+\mu))^2-2\sigma^2 t \mu-\sigma^4t^2\right)}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \mathrm{e}^{\frac{1}{2}(2 t \mu +\sigma^2 t^2)}\int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 t+\mu))^2}\, dx\\[1ex] &amp;  = \displaystyle\mathrm{e}^{\frac{1}{2}(2 t \mu +\sigma^2 t^2)} \left( \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 t+\mu))^2}\, dx\right) =  \mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}}.
\end{array}
\]</span> La integral del último paréntesis se resuelve haciento el cambio de variable <span class="math inline">\(u=x-\sigma^2 t\)</span> y usando que la integral de la función de densidad de <span class="math inline">\(X\)</span> sobre todo <span class="math inline">\(\mathbb{R}\)</span> vale 1.</p>
</div>
<p><strong>Relación entre la función generatriz de momentos y los momentos</strong></p>
<p>La razón del nombre que lleva la <strong>función generatriz de momentos</strong> es que podemos obtener todos los momentos de la variable a partir de ella:</p>
<p><l class="prop"> <strong>Proposición.</strong> </l> Sean <span class="math inline">\(X\)</span> una variable aleatoria con <strong>función generatriz de momentos</strong> <span class="math inline">\(m_X(t)\)</span>. Entonces, el momento de orden <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> se puede obtener de la forma siguiente: <span class="math display">\[
m_n =E\left(X^n\right)=\frac{d}{d t^n}m_X(t)|_{t=0} =m_X^{(n)}(0).
\]</span> O sea, el momento de orden <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> es la derivada <span class="math inline">\(n\)</span>-ésima de la función generatriz de momentos evaluada en <span class="math inline">\(t=0\)</span>.</p>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>Recordemos la definición de la función generatriz de momentos: <span class="math inline">\(m_X(t)=E\left(\mathrm{e}^{tX}\right).\)</span></p>
<p>La idea de la demostración es probar por inducción que <span class="math inline">\(m_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)\)</span>.</p>
<p>Veámoslo para <span class="math inline">\(n=1\)</span>: <span class="math inline">\(m_X'(t)=E\left(\mathrm{e}^{tX}\cdot X\right)\)</span>.</p>
<p>Seguidamente, apliquemos inducción sobre <span class="math inline">\(n\)</span>. Supongamos que <span class="math inline">\(m_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)\)</span> y veamos que <span class="math inline">\(m_X^{(n+1)}(t) =E\left(\mathrm{e}^{tX}\cdot X^{n+1}\right)\)</span>: <span class="math inline">\(m_X^{(n+1)}(t) =\frac{d}{dt}(m_X^{(n)}(t)) =\frac{d}{dt}E\left(\mathrm{e}^{tX}\cdot X^n\right) = E\left(\mathrm{e}^{tX}\cdot X^{n+1}\right),\)</span> tal como queríamos demostrar.</p>
<p>Ahora si aplicamos la expresión demostrada <span class="math inline">\(m_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)\)</span> a <span class="math inline">\(t=0\)</span>, obtenemos: <span class="math inline">\(m_X^{(n)}(0) =E\left(X^n\right)=m_n,\)</span> tal como dice la proposición.</p>
</div>
<div class="example">
<p><strong>Ejemplo: aplicación de la proposición en el caso en que <span class="math inline">\(X\)</span> es una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>En este caso, recordemos que: <span class="math inline">\(m_X (t)=1+p\left(\mathrm{e}^t -1 \right).\)</span></p>
<p>Se puede comprobar que <span class="math inline">\(m_X^{(n)}(t)=p\mathrm{e}^t\)</span>. Por tanto: <span class="math display">\[
m_n = m_X^{(n)}(0)=p,
\]</span> tal como habíamos calculado anteriormente.</p>
</div>
<div class="example">
<p><strong>Ejemplo: aplicación de la proposición en el caso en que <span class="math inline">\(X\)</span> es una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>En este caso, recordemos que: <span class="math inline">\(m_X (t)=\frac{\lambda}{\lambda -t},\)</span> para <span class="math inline">\(t&lt;\lambda\)</span> pero como <span class="math inline">\(\lambda &gt;0\)</span>, <span class="math inline">\(t=0\)</span> cumple la expresión anterior.</p>
<p>Dejamos como ejercicio para el lector comprobar que: <span class="math inline">\(m_X^{(n)}(t)=\frac{\lambda n!}{(\lambda-t)^{n+1}}\)</span>.</p>
<p>Por tanto: <span class="math display">\[
m_n = m_X^{(n)}(0) = \frac{\lambda n!}{\lambda^{n+1}}=\frac{n!}{\lambda^n},
\]</span> expresión que ya habíamos obtenido anteriormente.</p>
</div>
<div class="example">
<p><strong>Ejemplo: aplicación de la proposición en el caso en que <span class="math inline">\(X\)</span> es una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>En este caso, recordemos que: <span class="math inline">\(m_X (t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}}.\)</span></p>
<p>Aplicando la fórmula de los momentos para <span class="math inline">\(n=1\)</span> obtenemos: <span class="math inline">\(m'(t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left(\mu+t\sigma^2\right)\)</span>, que en <span class="math inline">\(t=0\)</span> vale: <span class="math inline">\(m'(0)=\mu=E(X)\)</span>, tal como ya sabemos.</p>
<p>Si la aplicamos para <span class="math inline">\(n=2\)</span>, obtenemos: <span class="math inline">\(m''(t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left((\mu+t\sigma^2)^2+ \sigma^2 \right) =\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left(t^2\sigma^4+\mu^2+\sigma^2+ 2t\mu\sigma^2 \right)\)</span>, que en <span class="math inline">\(t=0\)</span> vale: <span class="math inline">\(m''(0)=\mu^2+\sigma^2=E\left(X^2\right)\)</span>, tal como ya sabemos.</p>
<p>Para <span class="math inline">\(n=3\)</span>m obtenemos: <span class="math inline">\(m'''(t)=e^{\mu t+\frac{\sigma ^2 t^2}{2}}\left(\mu +\sigma ^2 t\right) \left(\left(\mu +\sigma ^2 t\right)^2+3 \sigma ^2\right)\)</span>, que en <span class="math inline">\(t=0\)</span> vale: <span class="math inline">\(m'''(0)=3\sigma^2\mu = E\left(X^3\right)\)</span>, valor que correspondería al momento de tercer orden de <span class="math inline">\(X\)</span>.</p>
<p>Por último, para <span class="math inline">\(n=4\)</span>, obtenemos: <span class="math inline">\(m^{(iv)}(t)=e^{\mu t+\frac{\sigma ^2 t^2}{2}}  \left(6 \sigma ^2 \left(\mu  +\sigma ^2 t\right)^2+\left(\mu  +\sigma ^2 t\right)^4+3 \sigma  ^4\right)\)</span>, que en <span class="math inline">\(t=0\)</span> vale: <span class="math inline">\(m^{(iv)}(0)=6\sigma^2\mu^2+\mu^4+3\sigma^4=E\left(X^4\right)\)</span>, valor que correspondería al momento de cuarto orden de <span class="math inline">\(X\)</span>.</p>
</div>
</section>
<section id="función-característica" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="función-característica"><span class="header-section-number">5.4.2</span> Función característica</h3>
<p><l class="definition"><strong>Definición de función característica:</strong> </l> Sea <span class="math inline">\(X\)</span> una variable aleatoria <span class="math inline">\(X\)</span> con función de probabilidad <span class="math inline">\(P_X\)</span> en el caso discreto o función de densidad <span class="math inline">\(f_X\)</span> en el caso continuo.</p>
<p>Sea <span class="math inline">\(w\in\mathbb{R}\)</span> un valor real cualquiera.</p>
<p>Definimos la función característica <span class="math inline">\(\phi_X(w)\)</span> en el valor <span class="math inline">\(w\)</span> como: <span class="math inline">\(\phi_X(w)=E\left(\mathrm{e}^{\mathrm{i} w X}\right),\)</span> donde <span class="math inline">\(\mathrm{i}\)</span> es el número complejo <span class="math inline">\(\mathrm{i}=\sqrt{-1}\)</span>.</p>
<p><l class="observ">Observación: </l> Si <span class="math inline">\(X\)</span> es una variable continua, la <strong>función característica</strong> <span class="math inline">\(\phi_X(w)\)</span> puede interpretarse como la <strong>transformada de Fourier</strong> de la <strong>función de densidad</strong> de <span class="math inline">\(X\)</span>: <span class="math inline">\(\phi(w)=\int_{-\infty}^\infty f_X(x)\mathrm{e}^{\mathrm{i}w x}\, dx.\)</span></p>
<p>Por tanto, usando la fórmula de la <strong>antitransformada de Fourier</strong>, podemos escribir la <strong>función de densidad</strong> <span class="math inline">\(f_X(x)\)</span> como función de la <strong>función característica</strong> de <span class="math inline">\(X\)</span>, <span class="math inline">\(\phi(w)\)</span>: <span class="math inline">\(f_X(x)=\frac{1}{2\pi}\int_{-\infty}^\infty \phi_X(w)\mathrm{e}^{-\mathrm{i}w x}\, dw.\)</span></p>
<p><l class="observ">Observación: </l> En el caso discreto, o sea, Si <span class="math inline">\(X\)</span> es una variable discreta, la <strong>función característica</strong> <span class="math inline">\(\phi_X(w)\)</span> se escribe como función de la <strong>función de probabilidad</strong> <span class="math inline">\(P_X(x_k)\)</span> con <strong>Dominio</strong> <span class="math inline">\(D_X=\{x_k,\ k\}\)</span> como: <span class="math inline">\(\phi(w)=\sum_{k} P_X(x_k)\mathrm{e}^{\mathrm{i}w x_k}.\)</span></p>
<p>En los casos en que los <span class="math inline">\(x_k\)</span> sean enteros, <span class="math inline">\(x_k=k\)</span>, que son la mayoría, la ecuación anterior es la <strong>tranformada de Fourier de la secuencia</strong> <span class="math inline">\(P_X(k)\)</span>. Dicha función es una <em>función periódica</em> en <span class="math inline">\(w\)</span> de periodo <span class="math inline">\(2\pi\)</span> ya que <span class="math inline">\(\mathrm{e}^{\mathrm{i}(w+2\pi)k}=\mathrm{e}^{\mathrm{i}wk}.\)</span></p>
<p>Por tanto, usando la fórmula de <strong>inversión</strong>, podemos escribir la <strong>función de probabilidad</strong> <span class="math inline">\(P_X(k)\)</span> como función de la función característica de <span class="math inline">\(X\)</span>, <span class="math inline">\(\phi(w)\)</span>: <span class="math inline">\(P_X(k)=\frac{1}{2\pi}\int_{0}^{2\pi} \phi_X(w)\mathrm{e}^{-\mathrm{i}w k}\, dw.\)</span></p>
<div class="example">
<p><strong>Ejemplo: cálculo de la función característica para una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de Bernoulli de parámetro <span class="math inline">\(p\)</span>. Recordemos que su función de probabilidad es: <span class="math display">\[
P_X(0)=q=1-p,\ p_X(1)=p.
\]</span> Su función característica será: <span class="math display">\[
\phi_X (w)=E\left(\mathrm{e}^{\mathrm{i}wX}\right) =p\mathrm{e}^{\mathrm{i}w\cdot 1}+(1-p)\mathrm{e}^{\mathrm{i}w\cdot 0}=p\mathrm{e}^{\mathrm{i}w}+(1-p)=1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right).
\]</span> Comprobemos la fórmula de la inversión: <span class="math display">\[
\begin{array}{rl}
P_X(1) &amp; = \frac{1}{2\pi}\int_0^{2\pi} \left(1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right)\right) e^{-\mathrm{i}w\cdot 1}\, dw =\frac{1}{2\pi}\left(\int_0^{2\pi} (1-p)e^{-\mathrm{i}w}\, dw + \int_0^{2\pi} p\, dw\right) \\ &amp; = \frac{1}{2\pi}\left( (1-p) \left[\frac{\mathrm{e}^{-\mathrm{i}w}}{-\mathrm{i}}\right]_0^{2\pi} +2\pi p\right)=\frac{1}{2\pi}\left((1-p)\cdot 0 +2\pi p\right)=p, \\
P_X(0) &amp; = \frac{1}{2\pi}\int_0^{2\pi} \left(1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right)\right) e^{-\mathrm{i}w\cdot 0}\, dw =\frac{1}{2\pi}\left(\int_0^{2\pi} (1-p) \, dw + \int_0^{2\pi} p \mathrm{e}^{\mathrm{i}w}\, dw\right) \\ &amp; = \frac{1}{2\pi}\left( (1-p) \cdot 2\pi  +p \left[\frac{\mathrm{e}^{\mathrm{i}w}}{\mathrm{i}}\right]_0^{2\pi}\right)=\frac{1}{2\pi}\left((1-p)\cdot 2\pi + p\cdot 0\right)=1-p.
\end{array}
\]</span></p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo de la función característica para una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria exponencial de parámetro <span class="math inline">\(\lambda\)</span>. Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\lambda \mathrm{e}^{-\lambda x},\)</span> para <span class="math inline">\(x\geq 0\)</span> y <span class="math inline">\(0\)</span>, en caso contrario.</p>
<p>Su función característica será: <span class="math display">\[
\phi_X (w)=E\left(\mathrm{e}^{\mathrm{i}wX}\right)=\int_0^\infty \mathrm{e}^{\mathrm{i}w x}\lambda \mathrm{e}^{-\lambda x}\, dx = \lambda \int_0^\infty\mathrm{e}^{(\mathrm{i}w-\lambda)x}\, dx = \lambda\left[\frac{\mathrm{e}^{(\mathrm{i}w-\lambda)x}}{\mathrm{i}w-\lambda}\right]_{x=0}^{x=\infty} = \frac{\lambda}{\lambda -\mathrm{i} w}.
\]</span> La expresión anterior es válida para todo <span class="math inline">\(w\in\mathbb{R}\)</span> ya que su valor sería: <span class="math inline">\(\phi_X (w)=\frac{\lambda}{\lambda -\mathrm{i} w}\cdot \frac{\lambda +\mathrm{i} w}{\lambda +\mathrm{i} w}=\frac{\lambda^2+\mathrm{i}\lambda w}{\lambda^2+w^2}=\frac{\lambda^2}{\lambda^2+w^2}+\mathrm{i}\frac{\lambda w}{\lambda^2+w^2}.\)</span> En la última expresión hemos separado la parte real de la imaginaria.</p>
<p>Calculemos la función de densidad a partir de la función característica: <span class="math display">\[
f_X(x)=\frac{1}{2\pi}\int_{-\infty}^\infty \frac{\lambda}{\lambda -\mathrm{i} w}\mathrm{e}^{-\mathrm{i}wx}\, dw = a\mathrm{e}^{-a x},
\]</span> si <span class="math inline">\(x&gt;0\)</span> y <span class="math inline">\(0\)</span> en caso contrario. El cálculo de la integral anterior debe realizarse usando el <em>Teorema de los Residuos</em>, <a href="https://en.wikipedia.org/wiki/Residue_theorem">Residue theorem</a> y se sale de los objetivos de este curso.</p>
</div>
<div class="example">
<p><strong>Ejemplo: cálculo de la función característica para una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},\)</span> para <span class="math inline">\(x\in \mathbb{R}\)</span>.</p>
<p>Su función característica será:</p>
<p><span class="math display">\[
\begin{array}{rl}
\phi_X (w) &amp; =\displaystyle E\left(\mathrm{e}^{\mathrm{i}w X}\right)=\int_{-\infty}^\infty \mathrm{e}^{\mathrm{i}w x}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{\mathrm{i}wx-\frac{(x-\mu)^2}{2\sigma^2}}\, dx \\[1ex]  &amp; =\displaystyle  \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}\left((x-(\sigma^2 \mathrm{i}w+\mu))^2-2\sigma^2 \mathrm{i}w \mu+\sigma^4 w^2\right)}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \mathrm{e}^{\frac{1}{2}(2 \mathrm{i}w \mu -\sigma^2 w^2)}\int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 \mathrm{i}w+\mu))^2}\, dx\\[1ex] &amp;  = \displaystyle\mathrm{e}^{\frac{1}{2}(2 \mathrm{i}w \mu -\sigma^2 w^2)} \left( \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 \mathrm{i}w+\mu))^2}\, dx\right) =  \mathrm{e}^{ \mathrm{i}w \mu -\frac{\sigma^2 w^2}{2}}.
\end{array}
\]</span> La integral del último paréntesis se resuelve haciento el cambio de variable <span class="math inline">\(u=x-\sigma^2 \mathrm{i}w\)</span> y usando que la integral de la función de densidad de <span class="math inline">\(X\)</span> sobre todo <span class="math inline">\(\mathbb{R}\)</span> vale 1.</p>
<p>Calculemos la función de densidad a partir de la función característica: <span class="math display">\[
\begin{array}{rl}
f_X(x) &amp; =\displaystyle\frac{1}{2\pi}\int_{-\infty}^\infty \mathrm{e}^{ \mathrm{i}w \mu -\frac{\sigma^2 w^2}{2}}\mathrm{e}^{-\mathrm{i} w x}\, dw = \frac{1}{2\pi}\int_{-\infty}^\infty \mathrm{e}^{\left(\frac{\mathrm{i}w\sigma}{\sqrt{2}}+\frac{\mu-x}{\sigma\sqrt{2}}\right)^2-\frac{(\mu-x)^2}{2\sigma^2}}\, dw =\frac{1}{2\pi}\mathrm{e}^{-\frac{(\mu-x)^2}{2\sigma^2}}\int_{-\infty}^\infty \mathrm{e}^{\left(\frac{\mathrm{i}w\sigma}{\sqrt{2}}+\frac{\mu-x}{\sigma\sqrt{2}}\right)^2}\, dw \\[1ex] &amp; =\displaystyle \frac{1}{2\pi}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\int_{-\infty}^\infty \mathrm{e}^{-\left(\frac{w\sigma}{\sqrt{2}}+\frac{\mu-x}{\mathrm{i}\sigma\sqrt{2}}\right)^2}\, dw \stackrel{\mbox{cambio de variable } u=\frac{w\sigma}{\sqrt{2}}+\frac{\mu-x}{\mathrm{i}\sigma\sqrt{2}}}{=} \frac{1}{2\pi}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\int_{-\infty}^\infty \frac{\sqrt{2}}{\sigma}\mathrm{e}^{-u^2}\, du \\[1ex] &amp; \displaystyle\stackrel{\int_{-\infty}^\infty \mathrm{e}^{-u^2}\, du =\sqrt{\pi}}{=} \frac{1}{\sqrt{2}\pi\sigma} \mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}} \sqrt{\pi} = \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},
\end{array}
\]</span> función que coincide con la densidad de la distribución <span class="math inline">\(N(\mu,\sigma)\)</span>.</p>
</div>
<p><strong>Relación entre la función característica y los momentos</strong></p>
<p>La relación entre la <strong>función característica</strong> y los <strong>momentos</strong> es la siguiente:</p>
<p><l class="prop"> <strong>Proposición.</strong> </l> Sean <span class="math inline">\(X\)</span> una variable aleatoria con <strong>función característica</strong> <span class="math inline">\(\phi_X(w)\)</span>. Entonces, el momento de orden <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> se puede obtener de la forma siguiente: <span class="math display">\[
m_n =E\left(X^n\right)=\frac{1}{\mathrm{i}^n}\frac{d}{d w^n}\phi_X(w)|_{w=0} =\frac{1}{\mathrm{i}^n}\phi_X^{(n)}(0).
\]</span> O sea, el momento de orden <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> es la derivada <span class="math inline">\(n\)</span>-ésima de la función característica evaluada en <span class="math inline">\(w=0\)</span> dividido por <span class="math inline">\(\mathrm{i}^n\)</span>.</p>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>La demostración se realiza de forma similar a la demostración de la proposición que relaciona la función generatriz de momentos y los momentos.</p>
<p>Se deja como ejercicio al lector.</p>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Realizar los mismos ejemplos que los realizados para la función generatriz de momentos. O sea:</p>
<ul>
<li><p>Si <span class="math inline">\(X\)</span> es una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span>, demostrar usando la función característica que para todo <span class="math inline">\(n\)</span>, <span class="math inline">\(m_n = E\left(X^n\right)=p\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> es una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span>, demostrar usando la función característica que para todo <span class="math inline">\(n\)</span>, <span class="math inline">\(m_n = E\left(X^n\right)=\frac{n!}{\lambda^n}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> es una variable normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>, demostrar usando la función característica que <span class="math inline">\(E(X)=\mu\)</span>, <span class="math inline">\(E\left(X^2\right)=\mu^2+\sigma^2\)</span>, <span class="math inline">\(E\left(X^3\right)=3\sigma^2\mu\)</span> y <span class="math inline">\(E\left(X^4\right)=6\sigma^2\mu^2+\mu^4+3\sigma^4\)</span>.</p></li>
</ul>
</div>
</section>
</section>
<section id="fiabilidad" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="fiabilidad"><span class="header-section-number">5.5</span> Fiabilidad</h2>
<p>Sea <span class="math inline">\(T\geq 0\)</span> una variable aleatoria que nos da, por ejemplo, el tiempo de vida de cierto componente o dispositivo.</p>
<p>Vamos a definir medidas para estudiar la fiabilidad de este tipo de variables aleatorias.</p>
<p><l class="definition"><strong>Definición:</strong></l> Sea <span class="math inline">\(T\geq 0\)</span> una variable aleatoria. La <strong>fiabilidad</strong> de <span class="math inline">\(T\)</span> en el tiempo <span class="math inline">\(t\)</span> se define como la probabilidad que el sistema, componente o dispositivo funcione en el tiempo <span class="math inline">\(t\)</span>: <span class="math inline">\(R(t)=P(T&gt;t)\)</span>.</p>
<p><l class="observ"><strong>Observación:</strong></l> Dada una variable <span class="math inline">\(T\geq 0\)</span>, la relación existente entre la <strong>fiabilidad</strong> <span class="math inline">\(R\)</span> y la <strong>función de distribución</strong> <span class="math inline">\(F_T\)</span> es la siguiente: <span class="math display">\[
R(t)=P(T&gt;t)=1-P(T\leq t)=1-F_T (t)
\]</span></p>
<section id="tiempo-medio-de-vida" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="tiempo-medio-de-vida"><span class="header-section-number">5.5.1</span> Tiempo medio de vida</h3>
<p><l class="observ">Observación:</l> Dada una variable <span class="math inline">\(T\geq 0\)</span> continua, el <strong>tiempo medio de vida</strong> de la variable <span class="math inline">\(T\)</span> sería <span class="math inline">\(E(T)\)</span>. Entonces, este <strong>tiempo medio de vida</strong> se puede calcular como: <span class="math inline">\(E(T)=\int_0^\infty R(t)\, dt.\)</span></p>
<p>Veámoslo. Para ello basta ver que <span class="math inline">\(E(T)=\int_0^\infty (1-F_T(t))\, dt\)</span>, donde <span class="math inline">\(F_T(t)\)</span> es la función de distribución de la variable <span class="math inline">\(T\)</span>: <span class="math display">\[
\begin{array}{rl}
E(T) &amp; =\displaystyle\int_{t=0}^{t=\infty} 1-F_T(t)\, dt=\int_{t=0}^{t=\infty}\int_{u=t}^{u=\infty} f_T(u)\,du\,dt \\[1ex] &amp; =\displaystyle\int_{u=0}^{u=\infty} f_T(u)\int_{t=0}^{t=u} \, dt\, du =\int_{u=0}^{u=\infty} f_T(u)\cdot u\, du = E(T),
\end{array}
\]</span> donde <span class="math inline">\(f_T(u)\)</span> seria la función de densidad de la variable <span class="math inline">\(T\)</span> en el valor <span class="math inline">\(u\)</span>.</p>
<div class="example">
<p><strong>Ejemplo</strong></p>
<p>Sea <span class="math inline">\(T\)</span> una variable aleatoria exponencial de parámetro <span class="math inline">\(\lambda\)</span>.</p>
La fiabilidad de <span class="math inline">\(T\)</span> sería: <span class="math inline">\(R(t)=P(T&gt;t)=1-F_T(t)=\mathrm{e}^{-\lambda t}\)</span>:
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="generación-de-muestras-de-variables-aleatorias-por-ordenador" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="generación-de-muestras-de-variables-aleatorias-por-ordenador"><span class="header-section-number">5.6</span> Generación de muestras de variables aleatorias por ordenador</h2>
<p>La simulación por <strong>computadora</strong> de cualquier fenómeno aleatorio implica la <strong>generación de variables aleatorias</strong> con distribuciones prefijadas de antemano.</p>
<p>Por ejemplo, la simulación de un sistema de colas implica generar el tiempo entre las llegadas de los clientes, así como los tiempos de servicio de cada cliente.</p>
<p>Fijémonos que fijar la variable aleatoria <span class="math inline">\(X\)</span> es equivalente a fijar la <strong>función de distribución <span class="math inline">\(F_X(x)\)</span></strong> o la <strong>función de densidad <span class="math inline">\(f_X(x)\)</span></strong> en el caso continuo o la <strong>función de probabilidad <span class="math inline">\(P_X(x)\)</span></strong> en el caso discreto.</p>
<p>Todos los métodos que vamos a describir presuponen que podemos generar <strong>números aleatorios</strong> que se distribuyen <strong>uniformemente</strong> entre 0 y 1. En <code>R</code> se puede hacer usando la función <code>runif(n)</code>, donde <code>n</code> es la cantidad de números aleatorios entre 0 y 1 a generar.</p>
<section id="método-de-transformación" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="método-de-transformación"><span class="header-section-number">5.6.1</span> Método de transformación</h3>
<p>El <strong>método de transformación</strong> se basa en el resultado siguiente:</p>
<p><l class="prop"><strong>Proposición.</strong> </l> Sea <span class="math inline">\(X\)</span> una variable aleatoria con función de distribución <span class="math inline">\(F_X(x)\)</span>. Supongamos que <span class="math inline">\(F_X(x)\)</span> es estrictamente creciente o que existe <span class="math inline">\(F_X^{-1}(y)\)</span>, para todo <span class="math inline">\(y\in [0,1]\)</span>. Sea <span class="math inline">\(Y\)</span> la variable aleatoria definida como: <span class="math inline">\(Y=F_X(X)\)</span>. Entonces la distribución de <span class="math inline">\(Y\)</span> es uniforme en el intervalo <span class="math inline">\([0,1]\)</span>.</p>
<div class="dem">
<p><strong>Demostración:</strong></p>
<p>Claramente, por propia definición de <span class="math inline">\(Y\)</span>, tenemos que el dominio de <span class="math inline">\(Y\)</span> es <span class="math inline">\([0,1]\)</span> ya que el conjunto recorrido de la función de distribución de cualquier variable es el intervalo <span class="math inline">\([0,1]\)</span>.</p>
<p>Para ver que la distribución de <span class="math inline">\(Y\)</span> es <span class="math inline">\(U[0,1]\)</span> basta comprobar que <span class="math inline">\(F_Y(y)=y\)</span>, para todo <span class="math inline">\(y\in [0,1]\)</span>: <span class="math display">\[
\begin{array}{rl}
F_Y(y) &amp; =P(Y\leq y)=P(F_X(X)\leq y)\stackrel{\mbox{usando que $F_X$ es estrictamente creciente}}{=} P(X\leq F_X^{-1}(y)) \\ &amp; =F_X(F_X^{-1}(y))=y.
\end{array}
\]</span></p>
</div>
<p>Usando la proposición anterior, dada una variable <span class="math inline">\(X\)</span>, como la distribución de la variable aleatoria <span class="math inline">\(Y=F_X(X)\)</span> es <span class="math inline">\(U[0,1]\)</span>, si hacemos <span class="math inline">\(X=F_X^{-1}(Y)\)</span>, tendremos que si sabemos generar una muestra de <span class="math inline">\(Y\)</span>, aplicándole a la muestra la función <span class="math inline">\(F_X^{-1}\)</span> tendremos generada una muestra de <span class="math inline">\(X\)</span>.</p>
<div class="example">
<p><strong>Ejemplo: generar una muestra de una variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Recordemos que si <span class="math inline">\(X\)</span> es exponencial de parámetro <span class="math inline">\(\lambda\)</span>, su función de distribución es: <span class="math inline">\(F_X(x)=1-\mathrm{e}^{-\lambda x}\)</span>.</p>
<p>Hallemos a continuación <span class="math inline">\(F_X^{-1}\)</span>: <span class="math display">\[
y=1-\mathrm{e}^{-\lambda x},\ \Leftrightarrow 1-y=\mathrm{e}^{-\lambda x},\ \Leftrightarrow \ln(1-y)=-\lambda x,\ \Leftrightarrow x=-\frac{1}{\lambda}\ln(1-y).
\]</span> Por tanto, <span class="math inline">\(F_X^{-1}(y)=-\frac{1}{\lambda}\ln(1-y)\)</span>.</p>
<p>Generemos una muestra con <code>R</code> de 25 valores de una variable exponencial de parámetro <span class="math inline">\(\lambda=2\)</span> usando el método anterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">25</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>muestra.y <span class="ot">=</span> <span class="fu">runif</span>(n)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>muestra.x <span class="ot">=</span> <span class="sc">-</span>(<span class="dv">1</span><span class="sc">/</span>lambda)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>muestra.y)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>muestra.x</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.15180860 0.37232459 1.10938234 0.01363114 0.02497869 0.12913003
 [7] 0.06869490 0.16503293 0.02769114 1.72580033 0.21095823 0.43858898
[13] 1.19300954 0.74605377 0.39200164 0.62509776 0.04245918 0.16351714
[19] 0.25378997 0.36720423 0.45184400 0.47511264 1.08034369 0.45831998
[25] 0.78862207</code></pre>
</div>
</div>
<p>Vamos a testear si nuestro método funciona.</p>
<p>Para ello generaremos una muestra de 500 valores usando el método de transformación y dibujaremos su <strong>histograma de frecuencias relativas</strong>.</p>
<p>Seguidamente dibujaremos la <strong>función de densidad de la variable exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong> y compararemos los resultados:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">500</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>lambda<span class="ot">=</span><span class="dv">2</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>muestra.y <span class="ot">=</span> <span class="fu">runif</span>(n)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>muestra.x <span class="ot">=</span> <span class="sc">-</span>(<span class="dv">1</span><span class="sc">/</span>lambda)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span><span class="sc">-</span>muestra.y)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(muestra.x,<span class="at">freq=</span><span class="cn">FALSE</span>,<span class="at">main=</span><span class="st">"Histograma de la muestra"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">=</span><span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="fl">2.5</span>,<span class="at">by=</span><span class="fl">0.01</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x2,<span class="fu">dexp</span>(x2,lambda),<span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="center">
<div class="cell">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</section>
<section id="método-de-rechazo" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="método-de-rechazo"><span class="header-section-number">5.6.2</span> Método de rechazo</h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria continua tal que su función de densidad verifica:</p>
<ul>
<li>Existen valores <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> tal que <span class="math inline">\(f_X(x)= 0\)</span> si <span class="math inline">\(x\not\in [a,b]\)</span>.</li>
<li>Existen valores <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span> tal que <span class="math inline">\(f_X(x)\in [c,d]\)</span>, si <span class="math inline">\(x\in [a,b]\)</span>.</li>
</ul>
<p>En resumen, los puntos <span class="math inline">\((x,f(x))\)</span> pertenecen al rectángulo <span class="math inline">\([a,b]\times [c,d]\)</span> y en caso contrario <span class="math inline">\(f_X(x)=0\)</span>.</p>
<p>En el gráfico siguiente, <span class="math inline">\(a=0\)</span>, <span class="math inline">\(b=2\)</span>, <span class="math inline">\(c=0\)</span> y <span class="math inline">\(d=1\)</span>.</p>
<div class="center">
<div class="cell">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
<p>Para generar una <strong>muestra aleatoria</strong> de la variable <span class="math inline">\(X\)</span>, hacemos lo siguiente:</p>
<ol type="1">
<li><p>generamos un valor aleatorio <span class="math inline">\(x\)</span> entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>.</p></li>
<li><p>generamos un valor aleatorio <span class="math inline">\(y\)</span> entre <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span>.</p></li>
<li><p>si <span class="math inline">\(y\leq f_X(x)\)</span>, aceptamos <span class="math inline">\(x\)</span> como valor de la muestra. En caso contrario, volvemos a empezar en 1.</p></li>
</ol>
<div class="example">
<p><strong>Ejemplo</strong></p>
<p>El gráfico de la figura anterior corresponde a la función de densidad siguiente: <span class="math display">\[
f_X(x)=\begin{cases}
x, &amp; \mbox{ si }0\leq x\leq 1,\\
2-x, &amp; \mbox{ si }1\leq x\leq 2,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span></p>
<p>Vamos a generar una muestra de <span class="math inline">\(25\)</span> valores usando el <strong>método del rechazo</strong>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>a<span class="ot">=</span><span class="dv">0</span>; b<span class="ot">=</span><span class="dv">2</span>; c<span class="ot">=</span><span class="dv">0</span>; d<span class="ot">=</span><span class="dv">1</span>; n<span class="ot">=</span><span class="dv">25</span>; i<span class="ot">=</span><span class="dv">1</span>;</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x){<span class="fu">ifelse</span>(x<span class="sc">&gt;=</span><span class="dv">0</span> <span class="sc">&amp;</span> x<span class="sc">&lt;=</span><span class="dv">1</span>,x,<span class="fu">ifelse</span>(x<span class="sc">&gt;=</span><span class="dv">1</span><span class="sc">&amp;</span>x<span class="sc">&lt;=</span><span class="dv">2</span>,<span class="dv">2</span><span class="sc">-</span>x,<span class="dv">0</span>))}</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>muestra<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(i <span class="sc">&lt;=</span>n){</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">runif</span>(<span class="dv">1</span>,a,b)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  y<span class="ot">=</span><span class="fu">runif</span>(<span class="dv">1</span>,c,d)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(y <span class="sc">&lt;=</span> <span class="fu">f</span>(x)){muestra<span class="ot">=</span><span class="fu">c</span>(muestra,x); i<span class="ot">=</span>i<span class="sc">+</span><span class="dv">1</span>}</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>muestra</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.8934245 1.0241151 0.7485943 1.1318743 1.1174486 0.8956145 1.6270601
 [8] 0.6737312 0.9584882 0.5762514 0.7390811 0.4276671 1.5210227 0.8506008
[15] 0.4126257 0.9897587 1.2166050 1.6098125 0.8727734 0.8756381 1.4853939
[22] 1.1539542 1.2353779 0.5157756 1.2873756</code></pre>
</div>
</div>
<p>Como hicimos con el ejemplo del <strong>método de transformación</strong>, vamos a generar una muestra de 500 valores de la variable <span class="math inline">\(X\)</span>, vamos a dibujar el <strong>histograma de frecuencias relativas</strong> junto con la función de densidad para ver si ésta se aproxima a dicho histograma:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>a<span class="ot">=</span><span class="dv">0</span>; b<span class="ot">=</span><span class="dv">2</span>; c<span class="ot">=</span><span class="dv">0</span>; d<span class="ot">=</span><span class="dv">1</span>; n<span class="ot">=</span><span class="dv">500</span>; i<span class="ot">=</span><span class="dv">1</span>;</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x){<span class="fu">ifelse</span>(x<span class="sc">&gt;=</span><span class="dv">0</span> <span class="sc">&amp;</span> x<span class="sc">&lt;=</span><span class="dv">1</span>,x,<span class="fu">ifelse</span>(x<span class="sc">&gt;=</span><span class="dv">1</span><span class="sc">&amp;</span>x<span class="sc">&lt;=</span><span class="dv">2</span>,<span class="dv">2</span><span class="sc">-</span>x,<span class="dv">0</span>))}</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>muestra<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(i <span class="sc">&lt;=</span>n){</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  x<span class="ot">=</span><span class="fu">runif</span>(<span class="dv">1</span>,a,b)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  y<span class="ot">=</span><span class="fu">runif</span>(<span class="dv">1</span>,c,d)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(y <span class="sc">&lt;=</span> <span class="fu">f</span>(x)){muestra<span class="ot">=</span><span class="fu">c</span>(muestra,x); i<span class="ot">=</span>i<span class="sc">+</span><span class="dv">1</span>}</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(muestra,<span class="at">freq=</span><span class="cn">FALSE</span>,<span class="at">main=</span><span class="st">"Histograma de la muestra"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">=</span><span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="dv">2</span>,<span class="at">by=</span><span class="fl">0.01</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x2,<span class="fu">f</span>(x2),<span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="center">
<div class="cell">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="entropía" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="entropía"><span class="header-section-number">5.7</span> Entropía</h2>
<p>La <strong>entropía</strong> es una medida de la <strong>incertidumbre</strong> en un experimento aleatorio.</p>
<p>Veremos cómo la <strong>entropía</strong> cuantifica la <strong>incertidumbre</strong> por la cantidad de <strong>información</strong> requerida para especificar el resultado de un experimento aleatorio.</p>
<section id="entropía-de-una-variable-aleatoria" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="entropía-de-una-variable-aleatoria"><span class="header-section-number">5.7.1</span> Entropía de una variable aleatoria</h3>
<p>Supongamos que tenemos una variable aleatoria <span class="math inline">\(X\)</span> discreta con valores enteros: <span class="math inline">\(D_X=\{1,2,\ldots,N\}\)</span>.</p>
<p>Sea <span class="math inline">\(k\in D_X\)</span> un valor de la variable. Estamos interesados en cuantificar la <strong>incertidumbre</strong> del suceso <span class="math inline">\(A_k =\{X=k\}\)</span>.</p>
<p>O sea, cuánta <strong>menos incertidumbre</strong> tenga <span class="math inline">\(A_k\)</span>, más <strong>alta será su probabilidad</strong>, y cuánta <strong>más incertidumbre</strong>, <strong>menos probabilidad</strong> de aparecer <span class="math inline">\(A_k\)</span>.</p>
<p>Una medida que cumple las condiciones anteriores es la siguiente: <span class="math inline">\(I(A_k)=I(\{X=k\})=\ln\left(\frac{1}{P(X=k)}\right)=-\ln\left(P(X=k)\right).\)</span></p>
<p>Por ejemplo, si <span class="math inline">\(P(A_k)=1\)</span>, o sea, <span class="math inline">\(A_k\)</span> aparece “<strong>seguro</strong>”, entonces tiene incertidumbre <strong>nula</strong>, <span class="math inline">\(I(A_k)=0\)</span>, y si <span class="math inline">\(P(A_k)=0\)</span>, o sea, <span class="math inline">\(A_k\)</span> no aparece “<strong>nunca</strong>”, tiene incertidumbre <strong>máxima</strong>, <span class="math inline">\(I(A_k)=\infty\)</span>.</p>
<p>La motivación anterior hace que definamos la <strong>entropía</strong> de una variable aleatoria de la forma siguiente:</p>
<p><l class="definition"><strong>Definición:</strong></l> Sea <span class="math inline">\(X\)</span> una variable aleatoria con función de densidad <span class="math inline">\(f_X(x)\)</span> en el caso continuo o función de probabilidad <span class="math inline">\(P_X(x)\)</span> en el caso discreto. Definimos <strong>entropía de X</strong> como: <span class="math inline">\(H_X = \displaystyle E\left(-\ln(f_X)\right)=\int_{-\infty}^\infty -\ln(f_X(x)) f_X(x)\, dx,\)</span> en el caso continuo y, <span class="math inline">\(H_X = \displaystyle E\left(-\ln(P_X)\right)=\sum_{x_k\in D_X} -\ln(P_X(x_k)) P_X(x_k),\)</span> en el caso discreto.</p>
<div class="example">
<p><strong>Ejemplo: entropía de una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable de Bernoulli de parámetro <span class="math inline">\(p\)</span>.</p>
<p>Recordemos que su función de probabilidad <span class="math inline">\(P_X\)</span> es: <span class="math inline">\(P_X(0)=1-p=q,\)</span> <span class="math inline">\(P_X(1)=p\)</span>.</p>
<p>La entropía de <span class="math inline">\(X\)</span> será: <span class="math display">\[
H_X = E\left(-\ln(P_X)\right) = -(1-p)\cdot \ln(1-p)-p\cdot \ln p.
\]</span> El gráfico de la entropía se puede observar en el gráfico siguiente donde <span class="math inline">\(X\)</span> tiene entropía máxima cuando <span class="math inline">\(p=\frac{1}{2}\)</span> que sería cuando <span class="math inline">\(X\)</span> tiene incertidumbre máxima al tratar de adivinar el resultado de <span class="math inline">\(X\)</span> y <span class="math inline">\(X\)</span> tiene entropía mínima cuando <span class="math inline">\(p=0\)</span> o <span class="math inline">\(p=1\)</span> ya que en estos casos el resultado de <span class="math inline">\(X\)</span> sería siempre <span class="math inline">\(0\)</span> o <span class="math inline">\(1\)</span>, respectivamente.</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: Entropía de una variable aleatoria exponencial de parámetro <span class="math inline">\(\lambda\)</span></strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria exponencial de parámetro <span class="math inline">\(\lambda\)</span>.</p>
<p>Recordemos que su función de densidad es: <span class="math inline">\(f_X(x)=\lambda \mathrm{e}^{-\lambda x}\)</span>, si <span class="math inline">\(x\geq 0\)</span> y <span class="math inline">\(f_X(x)=0\)</span>, en caso contrario.</p>
<p>Su entropía será: <span class="math display">\[
\begin{array}{rl}
H_X &amp; = \displaystyle E\left(-\ln(f_X)\right)=-\int_0^\infty \ln\left(\lambda\mathrm{e}^{-\lambda x}\right)\lambda\mathrm{e}^{-\lambda x}\, dx = -\lambda \int_0^\infty (\ln(\lambda) -\lambda x)\mathrm{e}^{-\lambda x}\, dx \\[1ex] &amp; =\displaystyle -\ln (\lambda)\int_0^\infty \lambda\mathrm{e}^{-\lambda x}\, dx+\lambda \int_0^\infty \lambda x \mathrm{e}^{-\lambda x}\, dx =-\ln(\lambda)\int_0^\infty f_X(x)\, dx +\lambda E(X)\\[1ex] &amp; =\displaystyle -\ln(\lambda)+\lambda \frac{1}{\lambda} =1-\ln(\lambda).
\end{array}
\]</span> El gráfico de la entropía se puede observar en el gráfico siguiente donde <span class="math inline">\(X\)</span> tiene entropía máxima cuando <span class="math inline">\(\lambda=0\)</span> que sería cuando <span class="math inline">\(X\)</span> tiene incertidumbre máxima al tratar de adivinar el resultado de <span class="math inline">\(X\)</span> al tener media <span class="math inline">\(E(X)=\frac{1}{\lambda}=\infty\)</span> y <span class="math inline">\(X\)</span> tiene entropía mínima cuando <span class="math inline">\(\lambda\)</span> tiende a <span class="math inline">\(\infty\)</span> ya que su media <span class="math inline">\(E(X)=\frac{1}{\lambda}\)</span> tendería a 0.</p>
<div class="center">
<div class="cell" data-fig="true">
<div class="cell-output-display">
<p><img src="4_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Distribuciones Notables</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./5.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vectores aleatorios bidimensionales</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Introducción a la probabilidad para el análisis de datos: Con R y python.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Este libro se ha creado con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>